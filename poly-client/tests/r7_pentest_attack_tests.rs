//! Round 7 Pentest Attack Tests
//!
//! Tests for vulnerabilities discovered in the R7 security audit:
//!
//! 1. wide_sub length mismatch (CRITICAL) — rns.rs used a.len() not max(a,b)
//! 2. wide_gt asymmetric length (MEDIUM) — same pattern as wide_sub
//! 3. rns_ct_mul_plain_simd NaN/Inf bypass (HIGH) — no validation on values
//! 4. rns_ct_add NaN/Inf scale bypass (HIGH) — NaN bypasses assert_eq
//! 5. rns_ct_sub NaN/Inf scale bypass (HIGH) — same as rns_ct_add
//! 6. rns_rescale NaN/Inf scale propagation (HIGH) — division propagates NaN
//! 7. Auth tag missing num_primes (HIGH) — mod-switch without invalidation
//! 8. rns_ct_add_plain_simd (fhe_layer) NaN/Inf bias (MEDIUM) — bias corruption

#![cfg(feature = "ckks")]

use poly_client::ckks::rns::RnsPoly;
use poly_client::ckks::rns_ckks::*;
use poly_client::ckks::rns_fhe_layer;
use poly_client::ckks::simd;
use rand::rngs::StdRng;
use rand::SeedableRng;

fn test_rng() -> StdRng {
    StdRng::seed_from_u64(0x0700_DEAD)
}

/// Helper: create a keyset with the given number of primes.
fn setup(num_primes: usize) -> (RnsCkksContext, RnsPoly, RnsPoly, RnsPoly) {
    let ctx = RnsCkksContext::new(num_primes);
    let mut rng = test_rng();
    let (s, pk_b, pk_a) = rns_keygen(&ctx, &mut rng);
    (ctx, s, pk_b, pk_a)
}

// ═══════════════════════════════════════════════════════════════════════
// 1. WIDE_SUB LENGTH MISMATCH (CRITICAL) — Fixed in R7
// ═══════════════════════════════════════════════════════════════════════
//
// wide_sub(a, b) used `let n = a.len()` which silently drops higher limbs
// of b when b is longer than a. This occurs during CRT reconstruction in
// garner_reconstruct_wide when wide_mul_u64 extends one operand via carry.
//
// Attack scenario: With many primes (e.g., 15+), CRT products become very
// large. The subtraction `q_total - result` may have `result` with more
// limbs than `q_total` due to intermediate carry propagation in wide_mul_u64.
// The truncated subtraction produces a wrong centered coefficient, which
// means the decrypted value is completely corrupted — a data integrity failure.

/// Encrypt with 15 primes and verify wide_sub correctness through full pipeline.
/// Before R7: wide_sub truncation could corrupt CRT reconstruction with many primes.
#[test]
fn r7_wide_sub_correctness_15_primes() {
    let (ctx, s, pk_b, pk_a) = setup(15);
    let mut rng = test_rng();

    let values: Vec<f64> = (0..32).map(|i| (i as f64) * 100.0 - 1500.0).collect();
    let ct = rns_encrypt_simd(&values, &pk_b, &pk_a, &ctx, &mut rng);
    let dec = rns_decrypt_simd(&ct, &s, &ctx, 32);

    for i in 0..32 {
        let err = (dec[i] - values[i]).abs();
        assert!(
            err < 1.0,
            "wide_sub 15-prime CRT: slot {} expected {}, got {} (err={})",
            i, values[i], dec[i], err
        );
    }
}

/// Encrypt with 20 primes and multiply — maximally stresses wide_sub in
/// the relinearization/CRT path where digit decomposition produces large intermediates.
#[test]
fn r7_wide_sub_mul_relin_20_primes() {
    let (ctx, s, pk_b, pk_a) = setup(20);
    let mut rng = test_rng();
    let evk = rns_gen_eval_key(&s, &ctx, &mut rng);

    let a_vals = vec![5.0; simd::NUM_SLOTS];
    let b_vals = vec![3.0; simd::NUM_SLOTS];
    let ct_a = rns_encrypt_simd(&a_vals, &pk_b, &pk_a, &ctx, &mut rng);
    let ct_b = rns_encrypt_simd(&b_vals, &pk_b, &pk_a, &ctx, &mut rng);

    let triple = rns_ct_mul(&ct_a, &ct_b, &ctx);
    let ct_mul = rns_relinearize(triple, &evk, &ctx);
    let ct_res = rns_rescale(&ct_mul);

    let dec = rns_decrypt_simd(&ct_res, &s, &ctx, 4);
    for i in 0..4 {
        let err = (dec[i] - 15.0).abs();
        assert!(
            err < 1.0,
            "wide_sub 20-prime mul: slot {} expected 15.0, got {} (err={})",
            i, dec[i], err
        );
    }
}

/// Deep circuit with 18 primes — chains 4 multiplications to repeatedly exercise
/// the wide_sub path in CRT reconstruction after each rescale.
#[test]
fn r7_wide_sub_deep_circuit_18_primes() {
    let (ctx, s, pk_b, pk_a) = setup(18);
    let mut rng = test_rng();
    let evk = rns_gen_eval_key(&s, &ctx, &mut rng);

    // Start with 2.0, square 4 times: 2 -> 4 -> 16 -> 256 -> 65536
    let vals = vec![2.0; simd::NUM_SLOTS];
    let mut ct = rns_encrypt_simd(&vals, &pk_b, &pk_a, &ctx, &mut rng);

    for _round in 0..4 {
        let triple = rns_ct_mul(&ct, &ct, &ctx);
        ct = rns_relinearize(triple, &evk, &ctx);
        ct = rns_rescale(&ct);
    }

    let dec = rns_decrypt_simd(&ct, &s, &ctx, 4);
    for i in 0..4 {
        let err = (dec[i] - 65536.0).abs();
        assert!(
            err < 50.0,
            "deep circuit 18-prime: slot {} expected 65536.0, got {} (err={})",
            i, dec[i], err
        );
    }
}

// ═══════════════════════════════════════════════════════════════════════
// 2. WIDE_GT ASYMMETRIC LENGTH (MEDIUM) — Fixed in R7
// ═══════════════════════════════════════════════════════════════════════
//
// wide_gt(a, b) used `let n = a.len()` — if b has higher non-zero limbs
// than a, they were ignored, making wide_gt return true when b > a.
// This is used in garner_reconstruct_wide for centering: if result > q/2,
// subtract q. With wide_gt wrong, centering can be wrong → wrong sign
// on the decoded coefficient.

/// Test that wide_gt correctness is maintained through encrypt/decrypt
/// with negative values (which exercise the centering path).
#[test]
fn r7_wide_gt_negative_values_centering() {
    let (ctx, s, pk_b, pk_a) = setup(15);
    let mut rng = test_rng();

    // Use negative values to force centering (result > q/2 → subtract q)
    let values: Vec<f64> = (0..16).map(|i| -(i as f64) * 500.0).collect();
    let ct = rns_encrypt_simd(&values, &pk_b, &pk_a, &ctx, &mut rng);
    let dec = rns_decrypt_simd(&ct, &s, &ctx, 16);

    for i in 0..16 {
        let err = (dec[i] - values[i]).abs();
        assert!(
            err < 1.0,
            "wide_gt centering: slot {} expected {}, got {} (err={})",
            i, values[i], dec[i], err
        );
    }
}

// ═══════════════════════════════════════════════════════════════════════
// 3. rns_ct_mul_plain_simd NaN/Inf BYPASS (HIGH) — Fixed in R7
// ═══════════════════════════════════════════════════════════════════════
//
// rns_ct_mul_plain_simd accepted arbitrary f64 values without validation.
// Unlike rns_encrypt_simd (fixed in R6), this function had no NaN/Inf check.
// An attacker supplying NaN weights in a neural network forward pass could
// silently corrupt all encrypted data flowing through that layer.

/// Attack: Pass NaN in plaintext values to rns_ct_mul_plain_simd.
#[test]
#[should_panic(expected = "all values must be finite")]
fn r7_attack_mul_plain_simd_nan() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_simd(&[1.0, 2.0, 3.0], &pk_b, &pk_a, &ctx, &mut rng);
    let bad_weights = vec![1.0, f64::NAN, 1.0];
    let _corrupted = rns_ct_mul_plain_simd(&ct, &bad_weights, &ctx);
}

/// Attack: Pass Infinity in plaintext values.
#[test]
#[should_panic(expected = "all values must be finite")]
fn r7_attack_mul_plain_simd_infinity() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_simd(&[1.0], &pk_b, &pk_a, &ctx, &mut rng);
    let bad_weights = vec![f64::INFINITY];
    let _corrupted = rns_ct_mul_plain_simd(&ct, &bad_weights, &ctx);
}

/// Attack: Pass negative infinity in plaintext values.
#[test]
#[should_panic(expected = "all values must be finite")]
fn r7_attack_mul_plain_simd_neg_infinity() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_simd(&[1.0], &pk_b, &pk_a, &ctx, &mut rng);
    let bad_weights = vec![f64::NEG_INFINITY];
    let _corrupted = rns_ct_mul_plain_simd(&ct, &bad_weights, &ctx);
}

/// Verify mul_plain_simd works correctly for valid values.
#[test]
fn r7_mul_plain_simd_valid() {
    let (ctx, s, pk_b, pk_a) = setup(4);
    let mut rng = test_rng();
    let ct = rns_encrypt_simd(&[10.0, 20.0, 30.0, 40.0], &pk_b, &pk_a, &ctx, &mut rng);
    let weights = vec![2.0, 0.5, -1.0, 3.0];
    let ct_mul = rns_ct_mul_plain_simd(&ct, &weights, &ctx);
    let ct_res = rns_rescale(&ct_mul);
    let dec = rns_decrypt_simd(&ct_res, &s, &ctx, 4);
    let expected = [20.0, 10.0, -30.0, 120.0];
    for i in 0..4 {
        let err = (dec[i] - expected[i]).abs();
        assert!(
            err < 2.0,
            "mul_plain_simd: slot {} expected {}, got {} (err={})",
            i, expected[i], dec[i], err
        );
    }
}

// ═══════════════════════════════════════════════════════════════════════
// 4. rns_ct_add NaN/Inf SCALE BYPASS (HIGH) — Fixed in R7
// ═══════════════════════════════════════════════════════════════════════
//
// rns_ct_add used `assert_eq!(a.scale, b.scale, "scale mismatch")`.
// For NaN: NaN != NaN → always panics. But for Infinity:
// Inf == Inf → true! This means two ciphertexts with Infinity scale
// pass the check, and the output has scale=Infinity which corrupts
// all downstream operations (rescale, add_plain, etc.).
// Additionally, -0.0 == 0.0 in f64, and scale=0 breaks rescaling.

/// Attack: Craft two ciphertexts with Infinity scale and add them.
/// Before R7: Inf == Inf passed assert_eq, corrupting the result.
#[test]
#[should_panic(expected = "scale must be finite and positive")]
fn r7_attack_ct_add_infinity_scale() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_f64(1.0, &pk_b, &pk_a, &ctx, &mut rng);

    let ct_inf_a = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: f64::INFINITY,
        level: ct.level,
        auth_tag: None,
    };
    let ct_inf_b = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: f64::INFINITY,
        level: ct.level,
        auth_tag: None,
    };

    // Before R7: This would succeed (Inf == Inf) and propagate Inf scale
    let _corrupted = rns_ct_add(&ct_inf_a, &ct_inf_b);
}

/// Attack: NaN scale on rns_ct_add.
#[test]
#[should_panic(expected = "scale must be finite and positive")]
fn r7_attack_ct_add_nan_scale() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_f64(1.0, &pk_b, &pk_a, &ctx, &mut rng);

    let ct_nan = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: f64::NAN,
        level: ct.level,
        auth_tag: None,
    };

    let _corrupted = rns_ct_add(&ct_nan, &ct);
}

/// Attack: Zero scale on rns_ct_add (0.0 == 0.0 passes assert_eq).
#[test]
#[should_panic(expected = "scale must be finite and positive")]
fn r7_attack_ct_add_zero_scale() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_f64(1.0, &pk_b, &pk_a, &ctx, &mut rng);

    let ct_zero_a = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: 0.0,
        level: ct.level,
        auth_tag: None,
    };
    let ct_zero_b = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: 0.0,
        level: ct.level,
        auth_tag: None,
    };

    let _corrupted = rns_ct_add(&ct_zero_a, &ct_zero_b);
}

/// Attack: Negative scale on rns_ct_add.
#[test]
#[should_panic(expected = "scale must be finite and positive")]
fn r7_attack_ct_add_negative_scale() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_f64(1.0, &pk_b, &pk_a, &ctx, &mut rng);

    let ct_neg = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: -1.0,
        level: ct.level,
        auth_tag: None,
    };

    let _corrupted = rns_ct_add(&ct_neg, &ct_neg);
}

// ═══════════════════════════════════════════════════════════════════════
// 5. rns_ct_sub NaN/Inf SCALE BYPASS (HIGH) — Fixed in R7
// ═══════════════════════════════════════════════════════════════════════

/// Attack: Infinity scale on rns_ct_sub.
#[test]
#[should_panic(expected = "scale must be finite and positive")]
fn r7_attack_ct_sub_infinity_scale() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_f64(1.0, &pk_b, &pk_a, &ctx, &mut rng);

    let ct_inf = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: f64::INFINITY,
        level: ct.level,
        auth_tag: None,
    };

    let _corrupted = rns_ct_sub(&ct_inf, &ct_inf);
}

/// Attack: NaN scale on rns_ct_sub.
#[test]
#[should_panic(expected = "scale must be finite and positive")]
fn r7_attack_ct_sub_nan_scale() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_f64(1.0, &pk_b, &pk_a, &ctx, &mut rng);

    let ct_nan = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: f64::NAN,
        level: ct.level,
        auth_tag: None,
    };

    let _corrupted = rns_ct_sub(&ct, &ct_nan);
}

// ═══════════════════════════════════════════════════════════════════════
// 6. rns_rescale NaN/Inf SCALE PROPAGATION (HIGH) — Fixed in R7
// ═══════════════════════════════════════════════════════════════════════
//
// rns_rescale divides ct.scale by q_last. If ct.scale is NaN, Inf, or
// negative, the division produces NaN or nonsensical results that
// propagate silently through all downstream operations.

/// Attack: Rescale a ciphertext with NaN scale.
#[test]
#[should_panic(expected = "scale must be finite and positive")]
fn r7_attack_rescale_nan_scale() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_f64(1.0, &pk_b, &pk_a, &ctx, &mut rng);

    let ct_nan = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: f64::NAN,
        level: ct.level,
        auth_tag: None,
    };

    let _corrupted = rns_rescale(&ct_nan);
}

/// Attack: Rescale a ciphertext with Infinity scale.
#[test]
#[should_panic(expected = "scale must be finite and positive")]
fn r7_attack_rescale_infinity_scale() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_f64(1.0, &pk_b, &pk_a, &ctx, &mut rng);

    let ct_inf = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: f64::INFINITY,
        level: ct.level,
        auth_tag: None,
    };

    let _corrupted = rns_rescale(&ct_inf);
}

/// Attack: Rescale a ciphertext with negative scale.
#[test]
#[should_panic(expected = "scale must be finite and positive")]
fn r7_attack_rescale_negative_scale() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_f64(1.0, &pk_b, &pk_a, &ctx, &mut rng);

    let ct_neg = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: -42.0,
        level: ct.level,
        auth_tag: None,
    };

    let _corrupted = rns_rescale(&ct_neg);
}

/// Attack: Rescale a ciphertext with zero scale.
#[test]
#[should_panic(expected = "scale must be finite and positive")]
fn r7_attack_rescale_zero_scale() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_f64(1.0, &pk_b, &pk_a, &ctx, &mut rng);

    let ct_zero = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: 0.0,
        level: ct.level,
        auth_tag: None,
    };

    let _corrupted = rns_rescale(&ct_zero);
}

// ═══════════════════════════════════════════════════════════════════════
// 7. AUTH TAG MISSING num_primes (HIGH) — Fixed in R7
// ═══════════════════════════════════════════════════════════════════════
//
// The HMAC-SHA256 authentication tag in compute_auth_tag hashed:
//   - domain separator "rns_ckks_auth_v1"
//   - scale (f64)
//   - level (u64)
//   - c0 coefficients
//   - c1 coefficients
//
// But NOT num_primes. This means an attacker could:
//   1. Intercept a ciphertext with 10 primes and valid auth tag
//   2. Call rns_ct_mod_switch_to to drop to 5 primes
//   3. The remaining coefficients are identical → same MAC input
//   4. BUT the ciphertext now decrypts to a different value
//      (different modulus chain changes decryption semantics)
//
// R7 fix adds num_primes to the hash and updates domain separator to v2.

/// Attack: Mod-switch a ciphertext and verify the auth tag is now invalid.
/// Before R7: The auth tag would still verify after mod-switching because
/// num_primes was not included in the hash.
#[test]
fn r7_attack_auth_tag_mod_switch_forgery() {
    let (ctx, _s, pk_b, pk_a) = setup(6);
    let mut rng = test_rng();

    let mac_key = [0xABu8; 32];
    let ct = rns_encrypt_f64(42.0, &pk_b, &pk_a, &ctx, &mut rng);

    // Set auth tag
    let mut ct_authed = ct.clone();
    ct_authed.auth_tag = Some(ct_authed.compute_auth_tag(&mac_key));
    assert!(ct_authed.verify_auth(&mac_key), "auth should verify on original");

    // Mod-switch to fewer primes (attacker operation)
    let ct_switched = rns_ct_mod_switch_to(&ct_authed, 3);

    // Reuse the original auth tag on the mod-switched ciphertext
    let mut ct_forged = ct_switched;
    ct_forged.auth_tag = ct_authed.auth_tag;

    // Before R7: This would pass (num_primes not in hash).
    // After R7: This MUST fail because num_primes is now included.
    assert!(
        !ct_forged.verify_auth(&mac_key),
        "FORGERY: auth tag should NOT verify after mod-switch (num_primes changed)"
    );
}

/// Verify that auth tag correctly validates when nothing is changed.
#[test]
fn r7_auth_tag_valid_roundtrip() {
    let (ctx, _s, pk_b, pk_a) = setup(4);
    let mut rng = test_rng();

    let mac_key = [0xCDu8; 32];
    let ct = rns_encrypt_f64(123.0, &pk_b, &pk_a, &ctx, &mut rng);

    let mut ct_authed = ct.clone();
    ct_authed.auth_tag = Some(ct_authed.compute_auth_tag(&mac_key));
    assert!(ct_authed.verify_auth(&mac_key), "auth should verify");
}

/// Verify that the v1 to v2 domain separator change invalidates old tags.
/// This ensures that ciphertexts tagged with the old (vulnerable) format
/// cannot pass verification under the new format.
#[test]
fn r7_auth_tag_domain_separator_change() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();

    let mac_key = [0xEFu8; 32];
    let ct = rns_encrypt_f64(1.0, &pk_b, &pk_a, &ctx, &mut rng);

    // Manually compute a tag using the OLD v1 domain separator
    use hmac::{Hmac, Mac};
    use sha2::Sha256;
    let mut mac = Hmac::<Sha256>::new_from_slice(&mac_key).unwrap();
    mac.update(b"rns_ckks_auth_v1"); // OLD domain separator
    mac.update(&ct.scale.to_le_bytes());
    mac.update(&(ct.level as u64).to_le_bytes());
    for ch in &ct.c0.residues {
        for &coeff in ch {
            mac.update(&coeff.to_le_bytes());
        }
    }
    for ch in &ct.c1.residues {
        for &coeff in ch {
            mac.update(&coeff.to_le_bytes());
        }
    }
    let old_tag: [u8; 32] = mac.finalize().into_bytes().into();

    // Set the old-format tag on the ciphertext
    let mut ct_old = ct.clone();
    ct_old.auth_tag = Some(old_tag);

    // The v1 tag must NOT verify under the new v2 computation
    assert!(
        !ct_old.verify_auth(&mac_key),
        "OLD v1 auth tag should NOT verify under new v2 domain separator"
    );
}

// ═══════════════════════════════════════════════════════════════════════
// 8. rns_ct_add_plain_simd (fhe_layer) NaN/Inf BIAS (MEDIUM) — Fixed in R7
// ═══════════════════════════════════════════════════════════════════════
//
// rns_fhe_layer::rns_ct_add_plain_simd encodes bias values into a plaintext
// polynomial. If bias values contain NaN/Inf, the encoding produces garbage
// coefficients that silently corrupt the ciphertext — and since this is in
// the neural network inference path, all subsequent layers see corrupted data.

/// Attack: Pass NaN bias to rns_ct_add_plain_simd in the FHE layer.
#[test]
#[should_panic(expected = "all bias values must be finite")]
fn r7_attack_fhe_layer_add_plain_nan_bias() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_simd(&[1.0, 2.0, 3.0], &pk_b, &pk_a, &ctx, &mut rng);
    let bad_bias = vec![1.0, f64::NAN, 3.0];
    let _corrupted = rns_fhe_layer::rns_ct_add_plain_simd(&ct, &bad_bias, 3);
}

/// Attack: Pass Infinity bias.
#[test]
#[should_panic(expected = "all bias values must be finite")]
fn r7_attack_fhe_layer_add_plain_inf_bias() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_simd(&[1.0], &pk_b, &pk_a, &ctx, &mut rng);
    let bad_bias = vec![f64::INFINITY];
    let _corrupted = rns_fhe_layer::rns_ct_add_plain_simd(&ct, &bad_bias, 1);
}

/// Attack: Ciphertext with NaN scale passed to rns_ct_add_plain_simd.
#[test]
#[should_panic(expected = "ct.scale must be finite and positive")]
fn r7_attack_fhe_layer_add_plain_nan_ct_scale() {
    let (ctx, _s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_simd(&[1.0], &pk_b, &pk_a, &ctx, &mut rng);

    let ct_nan = RnsCiphertext {
        c0: ct.c0.clone(),
        c1: ct.c1.clone(),
        scale: f64::NAN,
        level: ct.level,
        auth_tag: None,
    };

    let _corrupted = rns_fhe_layer::rns_ct_add_plain_simd(&ct_nan, &[1.0], 1);
}

/// Verify rns_ct_add_plain_simd works correctly for valid inputs.
#[test]
fn r7_fhe_layer_add_plain_valid() {
    let (ctx, s, pk_b, pk_a) = setup(3);
    let mut rng = test_rng();
    let ct = rns_encrypt_simd(&[10.0, 20.0, 30.0], &pk_b, &pk_a, &ctx, &mut rng);
    let biases = vec![5.0, -3.0, 7.0];
    let ct_res = rns_fhe_layer::rns_ct_add_plain_simd(&ct, &biases, 3);
    let dec = rns_decrypt_simd(&ct_res, &s, &ctx, 3);
    let expected = [15.0, 17.0, 37.0];
    for i in 0..3 {
        let err = (dec[i] - expected[i]).abs();
        assert!(
            err < 1.0,
            "fhe_layer add_plain_simd: slot {} expected {}, got {} (err={})",
            i, expected[i], dec[i], err
        );
    }
}

// ═══════════════════════════════════════════════════════════════════════
// 9. COMBINED ATTACK SCENARIOS
// ═══════════════════════════════════════════════════════════════════════

/// Full pipeline correctness test: encrypt -> mul_plain -> rescale -> add -> decrypt.
/// Exercises the fixed rns_ct_mul_plain_simd, rns_rescale, and rns_ct_add paths.
#[test]
fn r7_full_pipeline_mul_plain_rescale_add() {
    let (ctx, s, pk_b, pk_a) = setup(6);
    let mut rng = test_rng();

    let data = vec![10.0, 20.0, 30.0, 40.0];
    let weights = vec![2.0, 0.5, 3.0, -1.0];
    let ct = rns_encrypt_simd(&data, &pk_b, &pk_a, &ctx, &mut rng);

    // Multiply by plaintext weights
    let ct_mul = rns_ct_mul_plain_simd(&ct, &weights, &ctx);
    let ct_resc = rns_rescale(&ct_mul);

    // Add two copies
    let ct_sum = rns_ct_add(&ct_resc, &ct_resc);
    let dec = rns_decrypt_simd(&ct_sum, &s, &ctx, 4);

    // Expected: 2 * (data[i] * weights[i]) = [40.0, 20.0, 180.0, -80.0]
    let expected = [40.0, 20.0, 180.0, -80.0];
    for i in 0..4 {
        let err = (dec[i] - expected[i]).abs();
        assert!(
            err < 5.0,
            "full pipeline: slot {} expected {}, got {} (err={})",
            i, expected[i], dec[i], err
        );
    }
}

/// Subtraction correctness after R7 scale validation fix.
#[test]
fn r7_ct_sub_correctness() {
    let (ctx, s, pk_b, pk_a) = setup(4);
    let mut rng = test_rng();

    let a_vals = vec![100.0, 200.0, 300.0, 400.0];
    let b_vals = vec![30.0, 50.0, 70.0, 90.0];
    let ct_a = rns_encrypt_simd(&a_vals, &pk_b, &pk_a, &ctx, &mut rng);
    let ct_b = rns_encrypt_simd(&b_vals, &pk_b, &pk_a, &ctx, &mut rng);

    let ct_sub = rns_ct_sub(&ct_a, &ct_b);
    let dec = rns_decrypt_simd(&ct_sub, &s, &ctx, 4);

    let expected = [70.0, 150.0, 230.0, 310.0];
    for i in 0..4 {
        let err = (dec[i] - expected[i]).abs();
        assert!(
            err < 1.0,
            "ct_sub: slot {} expected {}, got {} (err={})",
            i, expected[i], dec[i], err
        );
    }
}

/// Auth tag integrity across full pipeline (encrypt -> mul -> relin -> rescale -> tag).
/// Verifies that auth tagging works correctly with the new v2 format including num_primes.
#[test]
fn r7_auth_tag_full_pipeline_integrity() {
    let (ctx, s, pk_b, pk_a) = setup(6);
    let mut rng = test_rng();
    let evk = rns_gen_eval_key(&s, &ctx, &mut rng);

    let mac_key = [0x42u8; 32];
    let vals = vec![7.0; simd::NUM_SLOTS];
    let ct = rns_encrypt_simd(&vals, &pk_b, &pk_a, &ctx, &mut rng);

    // Full pipeline
    let triple = rns_ct_mul(&ct, &ct, &ctx);
    let ct_relin = rns_relinearize(triple, &evk, &ctx);
    let ct_resc = rns_rescale(&ct_relin);

    // Tag the result
    let mut ct_tagged = ct_resc.clone();
    ct_tagged.auth_tag = Some(ct_tagged.compute_auth_tag(&mac_key));
    assert!(ct_tagged.verify_auth(&mac_key), "pipeline result auth should verify");

    // Tamper with one coefficient
    let mut ct_tampered = ct_tagged.clone();
    ct_tampered.c0.residues[0][0] ^= 1;
    assert!(
        !ct_tampered.verify_auth(&mac_key),
        "tampered ciphertext should NOT verify"
    );
}
