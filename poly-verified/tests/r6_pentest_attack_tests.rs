//! Round 6 Pentest Attack Tests for poly-verified.
//!
//! Findings:
//! V6-01 CRITICAL: FixedPoint Add/Sub/Mul/Div panic on overflow (adversarial DoS)
//! V6-02 CRITICAL: FixedPoint::abs() panics on i128::MIN
//! V6-03 HIGH:     FixedPoint Neg panics on i128::MIN
//! V6-04 HIGH:     CompositeProof::compute_composition_hash silently swallows serialization errors
//! V6-05 HIGH:     MerkleProof::to_bytes silently truncates sibling count > u32::MAX
//! V6-06 HIGH:     VerifiedResponse::to_bytes silently truncates proof length > u32::MAX
//! V6-07 MEDIUM:   verify_disclosure accepts empty (0-token) disclosures
//! V6-08 MEDIUM:   Commitment::PartialEq uses non-constant-time u64 comparison
//! V6-09 MEDIUM:   VerifiedProof derives Deserialize -- attacker can forge Disclosure via JSON
//! V6-10 MEDIUM:   HashChain length counter has no overflow protection (u64 wraps)
//! V6-11 LOW:      from_bytes methods silently accept trailing garbage bytes
//! V6-12 LOW:      Verified::map allows proof-value decoupling after transformation

use sha2::{Digest, Sha256};

use poly_verified::crypto::hash::hash_data;
use poly_verified::crypto::merkle::MerkleTree;
use poly_verified::disclosure::{create_disclosure, verify_disclosure, Disclosure};
use poly_verified::fixed_point::FixedPoint;
use poly_verified::ivc::hash_ivc::HashIvc;
use poly_verified::ivc::IvcBackend;
use poly_verified::proof_composition::CompositeProof;
use poly_verified::proof_serialize::VerifiedResponse;
use poly_verified::types::{
    hash_eq, Commitment, Hash, MerkleProof, PrivacyMode, ProofNode, SignedCommitment,
    StepWitness, VerifiedProof, ZERO_HASH, CodeAttestation,
};
use poly_verified::verified_type::Verified;

// ========================================================================
// Helpers
// ========================================================================

fn tokens_hash(tokens: &[u32]) -> Hash {
    let mut hasher = Sha256::new();
    for &t in tokens {
        hasher.update(t.to_le_bytes());
    }
    hasher.finalize().into()
}

fn valid_hash_ivc_proof_for_tokens(tokens: &[u32]) -> VerifiedProof {
    let ivc = HashIvc;
    let code_hash = [0x03; 32];
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    acc.input_hash = ZERO_HASH;
    acc.output_hash = tokens_hash(tokens);
    ivc.finalize(acc).unwrap()
}

fn make_verified(tokens: Vec<u32>) -> Verified<Vec<u32>> {
    let proof = valid_hash_ivc_proof_for_tokens(&tokens);
    Verified::__macro_new(tokens, proof)
}

// ========================================================================
// V6-01 CRITICAL (FIXED): FixedPoint Add/Sub/Mul overflow panics
// ========================================================================
//
// Previously, FixedPoint's Add, Sub, Mul trait impls used raw i128 +, -, *
// which panic in debug builds on overflow. An attacker providing extreme
// input values to any verified computation using FixedPoint could crash
// the prover or verifier.
//
// FIX: All operators now use saturating arithmetic.

#[test]
fn fix_v6_01a_add_overflow_saturates() {
    let max = FixedPoint::from_raw(i128::MAX);
    let one = FixedPoint::from_int(1);
    // Previously this would panic in debug mode.
    // Now it saturates to i128::MAX.
    let result = max + one;
    assert_eq!(result.raw(), i128::MAX, "Add should saturate at i128::MAX");
}

#[test]
fn fix_v6_01b_add_underflow_saturates() {
    let min = FixedPoint::from_raw(i128::MIN);
    let neg_one = FixedPoint::from_int(-1);
    // Previously this would panic.
    let result = min + neg_one;
    assert_eq!(result.raw(), i128::MIN, "Add should saturate at i128::MIN");
}

#[test]
fn fix_v6_01c_sub_overflow_saturates() {
    let max = FixedPoint::from_raw(i128::MAX);
    let neg_one = FixedPoint::from_int(-1);
    let result = max - neg_one;
    assert_eq!(result.raw(), i128::MAX, "Sub should saturate at i128::MAX");
}

#[test]
fn fix_v6_01d_sub_underflow_saturates() {
    let min = FixedPoint::from_raw(i128::MIN);
    let one = FixedPoint::from_int(1);
    let result = min - one;
    assert_eq!(result.raw(), i128::MIN, "Sub should saturate at i128::MIN");
}

#[test]
fn fix_v6_01e_mul_overflow_saturates() {
    let big = FixedPoint::from_raw(i128::MAX / 2);
    let three = FixedPoint::from_int(3);
    // i128::MAX/2 * 3 overflows i128 before division by SCALE.
    // Previously panicked. Now saturates.
    let result = big * three;
    assert_eq!(result.raw(), i128::MAX, "Mul overflow should saturate to MAX");
}

#[test]
fn fix_v6_01f_mul_negative_overflow_saturates() {
    let big = FixedPoint::from_raw(i128::MAX / 2);
    let neg_three = FixedPoint::from_int(-3);
    let result = big * neg_three;
    assert_eq!(result.raw(), i128::MIN, "Mul negative overflow should saturate to MIN");
}

#[test]
fn fix_v6_01g_div_overflow_saturates() {
    // When self is large and rhs is fractional (< 1), self * SCALE overflows.
    let big = FixedPoint::from_raw(i128::MAX);
    let half = FixedPoint::from_raw(FixedPoint::SCALE / 2); // 0.5
    // big / 0.5 = big * 2, which overflows.
    let result = big / half;
    assert_eq!(result.raw(), i128::MAX, "Div overflow should saturate to MAX");
}

#[test]
fn fix_v6_01h_normal_arithmetic_unaffected() {
    // Verify the fix doesn't break normal arithmetic.
    let a = FixedPoint::from_int(3);
    let b = FixedPoint::from_int(7);
    assert_eq!((a + b).to_i64(), 10);
    assert_eq!((b - a).to_i64(), 4);
    assert_eq!((a * b).to_i64(), 21);
    assert_eq!((b / a).to_i64(), 2);
}

// ========================================================================
// V6-02 CRITICAL (FIXED): FixedPoint::abs() panics on i128::MIN
// ========================================================================
//
// i128::MIN.abs() panics because |i128::MIN| > i128::MAX.
// FIX: Use saturating_abs() which returns i128::MAX for i128::MIN.

#[test]
fn fix_v6_02_abs_i128_min_no_panic() {
    let min = FixedPoint::from_raw(i128::MIN);
    // Previously: panic on abs()
    // Now: saturates to i128::MAX
    let result = min.abs();
    assert_eq!(result.raw(), i128::MAX, "abs(i128::MIN) should saturate to i128::MAX");
}

#[test]
fn fix_v6_02b_abs_normal_values_unaffected() {
    let neg = FixedPoint::from_int(-42);
    assert_eq!(neg.abs().to_i64(), 42);
    let pos = FixedPoint::from_int(42);
    assert_eq!(pos.abs().to_i64(), 42);
    assert_eq!(FixedPoint::ZERO.abs().raw(), 0);
}

// ========================================================================
// V6-03 HIGH (FIXED): FixedPoint Neg panics on i128::MIN
// ========================================================================
//
// -i128::MIN panics because the result doesn't fit in i128.
// FIX: Use saturating_neg() which returns i128::MAX for i128::MIN.

#[test]
fn fix_v6_03_neg_i128_min_no_panic() {
    let min = FixedPoint::from_raw(i128::MIN);
    // Previously: panic on negation
    // Now: saturates to i128::MAX
    let result = -min;
    assert_eq!(result.raw(), i128::MAX, "neg(i128::MIN) should saturate to i128::MAX");
}

#[test]
fn fix_v6_03b_neg_normal_values_unaffected() {
    let pos = FixedPoint::from_int(42);
    assert_eq!((-pos).to_i64(), -42);
    let neg = FixedPoint::from_int(-42);
    assert_eq!((-neg).to_i64(), 42);
}

// ========================================================================
// V6-04 HIGH (FIXED): CompositeProof silently swallows serialization errors
// ========================================================================
//
// compute_composition_hash used unwrap_or_default() for serde_json::to_vec.
// If serialization failed, it would produce empty bytes, meaning two
// different invalid proofs would hash identically -- enabling composition
// hash collisions.
//
// FIX: Changed to expect() with a clear error message. Serialization of
// VerifiedProof should never fail (it derives Serialize with no custom impl).

#[test]
fn fix_v6_04_composition_hash_is_unique_per_proof() {
    // Two different proofs must produce different composition hashes.
    let proof_a = VerifiedProof::Mock {
        input_hash: [0x01; 32],
        output_hash: [0x02; 32],
        privacy_mode: PrivacyMode::Transparent,
    };
    let proof_b = VerifiedProof::Mock {
        input_hash: [0x03; 32],
        output_hash: [0x04; 32],
        privacy_mode: PrivacyMode::Transparent,
    };

    let comp_a = CompositeProof::compose(proof_a, vec![]);
    let comp_b = CompositeProof::compose(proof_b, vec![]);

    assert_ne!(
        comp_a.composition_hash, comp_b.composition_hash,
        "Different proofs must produce different composition hashes"
    );
    assert!(comp_a.verify_composition());
    assert!(comp_b.verify_composition());
}

#[test]
fn fix_v6_04b_composition_with_inner_proofs_unique() {
    let outer = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let inner_a = VerifiedProof::Mock {
        input_hash: [0x01; 32],
        output_hash: [0x02; 32],
        privacy_mode: PrivacyMode::Transparent,
    };
    let inner_b = VerifiedProof::Mock {
        input_hash: [0x03; 32],
        output_hash: [0x04; 32],
        privacy_mode: PrivacyMode::Transparent,
    };

    let comp_with_a = CompositeProof::compose(outer.clone(), vec![inner_a]);
    let comp_with_b = CompositeProof::compose(outer.clone(), vec![inner_b]);
    let comp_empty = CompositeProof::compose(outer, vec![]);

    assert_ne!(comp_with_a.composition_hash, comp_with_b.composition_hash);
    assert_ne!(comp_with_a.composition_hash, comp_empty.composition_hash);
}

// ========================================================================
// V6-05 HIGH (FIXED): MerkleProof::to_bytes truncation guard
// ========================================================================
//
// If siblings.len() somehow exceeded 64 (the max allowed by from_bytes),
// to_bytes would silently truncate the count to u32.
// FIX: Added assertion in to_bytes that sibling count <= 64.

#[test]
fn fix_v6_05_to_bytes_respects_sibling_limit() {
    // Normal case: should work fine.
    let leaves: Vec<Hash> = (0..4u8).map(|i| hash_data(&[i])).collect();
    let tree = MerkleTree::build(&leaves);
    let proof = tree.generate_proof(2, &ZERO_HASH).unwrap();
    let bytes = proof.to_bytes();
    let decoded = MerkleProof::from_bytes(&bytes).unwrap();
    assert_eq!(decoded.leaf, proof.leaf);
}

// ========================================================================
// V6-06 HIGH (FIXED): VerifiedResponse::to_bytes truncation guard
// ========================================================================
//
// proof_bytes.len() as u32 would silently truncate on large proofs.
// FIX: Added assertion. In practice, proofs are always < 4GB.

#[test]
fn fix_v6_06_verified_response_roundtrip() {
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let value_bytes = b"test value".to_vec();
    let response = VerifiedResponse::new(&proof, ZERO_HASH, value_bytes.clone(), ZERO_HASH);

    let bytes = response.to_bytes();
    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();
    assert_eq!(decoded.value_bytes, value_bytes);
    assert!(decoded.verify_value_integrity());
}

// ========================================================================
// V6-07 MEDIUM (FIXED): verify_disclosure accepts empty disclosures
// ========================================================================
//
// A disclosure with total_tokens=0 and an empty tokens vector was accepted
// by verify_disclosure, bypassing Merkle root checks (the `all_leaves.is_empty()`
// guard skipped reconstruction). Combined with a Mock proof, this created a
// vacuously valid disclosure that proved nothing.
//
// FIX: verify_disclosure now rejects disclosures with total_tokens == 0.

#[test]
fn fix_v6_07_empty_disclosure_rejected() {
    // Construct an empty disclosure directly (bypassing create_disclosure which
    // requires at least 1 token in the verified value).
    let empty_disclosure = Disclosure {
        tokens: vec![],
        proofs: vec![],
        output_root: ZERO_HASH,
        total_tokens: 0,
        execution_proof: VerifiedProof::Mock {
            input_hash: ZERO_HASH,
            output_hash: ZERO_HASH,
            privacy_mode: PrivacyMode::Transparent,
        },
        output_binding: ZERO_HASH,
    };

    assert!(
        !verify_disclosure(&empty_disclosure),
        "VULNERABILITY: empty disclosure (0 tokens) should be rejected"
    );
}

#[test]
fn fix_v6_07b_single_token_still_works() {
    let verified = make_verified(vec![42]);
    let disclosure = create_disclosure(&verified, &[0]).unwrap();
    assert!(verify_disclosure(&disclosure));
}

// ========================================================================
// V6-08 MEDIUM: Commitment::PartialEq non-constant-time u64 comparison
// ========================================================================
//
// The total_checkpoints field was compared with == which short-circuits.
// This leaks the field value through timing (e.g., 0 == 0 is faster than
// comparing two different values bit by bit).
//
// FIX: Changed to XOR-based comparison: (a ^ b) == 0.
// Also changed && to & to prevent short-circuit evaluation in the full
// expression (all four comparisons must always execute).

#[test]
fn fix_v6_08_commitment_equality_correct() {
    let c1 = Commitment {
        root: [0xAA; 32],
        total_checkpoints: 100,
        chain_tip: [0xBB; 32],
        code_hash: [0xCC; 32],
    };
    let c2 = c1.clone();
    assert_eq!(c1, c2, "Equal commitments should compare equal");

    let mut c3 = c1.clone();
    c3.total_checkpoints = 101;
    assert_ne!(c1, c3, "Different checkpoint counts should compare unequal");

    let mut c4 = c1.clone();
    c4.root[0] ^= 0xFF;
    assert_ne!(c1, c4, "Different roots should compare unequal");

    let mut c5 = c1.clone();
    c5.chain_tip[31] ^= 0x01;
    assert_ne!(c1, c5, "Single bit difference in chain_tip should be detected");
}

// ========================================================================
// V6-09 MEDIUM: VerifiedProof derives Deserialize -- Disclosure forgery
// ========================================================================
//
// Although Verified<T> no longer derives Deserialize (V5-01 fix), the
// Disclosure struct DOES derive Deserialize, and it contains a VerifiedProof
// which also derives Deserialize. An attacker can:
//   1. Get a legitimate Disclosure via the API
//   2. Modify the JSON (swap execution_proof, change tokens, etc.)
//   3. Deserialize back into a Disclosure
//   4. Call verify_disclosure() which may pass if internal consistency holds
//
// This is partially mitigated because verify_disclosure checks Merkle proofs
// and output binding. But it demonstrates that the trust boundary for
// Disclosure objects extends to deserialization.

#[test]
fn attack_v6_09_disclosure_deserialization_forgery() {
    let tokens = vec![100, 200, 300, 400];
    let verified = make_verified(tokens.clone());
    let disclosure = create_disclosure(&verified, &[0, 1]).unwrap();

    // Serialize the disclosure
    let json = serde_json::to_string(&disclosure).unwrap();

    // Deserialize back -- this works because Disclosure derives Deserialize
    let deserialized: Disclosure = serde_json::from_str(&json).unwrap();
    assert!(verify_disclosure(&deserialized), "Roundtrip should still verify");

    // Now tamper: change a revealed token in the JSON
    let tampered_json = json.replace("\"token_id\":100", "\"token_id\":9999");
    let tampered: Disclosure = serde_json::from_str(&tampered_json).unwrap();

    // The tampered disclosure should fail verification (leaf hash mismatch)
    assert!(
        !verify_disclosure(&tampered),
        "Tampered disclosure via JSON should fail verification"
    );
}

#[test]
fn attack_v6_09b_disclosure_proof_swap_via_json() {
    let tokens_a = vec![100, 200, 300, 400];
    let tokens_b = vec![500, 600, 700, 800];

    let verified_a = make_verified(tokens_a.clone());
    let verified_b = make_verified(tokens_b.clone());

    let disclosure_a = create_disclosure(&verified_a, &[0]).unwrap();
    let disclosure_b = create_disclosure(&verified_b, &[0]).unwrap();

    // Serialize both
    let json_a = serde_json::to_string(&disclosure_a).unwrap();
    let json_b = serde_json::to_string(&disclosure_b).unwrap();

    // Extract execution_proof from B
    let b_parsed: serde_json::Value = serde_json::from_str(&json_b).unwrap();
    let proof_b = b_parsed["execution_proof"].clone();

    // Inject B's proof into A's disclosure
    let mut a_parsed: serde_json::Value = serde_json::from_str(&json_a).unwrap();
    a_parsed["execution_proof"] = proof_b;

    let franken: Disclosure = serde_json::from_value(a_parsed).unwrap();

    // Should fail because output_binding (from tokens_a) won't match
    // the swapped proof's output_hash (from tokens_b)
    assert!(
        !verify_disclosure(&franken),
        "Frankenstein disclosure with swapped proof should fail"
    );
}

// ========================================================================
// V6-10 MEDIUM: HashChain length counter overflow
// ========================================================================
//
// HashChain::append increments self.length with +=1 which wraps at u64::MAX.
// While reaching u64::MAX appends is infeasible in practice, the lack of
// overflow checking means length could theoretically wrap to 0, which would
// make step_count=0 after u64::MAX+1 appends.
//
// This is a design note rather than a practical vulnerability, but we test
// the boundary behavior to document it.

#[test]
fn attack_v6_10_hash_chain_length_consistency() {
    use poly_verified::crypto::chain::HashChain;

    let mut chain = HashChain::new();
    assert_eq!(chain.length, 0);

    let h = hash_data(b"step");
    chain.append(&h);
    assert_eq!(chain.length, 1);

    chain.append(&h);
    assert_eq!(chain.length, 2);

    // The chain tip should change even though the same value is appended.
    let tip_at_2 = chain.tip;
    chain.append(&h);
    assert_ne!(chain.tip, tip_at_2);
    assert_eq!(chain.length, 3);
}

// ========================================================================
// V6-11 LOW: from_bytes methods accept trailing garbage bytes
// ========================================================================
//
// All from_bytes methods (Commitment, SignedCommitment, ProofNode,
// CodeAttestation) check minimum length but accept extra trailing bytes.
// An attacker can append arbitrary data after the valid payload without
// causing an error. This can be used to hide covert channels or bypass
// length-based filtering.

#[test]
fn attack_v6_11a_commitment_trailing_bytes() {
    let commitment = Commitment {
        root: [0xAA; 32],
        total_checkpoints: 5,
        chain_tip: [0xBB; 32],
        code_hash: [0xCC; 32],
    };
    let mut bytes = commitment.to_bytes().to_vec();

    // Append trailing garbage
    bytes.extend_from_slice(&[0xFF; 100]);

    // [V10-01 FIX] from_bytes now rejects trailing bytes (strict parsing).
    // Previously it accepted them (lax parsing with `<` instead of `!=`).
    assert!(
        Commitment::from_bytes(&bytes).is_err(),
        "Commitment should reject trailing bytes after V10-01 fix"
    );
}

#[test]
fn attack_v6_11b_signed_commitment_trailing_bytes() {
    let commitment = Commitment {
        root: [0xAA; 32],
        total_checkpoints: 5,
        chain_tip: [0xBB; 32],
        code_hash: [0xCC; 32],
    };
    let signed = SignedCommitment {
        commitment,
        signature: [0xDD; 64],
        public_key: [0xEE; 32],
    };
    let mut bytes = signed.to_bytes().to_vec();
    bytes.extend_from_slice(&[0xFF; 50]);

    // [V10-01 FIX] Now rejects trailing bytes.
    assert!(
        SignedCommitment::from_bytes(&bytes).is_err(),
        "SignedCommitment should reject trailing bytes after V10-01 fix"
    );
}

#[test]
fn attack_v6_11c_proof_node_trailing_bytes() {
    let node = ProofNode {
        hash: [0xAA; 32],
        is_left: true,
    };
    let mut bytes = node.to_bytes().to_vec();
    bytes.extend_from_slice(&[0xFF; 20]);

    // [V10-01 FIX] Now rejects trailing bytes.
    assert!(
        ProofNode::from_bytes(&bytes).is_err(),
        "ProofNode should reject trailing bytes after V10-01 fix"
    );
}

#[test]
fn attack_v6_11d_code_attestation_trailing_bytes() {
    let attestation = CodeAttestation {
        node_id: [0x01; 32],
        code_hash: [0x02; 32],
        circuit_id: 42,
        signature: [0x03; 64],
    };
    let mut bytes = attestation.to_bytes().to_vec();
    bytes.extend_from_slice(&[0xDE, 0xAD, 0xBE, 0xEF]);

    // [V10-01 FIX] Now rejects trailing bytes.
    assert!(
        CodeAttestation::from_bytes(&bytes).is_err(),
        "CodeAttestation should reject trailing bytes after V10-01 fix"
    );
}

// ========================================================================
// V6-12 LOW: Verified::map allows proof-value decoupling
// ========================================================================
//
// Verified::map(f) transforms the value but preserves the original proof.
// This means after mapping, the proof no longer corresponds to the actual
// value stored. While this is documented as intended behavior (the proof
// covers the original computation, not the transformation), it can be
// confusing and could lead to misuse where someone trusts the mapped value
// as if it were verified.

#[test]
fn attack_v6_12_map_decouples_proof_from_value() {
    let tokens = vec![100, 200, 300];
    let verified = make_verified(tokens.clone());

    // Map transforms the value but keeps the original proof
    let doubled = verified.map(|v| v.into_iter().map(|x| x * 2).collect::<Vec<_>>());

    // The value is now [200, 400, 600]
    assert_eq!(*doubled.value(), vec![200, 400, 600]);

    // But the proof still references the original output_hash for [100, 200, 300]
    match doubled.proof() {
        VerifiedProof::HashIvc { output_hash, .. } => {
            let original_hash = tokens_hash(&[100, 200, 300]);
            assert!(
                hash_eq(output_hash, &original_hash),
                "Proof still references original tokens, not mapped ones"
            );
            // The mapped tokens [200,400,600] have a different hash
            let mapped_hash = tokens_hash(&[200, 400, 600]);
            assert!(
                !hash_eq(output_hash, &mapped_hash),
                "Proof does NOT match the mapped values"
            );
        }
        _ => panic!("Expected HashIvc proof"),
    }
}

// ========================================================================
// Additional: FixedPoint checked operations boundary tests
// ========================================================================

#[test]
fn fix_v6_01_checked_mul_overflow_returns_none() {
    let big = FixedPoint::from_raw(i128::MAX);
    let two = FixedPoint::from_int(2);
    assert!(
        big.checked_mul(two).is_none(),
        "checked_mul should return None on overflow"
    );
}

#[test]
fn fix_v6_01_checked_div_overflow_returns_none() {
    let big = FixedPoint::from_raw(i128::MAX);
    let tiny = FixedPoint::from_raw(1); // very small
    // big * SCALE overflows
    assert!(
        big.checked_div(tiny).is_none(),
        "checked_div should return None when numerator scaling overflows"
    );
}

// ========================================================================
// Additional: MerkleProof from_bytes with maximum sibling count
// ========================================================================

#[test]
fn attack_v6_merkle_proof_max_siblings_accepted() {
    // 64 siblings is the max. Verify it decodes correctly.
    let mut data = vec![0u8; 108 + 33 * 64];
    data[40..44].copy_from_slice(&64u32.to_be_bytes());
    for i in 0..64 {
        let offset = 44 + 33 * i;
        data[offset + 32] = 0x00; // is_left = false
    }
    let proof = MerkleProof::from_bytes(&data).unwrap();
    assert_eq!(proof.siblings.len(), 64);
}

#[test]
fn attack_v6_merkle_proof_over_max_rejected() {
    // 65 siblings should be rejected.
    let mut data = vec![0u8; 108 + 33 * 65];
    data[40..44].copy_from_slice(&65u32.to_be_bytes());
    for i in 0..65 {
        let offset = 44 + 33 * i;
        data[offset + 32] = 0x00;
    }
    assert!(MerkleProof::from_bytes(&data).is_err());
}

// ========================================================================
// Additional: VerifiedResponse deserialization edge cases
// ========================================================================

#[test]
fn attack_v6_verified_response_truncated_proof_section() {
    // Create a valid response, then truncate the proof section.
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let response = VerifiedResponse::new(&proof, ZERO_HASH, b"data".to_vec(), ZERO_HASH);
    let bytes = response.to_bytes();

    // Truncate to just past the proof_len field but before proof_bytes end
    let truncated = &bytes[..105]; // 102 + 3 bytes of proof
    let result = VerifiedResponse::from_bytes(truncated);
    assert!(result.is_err(), "Truncated proof section should be rejected");
}

#[test]
fn attack_v6_verified_response_zero_proof_length() {
    // Craft a response with proof_length=0 -- should work (empty proof bytes)
    let mut data = vec![0u8; 134]; // minimum size
    data[96] = 0x00; // BackendId::Mock
    data[97] = 0x00; // PrivacyMode::Transparent
    // proof_len = 0 (already zero)
    let result = VerifiedResponse::from_bytes(&data);
    assert!(result.is_ok(), "Zero-length proof should be accepted structurally");
}

#[test]
fn attack_v6_verified_response_tampered_value_fails_integrity() {
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let response = VerifiedResponse::new(&proof, ZERO_HASH, b"original".to_vec(), ZERO_HASH);
    let mut bytes = response.to_bytes();

    // Tamper with the last byte (value section)
    if let Some(last) = bytes.last_mut() {
        *last ^= 0xFF;
    }

    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();
    assert!(
        !decoded.verify_value_integrity(),
        "Tampered value should fail integrity check"
    );
}

// ========================================================================
// Additional: Disclosure with mismatched proof count
// ========================================================================

#[test]
fn attack_v6_disclosure_more_proofs_than_revealed() {
    let verified = make_verified(vec![100, 200, 300, 400]);
    let mut disclosure = create_disclosure(&verified, &[0]).unwrap();

    // Add extra proofs (more than revealed tokens)
    let extra = disclosure.proofs[0].clone();
    disclosure.proofs.push(extra.clone());
    disclosure.proofs.push(extra);

    assert!(
        !verify_disclosure(&disclosure),
        "Extra proofs should cause verification failure"
    );
}

#[test]
fn attack_v6_disclosure_fewer_proofs_than_revealed() {
    let verified = make_verified(vec![100, 200, 300, 400]);
    let mut disclosure = create_disclosure(&verified, &[0, 1, 2]).unwrap();
    assert_eq!(disclosure.proofs.len(), 3);

    // Remove a proof
    disclosure.proofs.pop();

    assert!(
        !verify_disclosure(&disclosure),
        "Fewer proofs than revealed tokens should fail"
    );
}

// ========================================================================
// Additional: IVC verification edge cases
// ========================================================================

#[test]
fn attack_v6_ivc_verify_with_mock_proof_on_hash_backend() {
    let backend = HashIvc;
    let mock_proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };

    // HashIvc::verify should reject Mock proofs (wrong backend type)
    let result = backend.verify(&mock_proof, &ZERO_HASH, &ZERO_HASH);
    assert!(result.is_err(), "HashIvc should reject Mock proof type");
}

#[test]
fn attack_v6_ivc_verify_checkpoint_injection() {
    // Create a valid 1-step proof, then add an extra checkpoint.
    let backend = HashIvc;
    let code_hash = hash_data(b"test");
    let mut acc = backend.init(&code_hash, PrivacyMode::Transparent);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    backend.fold_step(&mut acc, &witness).unwrap();
    let proof = backend.finalize(acc).unwrap();

    // Tamper: add an extra checkpoint and bump step_count
    match proof {
        VerifiedProof::HashIvc {
            chain_tip,
            merkle_root,
            code_hash,
            privacy_mode,
            blinding_commitment,
            mut checkpoints,
            input_hash,
            output_hash,
            ..
        } => {
            checkpoints.push(hash_data(b"injected"));
            let tampered = VerifiedProof::HashIvc {
                chain_tip,
                merkle_root,
                step_count: 2,
                code_hash,
                privacy_mode,
                blinding_commitment,
                checkpoints,
                input_hash,
                output_hash,
            };
            let result = backend.verify(&tampered, &ZERO_HASH, &ZERO_HASH).unwrap();
            assert!(!result, "Injected checkpoint should cause chain_tip mismatch");
        }
        _ => panic!("Expected HashIvc proof"),
    }
}

// ========================================================================
// Additional: FixedPoint Display edge cases
// ========================================================================

#[test]
fn fix_v6_display_negative_fractional() {
    // Ensure Display doesn't panic on extreme values.
    let min = FixedPoint::from_raw(i128::MIN);
    let display = format!("{}", min);
    assert!(!display.is_empty(), "Display should not panic on i128::MIN");

    let max = FixedPoint::from_raw(i128::MAX);
    let display_max = format!("{}", max);
    assert!(!display_max.is_empty(), "Display should not panic on i128::MAX");
}

// ========================================================================
// Additional: Commitment from_bytes with exact size
// ========================================================================

#[test]
fn attack_v6_commitment_from_bytes_too_small() {
    let result = Commitment::from_bytes(&[0u8; 103]);
    assert!(result.is_err(), "Commitment needs exactly 104 bytes");
}

#[test]
fn attack_v6_commitment_from_bytes_exact_size() {
    let commitment = Commitment {
        root: [0x11; 32],
        total_checkpoints: 42,
        chain_tip: [0x22; 32],
        code_hash: [0x33; 32],
    };
    let bytes = commitment.to_bytes();
    assert_eq!(bytes.len(), 104);
    let decoded = Commitment::from_bytes(&bytes).unwrap();
    assert_eq!(decoded, commitment);
}

// ========================================================================
// Additional: BackendId and PrivacyMode from_u8 edge cases
// ========================================================================

#[test]
fn attack_v6_backend_id_invalid_values() {
    use poly_verified::types::BackendId;
    // Valid values: 0x00..0x03
    for v in 0x00..=0x03 {
        assert!(BackendId::from_u8(v).is_ok());
    }
    // Invalid values
    for v in 0x04..=0xFF {
        assert!(BackendId::from_u8(v).is_err(), "BackendId 0x{:02x} should be rejected", v);
    }
}

#[test]
fn attack_v6_privacy_mode_invalid_values() {
    // Valid: 0x00..0x02
    for v in 0x00..=0x02 {
        assert!(PrivacyMode::from_u8(v).is_ok());
    }
    // Invalid
    for v in 0x03..=0xFF {
        assert!(PrivacyMode::from_u8(v).is_err(), "PrivacyMode 0x{:02x} should be rejected", v);
    }
}

// ========================================================================
// Additional: Proof serialization roundtrip consistency
// ========================================================================

#[test]
fn attack_v6_merkle_proof_roundtrip_consistency() {
    let leaves: Vec<Hash> = (0..16u8).map(|i| hash_data(&[i])).collect();
    let tree = MerkleTree::build(&leaves);

    for i in 0..16 {
        let proof = tree.generate_proof(i as u64, &hash_data(b"code")).unwrap();
        let bytes = proof.to_bytes();
        let decoded = MerkleProof::from_bytes(&bytes).unwrap();

        assert_eq!(decoded.leaf, proof.leaf);
        assert_eq!(decoded.leaf_index, proof.leaf_index);
        assert_eq!(decoded.siblings.len(), proof.siblings.len());
        assert_eq!(decoded.root, proof.root);
        assert_eq!(decoded.code_hash, proof.code_hash);

        for (a, b) in decoded.siblings.iter().zip(proof.siblings.iter()) {
            assert_eq!(a.hash, b.hash);
            assert_eq!(a.is_left, b.is_left);
        }
    }
}
