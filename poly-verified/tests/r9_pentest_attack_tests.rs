//! Round 9 Pentest Attack Tests for poly-verified.
//!
//! Findings:
//! V9-01 HIGH (FIXED):    verify_disclosure Mock proof with ZERO_HASH output_hash bypasses binding
//! V9-02 HIGH (FIXED):    VerifiedResponse::from_bytes does not validate proof_bytes deserialize
//! V9-03 HIGH (FIXED):    HashIvc verify() has no checkpoint count cap (DoS via large proof)
//! V9-04 MEDIUM:          FixedPoint checked_mul precision loss near i128 boundary
//! V9-05 MEDIUM:          Disclosure output_root not bound to execution proof's merkle_root
//! V9-06 MEDIUM:          CompositeProof composition_hash depends on non-canonical JSON serialization
//! V9-07 MEDIUM:          FixedPoint saturated arithmetic conflates distinct overflow magnitudes
//! V9-08 MEDIUM:          HashIvc finalize does not cap checkpoints (memory growth during fold)
//! V9-09 LOW:             FixedPoint from_int(i64::MIN) * from_int(-1) saturates instead of exact
//! V9-10 LOW:             Disclosure serde roundtrip could allow output_root/execution_proof mismatch
//! V9-11 LOW:             hash_eq constant-time may be optimized away by compiler
//! V9-12 HIGH:            FixedPoint Div saturation produces WRONG results for large values (x/x != 1)

use sha2::{Digest, Sha256};

use poly_verified::crypto::hash::{hash_combine, hash_data};
use poly_verified::crypto::merkle::{verify_proof, MerkleTree};
use poly_verified::disclosure::{
    create_disclosure, disclosure_output_hash, token_leaf, verify_disclosure, Disclosure, DisclosedToken,
};
use poly_verified::fixed_point::FixedPoint;
use poly_verified::ivc::hash_ivc::HashIvc;
use poly_verified::ivc::IvcBackend;
use poly_verified::proof_composition::CompositeProof;
use poly_verified::proof_serialize::VerifiedResponse;
use poly_verified::types::{
    hash_eq, Hash, PrivacyMode, StepWitness, VerifiedProof, ZERO_HASH,
};
use poly_verified::verified_type::Verified;

// ========================================================================
// Helpers
// ========================================================================

fn tokens_hash(tokens: &[u32]) -> Hash {
    let mut hasher = Sha256::new();
    for &t in tokens {
        hasher.update(t.to_le_bytes());
    }
    hasher.finalize().into()
}

fn valid_hash_ivc_proof_for_tokens(tokens: &[u32]) -> VerifiedProof {
    let ivc = HashIvc;
    let code_hash = [0x03; 32];
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    acc.input_hash = ZERO_HASH;
    acc.output_hash = disclosure_output_hash(tokens);
    ivc.finalize(acc).unwrap()
}

fn make_verified(tokens: Vec<u32>) -> Verified<Vec<u32>> {
    let proof = valid_hash_ivc_proof_for_tokens(&tokens);
    Verified::__macro_new(tokens, proof)
}

fn make_multistep_proof(steps: u8) -> VerifiedProof {
    let ivc = HashIvc;
    let code_hash = hash_data(b"multistep_test");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    for i in 0..steps {
        let witness = StepWitness {
            state_before: hash_data(&[i]),
            state_after: hash_data(&[i + 1]),
            step_inputs: hash_data(&[i * 2]),
        };
        ivc.fold_step(&mut acc, &witness).unwrap();
    }
    ivc.finalize(acc).unwrap()
}

// ========================================================================
// V9-01 HIGH (FIXED): Mock proof with ZERO_HASH output bypasses binding
// ========================================================================
//
// verify_disclosure for Mock proofs previously checked:
//   if output_hash != ZERO_HASH && output_binding != output_hash: fail
// This meant that if output_hash == ZERO_HASH (e.g., a default Mock proof),
// the binding check was skipped entirely. An attacker could:
//   1. Create a Mock proof with output_hash = ZERO_HASH
//   2. Pair it with ANY token set (the output_binding won't be checked)
//   3. verify_disclosure returns true
//
// This allows forging arbitrary disclosures with Mock proofs.
//
// FIX: Now always checks output_binding == output_hash unconditionally.

#[test]
fn fix_v9_01a_mock_zero_output_hash_now_rejected() {
    let tokens = vec![100, 200, 300, 400];

    // Create a Mock proof with ZERO_HASH output (attacker doesn't know tokens)
    let mock_proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH, // doesn't match tokens_hash(tokens)
        privacy_mode: PrivacyMode::Transparent,
    };
    let verified = Verified::__macro_new(tokens, mock_proof);
    let disclosure = create_disclosure(&verified, &[0, 1]).unwrap();

    // Before fix: this would PASS because ZERO_HASH output skipped binding check.
    // After fix: this FAILS because output_binding (tokens_hash) != ZERO_HASH.
    assert!(
        !verify_disclosure(&disclosure),
        "Mock proof with ZERO_HASH output should fail disclosure binding check"
    );
}

#[test]
fn fix_v9_01b_mock_correct_output_hash_still_works() {
    let tokens = vec![100, 200, 300, 400];
    let correct_hash = disclosure_output_hash(&tokens);

    // Mock proof with correct output_hash
    let mock_proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: correct_hash,
        privacy_mode: PrivacyMode::Transparent,
    };
    let verified = Verified::__macro_new(tokens, mock_proof);
    let disclosure = create_disclosure(&verified, &[0, 2]).unwrap();

    // This should still pass because the binding matches
    assert!(
        verify_disclosure(&disclosure),
        "Mock proof with correct output_hash should pass"
    );
}

#[test]
fn fix_v9_01c_mock_wrong_output_hash_rejected() {
    let tokens = vec![100, 200, 300, 400];

    // Mock proof with wrong output_hash (different tokens)
    let wrong_hash = tokens_hash(&[999, 888]);
    let mock_proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: wrong_hash,
        privacy_mode: PrivacyMode::Transparent,
    };
    let verified = Verified::__macro_new(tokens, mock_proof);
    let disclosure = create_disclosure(&verified, &[0]).unwrap();

    assert!(
        !verify_disclosure(&disclosure),
        "Mock proof with wrong output_hash should fail"
    );
}

#[test]
fn fix_v9_01d_mock_zero_hash_forgery_attempt() {
    // Attacker scenario: forge a disclosure for arbitrary tokens using a
    // trivially constructed Mock proof with zeroed fields.
    let attacker_tokens = vec![42, 43, 44, 45, 46];
    let forged_proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };

    // Build the disclosure manually
    let leaves: Vec<Hash> = attacker_tokens.iter().map(|&t| token_leaf(t)).collect();
    let tree = MerkleTree::build(&leaves);
    let code_hash = ZERO_HASH;

    let mut disclosed_tokens = Vec::new();
    let mut proofs = Vec::new();
    for (i, &tok) in attacker_tokens.iter().enumerate() {
        disclosed_tokens.push(DisclosedToken::Revealed {
            index: i,
            token_id: tok,
        });
        proofs.push(tree.generate_proof(i as u64, &code_hash).unwrap());
    }

    let forged_disclosure = Disclosure {
        tokens: disclosed_tokens,
        proofs,
        output_root: tree.root,
        total_tokens: attacker_tokens.len(),
        execution_proof: forged_proof,
        output_binding: tokens_hash(&attacker_tokens),
    };

    // Before V9-01 fix: this would PASS (ZERO_HASH output skipped binding).
    // After fix: output_binding (non-zero) != output_hash (ZERO_HASH), so FAIL.
    assert!(
        !verify_disclosure(&forged_disclosure),
        "Forged disclosure with zero-hash Mock proof should be rejected"
    );
}

// ========================================================================
// V9-02 HIGH (FIXED): VerifiedResponse proof_bytes not validated
// ========================================================================
//
// VerifiedResponse::from_bytes stores raw proof_bytes without checking that
// they deserialize to a valid VerifiedProof. A receiver calling only
// verify_value_integrity() has no guarantee the proof is well-formed.
//
// FIX: Added validate_proof_bytes() method that attempts deserialization.

#[test]
fn fix_v9_02a_valid_proof_bytes_pass_validation() {
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let response = VerifiedResponse::new(&proof, ZERO_HASH, b"data".to_vec(), ZERO_HASH);
    let bytes = response.to_bytes();
    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();

    assert!(
        decoded.validate_proof_bytes(),
        "Valid proof_bytes should pass validation"
    );
    assert!(decoded.verify_value_integrity());
}

#[test]
fn fix_v9_02b_corrupt_proof_bytes_fail_validation() {
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let response = VerifiedResponse::new(&proof, ZERO_HASH, b"data".to_vec(), ZERO_HASH);
    let mut bytes = response.to_bytes();

    // Corrupt proof_bytes section (starts at offset 102)
    // The proof_len field tells us how long the proof is
    let proof_len = u32::from_be_bytes(bytes[98..102].try_into().unwrap()) as usize;
    assert!(proof_len > 0);

    // Overwrite first byte of proof_bytes with garbage
    bytes[102] = 0xFF;

    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();

    // verify_value_integrity still passes (it only checks value_hash)
    // But validate_proof_bytes should fail
    assert!(
        !decoded.validate_proof_bytes(),
        "Corrupted proof_bytes should fail validation"
    );
}

#[test]
fn fix_v9_02c_empty_proof_bytes_fail_validation() {
    // Craft a VerifiedResponse with empty proof_bytes on the wire
    let mut data = vec![0u8; 134]; // minimum header
    data[96] = 0x00; // BackendId::Mock
    data[97] = 0x00; // PrivacyMode::Transparent
    // proof_len = 0
    data[98..102].copy_from_slice(&0u32.to_be_bytes());

    let decoded = VerifiedResponse::from_bytes(&data).unwrap();
    assert!(
        !decoded.validate_proof_bytes(),
        "Empty proof_bytes should fail validation"
    );
}

#[test]
fn fix_v9_02d_hash_ivc_proof_bytes_validated() {
    let proof = make_multistep_proof(3);
    let response = VerifiedResponse::new(&proof, ZERO_HASH, b"test".to_vec(), ZERO_HASH);
    let bytes = response.to_bytes();
    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();

    assert!(
        decoded.validate_proof_bytes(),
        "HashIvc proof_bytes should pass validation"
    );
}

// ========================================================================
// V9-03 HIGH (FIXED): HashIvc verify() no checkpoint cap (DoS)
// ========================================================================
//
// An attacker can craft a HashIvc proof with millions of checkpoints.
// verify() rebuilds the hash chain O(N) and Merkle tree O(N log N),
// causing expensive computation and memory allocation.
//
// FIX: Added MAX_CHECKPOINTS (1,000,000) cap in verify().

#[test]
fn fix_v9_03a_reasonable_checkpoint_count_accepted() {
    // 100 checkpoints should verify fine
    let proof = make_multistep_proof(100);
    let ivc = HashIvc;
    assert!(ivc.verify(&proof, &ZERO_HASH, &ZERO_HASH).unwrap());
}

#[test]
fn fix_v9_03b_crafted_oversized_proof_rejected() {
    // Craft a proof claiming 2,000,000 checkpoints
    // We don't actually allocate 2M hashes -- we just verify the cap works
    // by creating a smaller proof and then tampering with step_count.
    let ivc = HashIvc;
    let code_hash = hash_data(b"dos_test");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    let proof = ivc.finalize(acc).unwrap();

    // Tamper: create a proof with huge step_count + matching checkpoint count
    // This tests the cap. We use step_count=2000001 but only 1 real checkpoint.
    match proof {
        VerifiedProof::HashIvc {
            chain_tip,
            merkle_root,
            code_hash,
            privacy_mode,
            blinding_commitment,
            input_hash,
            output_hash,
            checkpoints,
            ..
        } => {
            // The crafted proof has mismatched step_count (will fail checkpoint count check first)
            let tampered = VerifiedProof::HashIvc {
                chain_tip,
                merkle_root,
                step_count: 2_000_001,
                code_hash,
                privacy_mode,
                blinding_commitment,
                checkpoints, // only 1 checkpoint vs step_count of 2M
                input_hash,
                output_hash,
            };
            // Should fail on step_count != checkpoints.len()
            assert!(
                !ivc.verify(&tampered, &ZERO_HASH, &ZERO_HASH).unwrap(),
                "Mismatched step_count should be rejected"
            );
        }
        _ => panic!("Expected HashIvc"),
    }
}

#[test]
fn fix_v9_03c_checkpoint_cap_boundary() {
    // Verify that the cap constant exists and is reasonable
    // We can't easily create 1M+ checkpoints in a test, but we can verify
    // that the verifier rejects a proof claiming step_count > 1M with
    // matching checkpoint count.

    // Create a proof and replace checkpoints with a vector that would
    // exceed the cap. We use a small proof and just check step_count mismatch.
    let proof = make_multistep_proof(5);
    match proof {
        VerifiedProof::HashIvc {
            chain_tip,
            merkle_root,
            code_hash,
            privacy_mode,
            blinding_commitment,
            input_hash,
            output_hash,
            ..
        } => {
            // Claim 1,000,001 steps with only 5 checkpoints
            let oversized = VerifiedProof::HashIvc {
                chain_tip,
                merkle_root,
                step_count: 1_000_001,
                code_hash,
                privacy_mode,
                blinding_commitment,
                checkpoints: vec![[0xAA; 32]; 5], // doesn't match step_count
                input_hash,
                output_hash,
            };
            let ivc = HashIvc;
            assert!(
                !ivc.verify(&oversized, &ZERO_HASH, &ZERO_HASH).unwrap(),
                "Step count exceeding cap with mismatched checkpoints should fail"
            );
        }
        _ => panic!("Expected HashIvc"),
    }
}

// ========================================================================
// V9-04 MEDIUM: FixedPoint checked_mul precision loss near boundary
// ========================================================================
//
// checked_mul computes (self.raw * rhs.raw) / SCALE. For values where
// self.raw * rhs.raw barely fits in i128, the product is exact, but the
// division by SCALE truncates potentially significant bits. Two different
// inputs can produce the same output when the difference is < SCALE in
// the product space.
//
// This is inherent to fixed-point arithmetic but becomes problematic
// when the caller expects high precision near the overflow boundary.

#[test]
fn attack_v9_04a_checked_mul_precision_loss() {
    // Two different multiplications that produce the same truncated result
    let a = FixedPoint::from_raw(1 << 63); // large value
    let b = FixedPoint::from_raw(1 << 63);

    // a * b / SCALE: the product is 2^126, divided by 2^48 = 2^78
    let result = a.checked_mul(b);
    assert!(result.is_some(), "Multiplication should not overflow");

    // Now try with slightly different values
    let a2 = FixedPoint::from_raw((1 << 63) + 1);
    let result2 = a2.checked_mul(b);

    // Both should succeed but may produce different results
    if let (Some(r1), Some(r2)) = (result, result2) {
        // The precision loss means small input differences may vanish
        let diff = (r1.raw() - r2.raw()).abs();
        // Document that precision loss occurs
        assert!(
            diff >= 0,
            "Precision loss is inherent in fixed-point multiplication"
        );
    }
}

#[test]
fn attack_v9_04b_checked_mul_overflow_returns_none() {
    // Values that definitely overflow i128 when multiplied
    let huge = FixedPoint::from_raw(i128::MAX / 2 + 1);
    let also_huge = FixedPoint::from_raw(3);

    // i128::MAX/2 * 3 overflows i128
    let result = huge.checked_mul(also_huge);
    assert!(
        result.is_none(),
        "Multiplication overflow should return None"
    );
}

#[test]
fn attack_v9_04c_checked_div_precision_loss() {
    // Division: (self.raw * SCALE) / rhs.raw
    // When self.raw is large, self.raw * SCALE can overflow
    let large = FixedPoint::from_int(i64::MAX / 2);
    let small = FixedPoint::from_decimal(1, 1); // 0.1

    // large / 0.1 = large * 10 -- may overflow in checked_div
    let result = large.checked_div(small);
    // Should return None if numerator overflows
    if result.is_none() {
        // Expected: i64::MAX/2 * SCALE would overflow when multiplied by SCALE again
    }
}

// ========================================================================
// V9-05 MEDIUM: Disclosure output_root not bound to execution proof
// ========================================================================
//
// The execution proof (HashIvc) has its own merkle_root over computation
// checkpoints. The disclosure has output_root over token Merkle leaves.
// These are two DIFFERENT Merkle trees with no cryptographic binding.
//
// The only binding is through output_hash (tokens_hash). An attacker
// who can find a different token set with the same tokens_hash could
// create a valid disclosure for the wrong tokens.
//
// This is mitigated by SHA-256 collision resistance but documents the
// architectural gap.

#[test]
fn attack_v9_05a_two_merkle_trees_are_independent() {
    let tokens = vec![100, 200, 300, 400];
    let verified = make_verified(tokens.clone());
    let disclosure = create_disclosure(&verified, &[0, 1]).unwrap();

    // The execution proof's merkle_root is over computation checkpoints
    let proof_merkle_root = match verified.proof() {
        VerifiedProof::HashIvc { merkle_root, .. } => *merkle_root,
        _ => panic!("Expected HashIvc"),
    };

    // The disclosure's output_root is over token leaves
    let token_leaves: Vec<Hash> = tokens.iter().map(|&t| token_leaf(t)).collect();
    let token_tree = MerkleTree::build(&token_leaves);

    // These are two completely different Merkle trees
    assert_ne!(
        proof_merkle_root, disclosure.output_root,
        "Proof merkle_root and disclosure output_root should differ (different trees)"
    );
    assert_eq!(
        disclosure.output_root, token_tree.root,
        "Disclosure output_root should match token Merkle tree"
    );
    assert!(verify_disclosure(&disclosure));
}

#[test]
fn attack_v9_05b_disclosure_output_root_tampered() {
    let tokens = vec![100, 200, 300, 400];
    let verified = make_verified(tokens);
    let mut disclosure = create_disclosure(&verified, &[0, 1]).unwrap();

    // Replace output_root with the execution proof's merkle_root
    match &disclosure.execution_proof {
        VerifiedProof::HashIvc { merkle_root, .. } => {
            disclosure.output_root = *merkle_root;
        }
        _ => panic!("Expected HashIvc"),
    }

    // Should fail: the Merkle proofs won't match the replaced root
    assert!(
        !verify_disclosure(&disclosure),
        "Disclosure with swapped merkle root should fail"
    );
}

// ========================================================================
// V9-06 MEDIUM: CompositeProof JSON-based composition hash
// ========================================================================
//
// CompositeProof::compute_composition_hash uses serde_json::to_vec to
// serialize each proof before hashing. JSON serialization is NOT canonical:
// - Field ordering could change between serde_json versions
// - Number formatting may differ
// - Unicode escaping behavior can vary
//
// If a CompositeProof is created with one serde_json version and verified
// with another that produces different JSON, the composition hash won't match.

#[test]
fn attack_v9_06a_composition_hash_is_json_dependent() {
    let outer = VerifiedProof::Mock {
        input_hash: [0x01; 32],
        output_hash: [0x02; 32],
        privacy_mode: PrivacyMode::Transparent,
    };
    let composite = CompositeProof::compose(outer.clone(), vec![]);

    // The composition hash is computed from JSON serialization of the outer
    // proof, then combined with the effective privacy mode binding.
    // [V13-11 FIX] Privacy mode is now bound into the composition hash.
    let json_bytes = serde_json::to_vec(&outer).unwrap();
    let proof_hash = hash_data(&json_bytes);
    let privacy_binding = hash_data(&[PrivacyMode::Transparent as u8]);
    let expected_hash = hash_combine(&proof_hash, &privacy_binding);

    // The composition hash should match what we compute manually
    assert_eq!(
        composite.composition_hash, expected_hash,
        "Composition hash should be hash of JSON-serialized outer proof + privacy binding"
    );

    // Document: if serde_json changes its output format, this test will break,
    // proving the non-canonical serialization vulnerability.
}

#[test]
fn attack_v9_06b_composition_hash_roundtrip_stable() {
    // Verify that at least within the same binary, the hash is stable
    let outer = make_multistep_proof(3);
    let inner = make_multistep_proof(2);

    let comp1 = CompositeProof::compose(outer.clone(), vec![inner.clone()]);
    let comp2 = CompositeProof::compose(outer, vec![inner]);

    assert_eq!(
        comp1.composition_hash, comp2.composition_hash,
        "Same inputs should produce same composition hash within same binary"
    );
    assert!(comp1.verify_composition());
    assert!(comp2.verify_composition());
}

// ========================================================================
// V9-07 MEDIUM: FixedPoint saturated arithmetic conflates values
// ========================================================================
//
// When arithmetic operations saturate (overflow/underflow), the result is
// clamped to i128::MAX or i128::MIN. This means multiple distinct
// computations produce identical FixedPoint values, losing information
// about the actual magnitude.
//
// In a verified computation, this means two different inputs could produce
// the same "proven" output through saturation.

#[test]
fn attack_v9_07a_different_overflows_same_result() {
    let huge_a = FixedPoint::from_raw(i128::MAX - 100);
    let huge_b = FixedPoint::from_raw(i128::MAX - 200);
    let addend = FixedPoint::from_raw(1000);

    let result_a = huge_a + addend; // saturates to i128::MAX
    let result_b = huge_b + addend; // also saturates to i128::MAX

    assert_eq!(
        result_a.raw(),
        i128::MAX,
        "Addition should saturate to MAX"
    );
    assert_eq!(
        result_b.raw(),
        i128::MAX,
        "Addition should saturate to MAX"
    );
    assert_eq!(
        result_a, result_b,
        "Different inputs saturate to the same result (information loss)"
    );
}

#[test]
fn attack_v9_07b_mul_overflow_same_saturation() {
    // Two different multiplications that both overflow
    let a = FixedPoint::from_int(i64::MAX);
    let b = FixedPoint::from_int(i64::MAX);
    let c = FixedPoint::from_int(i64::MAX / 2);

    let result_ab = a * b; // definitely overflows
    let result_ac = a * c; // also overflows (but less)

    // Both saturate to i128::MAX
    assert_eq!(result_ab.raw(), i128::MAX);
    assert_eq!(result_ac.raw(), i128::MAX);
    assert_eq!(
        result_ab, result_ac,
        "Different overflow multiplications produce same saturated result"
    );
}

#[test]
fn attack_v9_07c_neg_overflow_saturation() {
    let huge_neg = FixedPoint::from_raw(i128::MIN + 100);
    let subtrahend = FixedPoint::from_raw(1000);

    let result = huge_neg - subtrahend; // saturates to i128::MIN
    assert_eq!(result.raw(), i128::MIN);

    // Even with a different starting point
    let huge_neg2 = FixedPoint::from_raw(i128::MIN + 500);
    let result2 = huge_neg2 - subtrahend;
    assert_eq!(result2.raw(), i128::MIN);

    assert_eq!(result, result2, "Different underflows produce same result");
}

// ========================================================================
// V9-08 MEDIUM: HashIvc finalize has no cap on accumulated checkpoints
// ========================================================================
//
// During fold_step, checkpoints are pushed into a Vec without limit.
// If a computation has millions of steps, the accumulator's checkpoint
// vector grows unboundedly. While this is less of a security issue
// (the prover controls their own memory), it means there's no defense
// against a buggy or malicious step function that loops excessively.

#[test]
fn attack_v9_08a_accumulator_grows_without_bound() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"growth_test");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);

    // Fold 1000 steps -- accumulator checkpoint vector grows linearly
    for i in 0..1000u32 {
        let witness = StepWitness {
            state_before: hash_data(&i.to_le_bytes()),
            state_after: hash_data(&(i + 1).to_le_bytes()),
            step_inputs: hash_data(&(i * 2).to_le_bytes()),
        };
        ivc.fold_step(&mut acc, &witness).unwrap();
    }

    let proof = ivc.finalize(acc).unwrap();
    match &proof {
        VerifiedProof::HashIvc {
            step_count,
            checkpoints,
            ..
        } => {
            assert_eq!(*step_count, 1000);
            assert_eq!(checkpoints.len(), 1000);
            // Each checkpoint is 32 bytes = 32 KB total
            // For millions of steps this becomes gigabytes
        }
        _ => panic!("Expected HashIvc"),
    }

    // Verify still works for reasonable sizes
    assert!(ivc.verify(&proof, &ZERO_HASH, &ZERO_HASH).unwrap());
}

// ========================================================================
// V9-09 LOW: FixedPoint from_int(i64::MIN) * from_int(-1) saturates
// ========================================================================
//
// i64::MIN = -2^63. from_int(-2^63) gives raw = -2^63 * 2^48 = -2^111.
// from_int(-1) gives raw = -1 * 2^48 = -2^48.
// Mul: (-2^111) * (-2^48) = 2^159. But 2^159 > i128::MAX (2^127-1),
// so checked_mul returns None and Mul trait saturates to i128::MAX.
// The exact result should be 2^63 * SCALE, but we get saturation.

#[test]
fn attack_v9_09a_min_times_neg_one_saturates() {
    let min_val = FixedPoint::from_int(i64::MIN);
    let neg_one = FixedPoint::from_int(-1);

    // Mathematically: i64::MIN * (-1) = i64::MAX + 1 = 2^63
    // But in FixedPoint: raw multiplication overflows i128
    let result = min_val * neg_one;

    // The result saturates instead of being exact
    assert_eq!(
        result.raw(),
        i128::MAX,
        "i64::MIN * (-1) saturates to MAX due to raw overflow"
    );

    // Verify checked_mul also fails
    assert!(
        min_val.checked_mul(neg_one).is_none(),
        "checked_mul should return None for this overflow"
    );
}

#[test]
fn attack_v9_09b_neg_one_times_neg_one_exact() {
    // Sanity: (-1) * (-1) = 1 should work fine
    let neg_one = FixedPoint::from_int(-1);
    let result = neg_one * neg_one;
    assert_eq!(result.to_i64(), 1);
    assert_eq!(result.raw(), FixedPoint::ONE.raw());
}

#[test]
fn attack_v9_09c_large_negation_boundary() {
    // Negate i128::MIN should saturate to i128::MAX (not panic)
    let extreme = FixedPoint::from_raw(i128::MIN);
    let negated = -extreme;
    assert_eq!(
        negated.raw(),
        i128::MAX,
        "Negating i128::MIN should saturate to i128::MAX"
    );
}

// ========================================================================
// V9-10 LOW: Disclosure serde roundtrip allows field tampering
// ========================================================================
//
// Disclosure derives Serialize + Deserialize. An attacker can deserialize
// a Disclosure, modify fields (e.g., execution_proof, output_root), and
// re-serialize. While verify_disclosure would catch most tampering,
// there's a risk that a receiver stores the deserialized Disclosure
// without calling verify_disclosure first.

#[test]
fn attack_v9_10a_disclosure_serde_tamper_execution_proof() {
    let tokens = vec![100, 200, 300, 400];
    let verified = make_verified(tokens.clone());
    let disclosure = create_disclosure(&verified, &[0, 1]).unwrap();
    assert!(verify_disclosure(&disclosure));

    // Serialize to JSON
    let json = serde_json::to_string(&disclosure).unwrap();
    let mut deserialized: Disclosure = serde_json::from_str(&json).unwrap();

    // Tamper: replace execution_proof with a different one
    let other_tokens = vec![999, 888, 777, 666];
    let other_proof = valid_hash_ivc_proof_for_tokens(&other_tokens);
    deserialized.execution_proof = other_proof;

    // verify_disclosure should catch this
    assert!(
        !verify_disclosure(&deserialized),
        "Deserialized disclosure with swapped execution proof should fail"
    );
}

#[test]
fn attack_v9_10b_disclosure_serde_tamper_output_binding() {
    let tokens = vec![100, 200, 300, 400];
    let verified = make_verified(tokens);
    let disclosure = create_disclosure(&verified, &[0]).unwrap();

    let json = serde_json::to_string(&disclosure).unwrap();
    let mut deserialized: Disclosure = serde_json::from_str(&json).unwrap();

    // Tamper: change output_binding
    deserialized.output_binding = [0xFF; 32];

    assert!(
        !verify_disclosure(&deserialized),
        "Tampered output_binding should be rejected after serde roundtrip"
    );
}

#[test]
fn attack_v9_10c_disclosure_serde_valid_roundtrip() {
    let tokens = vec![100, 200, 300, 400];
    let verified = make_verified(tokens);
    let disclosure = create_disclosure(&verified, &[0, 2]).unwrap();

    let json = serde_json::to_string(&disclosure).unwrap();
    let deserialized: Disclosure = serde_json::from_str(&json).unwrap();

    // Untampered roundtrip should still verify
    assert!(
        verify_disclosure(&deserialized),
        "Valid serde roundtrip should preserve disclosure validity"
    );
}

// ========================================================================
// V9-11 LOW: hash_eq constant-time may be optimized by compiler
// ========================================================================
//
// hash_eq uses bitwise OR accumulation to prevent timing side-channels.
// However, the Rust compiler is free to optimize this into a memcmp-like
// operation with early exit, defeating the constant-time property.
// There is no `core::hint::black_box` wrapping or volatile access.
//
// We can only test functional correctness here; timing guarantees
// require assembly-level verification or use of a constant-time library.

#[test]
fn attack_v9_11a_hash_eq_functional_correctness() {
    // Verify hash_eq works correctly for all bit patterns
    let a = [0xAB; 32];
    let b = [0xAB; 32];
    assert!(hash_eq(&a, &b));

    // Single bit difference in each byte position
    for i in 0..32 {
        let mut c = a;
        c[i] ^= 0x01;
        assert!(!hash_eq(&a, &c), "Failed at byte {}", i);
    }
}

#[test]
fn attack_v9_11b_hash_eq_zero_vs_nonzero() {
    // ZERO_HASH should not equal any non-zero hash
    let non_zero = hash_data(b"anything");
    assert!(!hash_eq(&ZERO_HASH, &non_zero));
    assert!(hash_eq(&ZERO_HASH, &ZERO_HASH));
}

// ========================================================================
// Additional: Proof privacy mode downgrade attack via disclosure
// ========================================================================
//
// Can an attacker create a disclosure from a Private-mode proof and
// extract information that should be hidden?

#[test]
fn attack_v9_privacy_mode_downgrade_via_disclosure() {
    let tokens = vec![100, 200, 300, 400];

    // Create a Private-mode proof
    let ivc = HashIvc;
    let code_hash = [0x03; 32];
    let mut acc = ivc.init(&code_hash, PrivacyMode::Private);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    acc.input_hash = ZERO_HASH;
    acc.output_hash = disclosure_output_hash(&tokens);
    let proof = ivc.finalize(acc).unwrap();

    // The code_hash() accessor hides the code in Private mode
    assert_eq!(proof.code_hash(), ZERO_HASH);

    // But creating a disclosure from a Private proof still reveals the
    // Merkle tree structure and token values (if disclosed)
    let verified = Verified::__macro_new(tokens, proof);
    let disclosure = create_disclosure(&verified, &[0, 1]).unwrap();

    // The disclosure reveals tokens 0 and 1 even though the proof is Private
    // This is by design: disclosure controls what the receiver sees,
    // but the prover chooses what to disclose.
    match &disclosure.tokens[0] {
        DisclosedToken::Revealed { token_id, .. } => {
            assert_eq!(*token_id, 100, "Private proof still allows token disclosure");
        }
        _ => panic!("Expected revealed"),
    }

    // The execution proof's privacy mode is preserved in the disclosure
    assert_eq!(
        disclosure.execution_proof.privacy_mode(),
        PrivacyMode::Private
    );

    assert!(verify_disclosure(&disclosure));
}

// ========================================================================
// Additional: Merkle proof with duplicated sibling (second preimage)
// ========================================================================
//
// In a Merkle tree with odd number of leaves, the last leaf is duplicated.
// This means hash_combine(leaf, leaf) is used. Can an attacker exploit
// this to create a proof for a leaf at a position that doesn't exist?

#[test]
fn attack_v9_merkle_odd_leaf_duplication_exploit() {
    // 3 leaves: the 4th "virtual" position uses hash_combine(leaf[2], leaf[2])
    let leaves = vec![hash_data(&[0]), hash_data(&[1]), hash_data(&[2])];
    let tree = MerkleTree::build(&leaves);

    // The tree has layers:
    // L0: [leaf0, leaf1, leaf2]
    // L1: [hash(leaf0,leaf1), hash(leaf2,leaf2)]  <-- leaf2 duplicated
    // L2: [root]

    // Verify all 3 real positions work
    for i in 0..3 {
        let proof = tree.generate_proof(i, &ZERO_HASH).unwrap();
        assert!(verify_proof(&proof));
    }

    // Position 3 doesn't exist -- should be out of bounds
    assert!(tree.generate_proof(3, &ZERO_HASH).is_err());

    // Can we forge a proof for position 2 using the duplication?
    // The sibling for leaf[2] at L0 is leaf[2] itself (self-duplicate)
    let proof_2 = tree.generate_proof(2, &ZERO_HASH).unwrap();
    assert_eq!(proof_2.siblings.len(), 2);

    // The first sibling should be leaf[2] (self-duplicate for odd position)
    assert_eq!(
        proof_2.siblings[0].hash, leaves[2],
        "Odd leaf's sibling should be itself"
    );
    assert!(
        !proof_2.siblings[0].is_left,
        "Self-duplicate sibling should be on the right"
    );
}

// ========================================================================
// Additional: IVC proof code_hash/privacy_mode binding
// ========================================================================
//
// HashIvc binds code_hash and privacy_mode into the chain_tip:
//   bound_tip = hash_combine(hash_combine(chain.tip, H(code_hash)), H(privacy))
//
// Can an attacker swap code_hash and privacy_mode values while keeping
// the bound_tip valid?

#[test]
fn attack_v9_ivc_code_hash_swap_detected() {
    let ivc = HashIvc;
    let code_a = hash_data(b"function_a");
    let code_b = hash_data(b"function_b");

    let witness = StepWitness {
        state_before: hash_data(b"state"),
        state_after: hash_data(b"state2"),
        step_inputs: hash_data(b"input"),
    };

    let mut acc = ivc.init(&code_a, PrivacyMode::Transparent);
    ivc.fold_step(&mut acc, &witness).unwrap();
    let proof_a = ivc.finalize(acc).unwrap();

    // Tamper: change code_hash in the proof
    match proof_a {
        VerifiedProof::HashIvc {
            chain_tip,
            merkle_root,
            step_count,
            privacy_mode,
            blinding_commitment,
            checkpoints,
            input_hash,
            output_hash,
            ..
        } => {
            let tampered = VerifiedProof::HashIvc {
                chain_tip,
                merkle_root,
                step_count,
                code_hash: code_b, // swapped!
                privacy_mode,
                blinding_commitment,
                checkpoints,
                input_hash,
                output_hash,
            };

            // Verification should fail because the bound_tip includes code_hash
            assert!(
                !ivc.verify(&tampered, &ZERO_HASH, &ZERO_HASH).unwrap(),
                "Swapped code_hash should be detected by bound chain_tip"
            );
        }
        _ => panic!("Expected HashIvc"),
    }
}

#[test]
fn attack_v9_ivc_privacy_mode_swap_detected() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"test_fn");

    let witness = StepWitness {
        state_before: hash_data(b"state"),
        state_after: hash_data(b"state2"),
        step_inputs: hash_data(b"input"),
    };

    // Create a Transparent proof
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    ivc.fold_step(&mut acc, &witness).unwrap();
    let proof = ivc.finalize(acc).unwrap();

    // Try to change privacy_mode to Private (to bypass I/O checks)
    match proof {
        VerifiedProof::HashIvc {
            chain_tip,
            merkle_root,
            step_count,
            code_hash,
            checkpoints,
            input_hash,
            output_hash,
            ..
        } => {
            let tampered = VerifiedProof::HashIvc {
                chain_tip,
                merkle_root,
                step_count,
                code_hash,
                privacy_mode: PrivacyMode::Private, // swapped!
                blinding_commitment: Some([0xAA; 32]), // fake blinding
                checkpoints,
                input_hash,
                output_hash,
            };

            // Should fail: bound_tip includes privacy_mode, and blinding won't match
            assert!(
                !ivc.verify(&tampered, &ZERO_HASH, &ZERO_HASH).unwrap(),
                "Privacy mode swap should be detected"
            );
        }
        _ => panic!("Expected HashIvc"),
    }
}

// ========================================================================
// Additional: FixedPoint exp_approx with NaN-like behavior
// ========================================================================
//
// exp_approx can produce wildly wrong results for inputs where the
// Taylor series hasn't converged. We verify the boundary between
// "usable" and "garbage" results.

#[test]
fn attack_v9_exp_convergence_boundary() {
    // exp(x) Taylor series converges for all x, but slowly for |x| > 1.
    // With 20 terms:
    // - exp(1) = 2.718... (good)
    // - exp(2) = 7.389... (acceptable)
    // - exp(5) = 148.4... (starts to diverge)
    // - exp(10) = 22026... (garbage with 20 terms)

    let one = FixedPoint::ONE;
    let e1 = one.exp_approx(20);
    assert_eq!(e1.to_i64(), 2, "exp(1) should be ~2");

    let two = FixedPoint::from_int(2);
    let e2 = two.exp_approx(20);
    assert_eq!(e2.to_i64(), 7, "exp(2) should be ~7");

    // For exp(5), the result may not be exact but should be in the ballpark
    let five = FixedPoint::from_int(5);
    let e5 = five.exp_approx(30); // need more terms for larger input
    let e5_int = e5.to_i64();
    // exp(5) = 148.4, but with limited terms the result may be off
    assert!(
        e5_int > 100 && e5_int < 200,
        "exp(5) with 30 terms should be ~148, got {}",
        e5_int
    );
}

// ========================================================================
// Additional: Disclosure with tokens at u32 boundary values
// ========================================================================

#[test]
fn attack_v9_disclosure_boundary_token_values() {
    let tokens = vec![0, 1, u32::MAX - 1, u32::MAX];
    let verified = make_verified(tokens.clone());
    let disclosure = create_disclosure(&verified, &[0, 1, 2, 3]).unwrap();
    assert!(verify_disclosure(&disclosure));

    // Verify each token is correctly revealed
    for (i, &expected) in tokens.iter().enumerate() {
        match &disclosure.tokens[i] {
            DisclosedToken::Revealed { token_id, .. } => {
                assert_eq!(*token_id, expected, "Token {} mismatch", i);
            }
            _ => panic!("Expected revealed at position {}", i),
        }
    }
}

// ========================================================================
// Additional: CompositeProof with nested HashIvc proofs containing
// different checkpoint counts
// ========================================================================

#[test]
fn attack_v9_composite_checkpoint_count_variance() {
    let outer = make_multistep_proof(1);
    let inner_small = make_multistep_proof(2);
    let inner_large = make_multistep_proof(50);

    let composite = CompositeProof::compose(outer, vec![inner_small, inner_large]);
    assert!(composite.verify_composition());
    assert_eq!(composite.proof_count(), 3);

    // Verify composition hash changes if we swap inner proofs
    let outer2 = make_multistep_proof(1);
    let inner_small2 = make_multistep_proof(2);
    let inner_large2 = make_multistep_proof(50);

    let composite_swapped =
        CompositeProof::compose(outer2, vec![inner_large2, inner_small2]);
    assert!(composite_swapped.verify_composition());

    // Different order should produce different composition hash
    assert_ne!(
        composite.composition_hash, composite_swapped.composition_hash,
        "Different inner proof order should produce different hash"
    );
}

// ========================================================================
// Additional: VerifiedResponse with extremely large value_bytes
// ========================================================================

#[test]
fn attack_v9_verified_response_large_value_bytes() {
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };

    // 1 MB value_bytes
    let large_value = vec![0xAB; 1024 * 1024];
    let response = VerifiedResponse::new(&proof, ZERO_HASH, large_value.clone(), ZERO_HASH);

    let bytes = response.to_bytes();
    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();

    assert_eq!(decoded.value_bytes.len(), 1024 * 1024);
    assert!(decoded.verify_value_integrity());
    assert!(decoded.validate_proof_bytes());
}

// ========================================================================
// Additional: FixedPoint comparison after saturation
// ========================================================================

#[test]
fn attack_v9_fixed_point_comparison_after_saturation() {
    // After saturation, Ord comparison should still work
    let max = FixedPoint::from_raw(i128::MAX);
    let min = FixedPoint::from_raw(i128::MIN);
    let zero = FixedPoint::ZERO;
    let one = FixedPoint::ONE;

    assert!(max > zero);
    assert!(min < zero);
    assert!(one > zero);
    assert!(max > one);
    assert!(min < one);
    assert!(max > min);

    // Two saturated values should be equal
    let max2 = FixedPoint::from_raw(i128::MAX);
    assert_eq!(max, max2);
}

// ========================================================================
// Additional: HashIvc with Privacy + I/O binding interaction
// ========================================================================

#[test]
fn attack_v9_private_mode_io_binding_bypass() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"private_test");

    // Create a Private-mode proof
    let mut acc = ivc.init(&code_hash, PrivacyMode::Private);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    acc.input_hash = hash_data(b"real_input");
    acc.output_hash = hash_data(b"real_output");
    let proof = ivc.finalize(acc).unwrap();

    // In Private mode, the verifier doesn't check I/O hashes.
    // This means ANY expected_input/output passes.
    assert!(
        ivc.verify(&proof, &ZERO_HASH, &ZERO_HASH).unwrap(),
        "Private mode should accept any expected I/O"
    );
    assert!(
        ivc.verify(&proof, &hash_data(b"garbage"), &hash_data(b"trash"))
            .unwrap(),
        "Private mode should accept any expected I/O (even garbage)"
    );

    // This is by design: Private mode doesn't reveal I/O.
    // But it means the verifier has NO way to check I/O correctness.
    // The verifier must trust the proof structurally (chain + blinding).
}

// ========================================================================
// Additional: Disclosure with interleaved revealed/redacted pattern
// ========================================================================

#[test]
fn attack_v9_disclosure_alternating_reveal_pattern() {
    let tokens: Vec<u32> = (0..16).map(|i| i * 100).collect();
    let verified = make_verified(tokens);

    // Reveal every other token
    let even_indices: Vec<usize> = (0..16).step_by(2).collect();
    let disclosure = create_disclosure(&verified, &even_indices).unwrap();

    assert_eq!(disclosure.proofs.len(), 8);
    assert!(verify_disclosure(&disclosure));

    // Verify the pattern: even = revealed, odd = redacted
    for (i, token) in disclosure.tokens.iter().enumerate() {
        if i % 2 == 0 {
            assert!(
                matches!(token, DisclosedToken::Revealed { .. }),
                "Even index {} should be revealed",
                i
            );
        } else {
            assert!(
                matches!(token, DisclosedToken::Redacted { .. }),
                "Odd index {} should be redacted",
                i
            );
        }
    }
}

// ========================================================================
// Additional: HashIvc verify detects checkpoint duplication attack
// ========================================================================

#[test]
fn attack_v9_ivc_duplicated_checkpoints_detected() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"dup_cp_test");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);

    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    let proof = ivc.finalize(acc).unwrap();

    // Tamper: duplicate the checkpoint to claim 2 steps
    match proof {
        VerifiedProof::HashIvc {
            merkle_root,
            code_hash,
            privacy_mode,
            blinding_commitment,
            input_hash,
            output_hash,
            checkpoints,
            ..
        } => {
            let cp = checkpoints[0];
            let tampered = VerifiedProof::HashIvc {
                // chain_tip won't match because the chain is now 2 steps
                chain_tip: ZERO_HASH, // obviously wrong
                merkle_root,
                step_count: 2,
                code_hash,
                privacy_mode,
                blinding_commitment,
                checkpoints: vec![cp, cp], // duplicated!
                input_hash,
                output_hash,
            };

            assert!(
                !ivc.verify(&tampered, &ZERO_HASH, &ZERO_HASH).unwrap(),
                "Duplicated checkpoint with wrong chain_tip should be rejected"
            );
        }
        _ => panic!("Expected HashIvc"),
    }
}

// ========================================================================
// Additional: FixedPoint division edge cases
// ========================================================================

#[test]
fn attack_v9_fixed_point_div_neg_one() {
    // x / (-1) should negate x
    let five = FixedPoint::from_int(5);
    let neg_one = FixedPoint::from_int(-1);
    let result = five / neg_one;
    assert_eq!(result.to_i64(), -5);
}

#[test]
fn attack_v9_fixed_point_div_self_normal() {
    // x / x should be 1.0 for any non-zero x (within non-saturating range)
    let vals = [1i64, -1, 42, -42, 1000, -1000, 100_000, -100_000];
    for &v in &vals {
        let x = FixedPoint::from_int(v);
        let result = x / x;
        assert_eq!(
            result.to_i64(),
            1,
            "FixedPoint::from_int({}) / self should be 1, got {}",
            v,
            result.to_i64()
        );
    }
}

// ========================================================================
// V9-12 HIGH: FixedPoint Div saturation produces WRONG results for large values
// ========================================================================
//
// When self.raw * SCALE overflows in the Div implementation, the code saturates
// to i128::MAX (or i128::MIN). Then it divides by rhs.raw. For large positive
// values where both operands are the same (x / x should be 1), the saturation
// path computes i128::MAX / x.raw, which gives a result that depends on x
// rather than being 1.
//
// For i64::MAX/2: raw = (i64::MAX/2) * SCALE ~ 2^110
// raw * SCALE ~ 2^158, overflows  saturated to i128::MAX ~ 2^127
// i128::MAX / raw ~ 2^127 / 2^110 ~ 2^17  gets cast wrong
//
// This is a CORRECTNESS BUG: x/x does not equal 1 for large values!

#[test]
fn attack_v9_12a_div_self_large_value_wrong_result() {
    // i64::MAX / 2 is large enough that raw * SCALE overflows i128
    let large = FixedPoint::from_int(i64::MAX / 2);
    let result = large / large;

    // x / x should be 1.0, but due to saturation it's wrong
    // The Div saturates to i128::MAX for positive overflow, then divides
    // by the large raw value, giving an incorrect result.
    assert_ne!(
        result.to_i64(),
        1,
        "V9-12 BUG: x/x for large x should be 1 but isn't due to Div saturation"
    );
    // Document the actual wrong value for this input
    let wrong_result = result.to_i64();
    // This is a proven incorrect result in a verified computation.
    assert!(
        wrong_result != 1,
        "Large value division self/self gives {} instead of 1",
        wrong_result
    );
}

#[test]
fn attack_v9_12b_checked_div_returns_none_for_overflow() {
    // checked_div should return None when numerator overflows
    let large = FixedPoint::from_int(i64::MAX / 2);
    let result = large.checked_div(large);

    // checked_div computes self.raw.checked_mul(SCALE) which overflows
    assert!(
        result.is_none(),
        "checked_div should return None when numerator overflows"
    );
}

#[test]
fn attack_v9_12c_div_small_values_correct() {
    // Division should be correct for values where raw * SCALE doesn't overflow
    // The safe range is approximately |value| < 2^(127-48) = 2^79
    // from_int(i64) gives raw = i64 * 2^48, so raw * SCALE = i64 * 2^96
    // This overflows i128 when i64 > 2^31 (since 2^31 * 2^96 = 2^127)
    // So roughly |value| < 2^31 is safe for division

    let a = FixedPoint::from_int(1000);
    let b = FixedPoint::from_int(100);
    let result = a / b;
    assert_eq!(result.to_i64(), 10, "1000 / 100 should be 10");

    let c = FixedPoint::from_int(7);
    let d = FixedPoint::from_int(2);
    let result2 = c / d;
    assert_eq!(result2.to_i64(), 3, "7 / 2 should be 3 (truncated)");
}

#[test]
#[should_panic(expected = "division by zero")]
fn attack_v9_fixed_point_div_zero_panics() {
    let five = FixedPoint::from_int(5);
    let zero = FixedPoint::ZERO;
    let _ = five / zero;
}

// ========================================================================
// Additional: Merkle tree root collision resistance
// ========================================================================

#[test]
fn attack_v9_merkle_different_leaf_order_different_root() {
    let leaf_a = hash_data(&[0x01]);
    let leaf_b = hash_data(&[0x02]);

    let tree_ab = MerkleTree::build(&[leaf_a, leaf_b]);
    let tree_ba = MerkleTree::build(&[leaf_b, leaf_a]);

    assert_ne!(
        tree_ab.root, tree_ba.root,
        "Different leaf ordering must produce different roots"
    );
}

#[test]
fn attack_v9_merkle_subset_different_root() {
    let leaves: Vec<Hash> = (0..4u8).map(|i| hash_data(&[i])).collect();
    let tree_4 = MerkleTree::build(&leaves);
    let tree_3 = MerkleTree::build(&leaves[..3]);
    let tree_2 = MerkleTree::build(&leaves[..2]);

    assert_ne!(tree_4.root, tree_3.root);
    assert_ne!(tree_3.root, tree_2.root);
    assert_ne!(tree_4.root, tree_2.root);
}
