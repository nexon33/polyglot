//! Round 5 Pentest Attack Tests for poly-verified.
//!
//! Findings:
//! V5-01 CRITICAL: Deserialization bypasses Verified<T> construction guard
//! V5-02 HIGH:     Private mode I/O bypass — attacker skips all I/O binding checks
//! V5-03 HIGH:     Disclosure verification does not verify redacted leaves against Merkle tree
//! V5-04 HIGH:     Blinding commitment is deterministic (not random) — no actual privacy
//! V5-05 MEDIUM:   CompositeProof.verify_composition() uses non-constant-time comparison
//! V5-06 MEDIUM:   VerifiedResponse.verify_value_integrity() uses non-constant-time comparison
//! V5-07 MEDIUM:   Checkpoints included in proof leak full computation trace
//! V5-08 MEDIUM:   Empty inner_proofs in CompositeProof not distinguished from single proof
//! V5-09 LOW:      MerkleProof.from_bytes allows oversized sibling counts (up to 64)
//! V5-10 LOW:      __macro_new Mock guard is ineffective without "mock" feature

use sha2::{Digest, Sha256};

use poly_verified::crypto::hash::{hash_blinding, hash_combine, hash_data};
use poly_verified::disclosure::{create_disclosure, verify_disclosure, DisclosedToken};
use poly_verified::ivc::hash_ivc::HashIvc;
use poly_verified::ivc::IvcBackend;
use poly_verified::proof_composition::CompositeProof;
use poly_verified::proof_serialize::VerifiedResponse;
use poly_verified::types::{
    Hash, MerkleProof, PrivacyMode, StepWitness, VerifiedProof, ZERO_HASH,
};
use poly_verified::verified_type::Verified;

// ========================================================================
// Helpers
// ========================================================================

fn tokens_hash(tokens: &[u32]) -> Hash {
    let mut hasher = Sha256::new();
    for &t in tokens {
        hasher.update(t.to_le_bytes());
    }
    hasher.finalize().into()
}

fn valid_hash_ivc_proof_for_tokens(tokens: &[u32]) -> VerifiedProof {
    let ivc = HashIvc;
    let code_hash = [0x03; 32];
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    acc.input_hash = ZERO_HASH;
    acc.output_hash = tokens_hash(tokens);
    ivc.finalize(acc).unwrap()
}

fn valid_hash_ivc_proof_with_mode(tokens: &[u32], mode: PrivacyMode) -> VerifiedProof {
    let ivc = HashIvc;
    let code_hash = [0x03; 32];
    let mut acc = ivc.init(&code_hash, mode);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    acc.input_hash = ZERO_HASH;
    acc.output_hash = tokens_hash(tokens);
    ivc.finalize(acc).unwrap()
}

fn sample_tokens() -> Vec<u32> {
    vec![100, 200, 300, 400, 500, 600, 700, 800]
}

fn make_verified(tokens: Vec<u32>) -> Verified<Vec<u32>> {
    let proof = valid_hash_ivc_proof_for_tokens(&tokens);
    Verified::__macro_new(tokens, proof)
}

// ========================================================================
// V5-01 CRITICAL (FIXED): Deserialization bypasses Verified<T> construction guard
// ========================================================================
//
// Previously, Verified<T> derived Serialize + Deserialize. An attacker could:
//   1. Serialize a legitimate Verified<T>
//   2. Modify the JSON (change the value, keep the proof)
//   3. Deserialize back into a Verified<T> with forged value
//
// FIX: Removed Deserialize from Verified<T>. Now deserialization fails at
// compile time. This test confirms the fix: serde_json::from_str no longer
// compiles for Verified<T>, so we verify serialization still works but
// demonstrate that the deserialization path is closed.

#[test]
fn fix_v5_01_serialization_still_works() {
    let tokens = sample_tokens();
    let verified = make_verified(tokens.clone());

    // Serialization still works
    let json = serde_json::to_string(&verified).unwrap();
    assert!(json.contains("100"));
    assert!(json.contains("HashIvc"));

    // Deserialization is now a compile error:
    //   let forged: Verified<Vec<u32>> = serde_json::from_str(&json).unwrap();
    // ^ error[E0277]: the trait bound `Verified<Vec<u32>>: Deserialize<'_>` is not satisfied
    //
    // This is the intended behavior. Verified<T> values can only be
    // created through the controlled constructor paths.
}

#[test]
fn fix_v5_01b_mock_proof_deserialization_blocked() {
    // Previously an attacker could craft JSON with a Mock proof and deserialize it.
    // Now Verified<T> does not implement Deserialize, so this is blocked at compile time.
    //
    // The forged JSON:
    //   {"value":[100,200,...],"proof":{"Mock":{"input_hash":[0,...],...}}}
    //
    // Cannot be deserialized into Verified<Vec<u32>> anymore.
    // This test just documents the fix — the compile-time check is the real guard.
    let tokens = sample_tokens();
    let verified = make_verified(tokens);
    let _json = serde_json::to_string(&verified).unwrap();
    // serde_json::from_str::<Verified<Vec<u32>>>(&json) would not compile.
}

// ========================================================================
// V5-02 HIGH: Private mode I/O bypass — full I/O binding skipped
// ========================================================================
//
// In PrivacyMode::Private, verify() skips ALL I/O hash checks (line 179-181
// of hash_ivc.rs). An attacker who crafts a valid Private-mode proof can
// attach it to ANY output tokens, because the output_hash is never verified.
//
// Similarly, verify_disclosure() for Private-mode proofs would skip the
// output_binding check. However, the current verify_disclosure() code does
// NOT pass through privacy_mode to the I/O check — it always checks
// output_binding against output_hash. Let's verify this interaction.

#[test]
fn attack_v5_02_private_mode_allows_any_output_hash() {
    let ivc = HashIvc;
    let code_hash = [0x03; 32];

    // Create a valid Private-mode proof
    let mut acc = ivc.init(&code_hash, PrivacyMode::Private);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();

    // Set output_hash to something specific
    acc.output_hash = hash_data(b"real_output");
    let proof = ivc.finalize(acc).unwrap();

    // Now verify with COMPLETELY WRONG expected hashes — should fail but PASSES
    // because Private mode skips I/O binding entirely
    let wrong_input = hash_data(b"wrong_input");
    let wrong_output = hash_data(b"wrong_output");

    let result = ivc.verify(&proof, &wrong_input, &wrong_output).unwrap();

    // THIS IS THE VULNERABILITY: Private mode accepts ANY expected I/O
    assert!(
        result,
        "Private mode should verify even with wrong expected I/O (this IS the vulnerability)"
    );

    // Impact: If someone creates a Private-mode proof from computation A,
    // they can claim the output was from computation B.
    // The proof carries output_hash internally but the verifier never checks it.
}

#[test]
fn attack_v5_02b_private_disclosure_output_binding_behavior() {
    let tokens_real = vec![100, 200, 300, 400];
    let tokens_fake = vec![999, 888, 777, 666];

    // Create a valid Private-mode proof for the real tokens
    let proof = valid_hash_ivc_proof_with_mode(&tokens_real, PrivacyMode::Private);

    // Attach it to fake tokens
    let verified_fake = Verified::__macro_new(tokens_fake.clone(), proof);
    let disclosure = create_disclosure(&verified_fake, &[0, 1]).unwrap();

    // verify_disclosure checks output_binding against output_hash in the proof.
    // For Private mode, the proof's output_hash was set to tokens_hash(tokens_real),
    // but disclosure.output_binding = tokens_hash(tokens_fake).
    // This SHOULD fail because the binding doesn't match.
    let result = verify_disclosure(&disclosure);

    // Note: The disclosure verification DOES check output_binding even for Private
    // mode (it calls ivc.verify which skips I/O, but also directly checks
    // output_binding == output_hash). Let's verify the actual behavior.
    //
    // Looking at the code: verify_disclosure passes output_hash as expected_output
    // to ivc.verify(), which in Private mode SKIPS the check. BUT verify_disclosure
    // ALSO does a direct hash_eq(&disclosure.output_binding, output_hash) check
    // BEFORE calling ivc.verify(). So the binding check still happens.
    //
    // However, there's a subtle issue: for Private mode, the ivc.verify() call
    // passes input_hash as expected_input, which means the verifier can't
    // distinguish between proofs for different inputs.
    assert!(
        !result,
        "Private disclosure with wrong tokens should fail binding check"
    );
}

// ========================================================================
// V5-03 HIGH: Redacted leaf hashes not verified against Merkle tree
// ========================================================================
//
// verify_disclosure() only checks that redacted leaf_hash != ZERO_HASH.
// It does NOT verify that the redacted leaf_hash is actually the correct
// Merkle leaf for that position. An attacker can:
//   1. Get a valid disclosure with some revealed and some redacted tokens
//   2. Replace redacted leaf_hash values with arbitrary non-zero hashes
//   3. Verification still passes
//
// This means the attacker can claim a different number of redacted tokens
// exist, or that different tokens were redacted, without detection.

#[test]
fn fix_v5_03_redacted_leaf_hash_substitution_now_fails() {
    let verified = make_verified(sample_tokens());
    let mut disclosure = create_disclosure(&verified, &[0]).unwrap();

    // Replace ALL redacted leaf hashes with arbitrary values
    for i in 1..disclosure.tokens.len() {
        if let DisclosedToken::Redacted { index, .. } = &disclosure.tokens[i] {
            disclosure.tokens[i] = DisclosedToken::Redacted {
                index: *index,
                leaf_hash: [0xDE; 32], // completely fake
            };
        }
    }

    // [FIXED] Now fails because verify_disclosure reconstructs the Merkle tree
    // from ALL leaves (revealed + redacted) and checks the root matches output_root.
    // The fake leaf hashes produce a different root.
    let result = verify_disclosure(&disclosure);
    assert!(
        !result,
        "Tampered redacted leaf hashes should now FAIL verification (V5-03 fixed)"
    );
}

#[test]
fn fix_v5_03b_forged_output_root_now_fails() {
    // Previously, the output_root was never verified against the token leaves
    // when there were no revealed tokens (fully private disclosure).
    let verified = make_verified(sample_tokens());
    let mut disclosure = create_disclosure(&verified, &[]).unwrap();

    let _original_root = disclosure.output_root;
    disclosure.output_root = [0xFF; 32]; // forge the root

    // [FIXED] Now fails because verify_disclosure reconstructs the Merkle tree
    // from all redacted leaf hashes and checks root matches output_root.
    let result = verify_disclosure(&disclosure);
    assert!(
        !result,
        "Forged output_root should now FAIL verification (V5-03b fixed)"
    );
}

// ========================================================================
// V5-04 HIGH: Blinding is deterministic, not random — no actual privacy
// ========================================================================
//
// The "blinding" in Private/PrivateInputs modes is computed as:
//   hash_blinding(transition || step_counter)
//
// This is FULLY DETERMINISTIC — it depends only on the checkpoints which
// are already in the proof. An attacker who sees a Private-mode proof can:
//   1. Extract the checkpoints from the proof
//   2. Recompute the blinding commitment exactly
//   3. Verify it matches — confirming the computation trace
//
// The blinding provides ZERO additional privacy because:
// - The checkpoints are stored in the proof in cleartext
// - The blinding is derived deterministically from the checkpoints
// - There is no external randomness (no nonce, no secret key)

#[test]
fn attack_v5_04_blinding_is_deterministic() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"secret_fn");

    // Create two identical Private-mode proofs
    let make_proof = || {
        let mut acc = ivc.init(&code_hash, PrivacyMode::Private);
        let witness = StepWitness {
            state_before: hash_data(b"state0"),
            state_after: hash_data(b"state1"),
            step_inputs: hash_data(b"data"),
        };
        ivc.fold_step(&mut acc, &witness).unwrap();
        acc.output_hash = hash_data(b"output");
        ivc.finalize(acc).unwrap()
    };

    let proof1 = make_proof();
    let proof2 = make_proof();

    match (&proof1, &proof2) {
        (
            VerifiedProof::HashIvc {
                blinding_commitment: bc1,
                ..
            },
            VerifiedProof::HashIvc {
                blinding_commitment: bc2,
                ..
            },
        ) => {
            // Blinding commitments are IDENTICAL for same computation
            assert_eq!(
                bc1, bc2,
                "Blinding should be deterministic (this confirms the vulnerability)"
            );
        }
        _ => panic!("wrong proof types"),
    }
}

#[test]
fn attack_v5_04b_attacker_can_recompute_blinding_from_checkpoints() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"secret_fn");

    let mut acc = ivc.init(&code_hash, PrivacyMode::Private);
    let witness = StepWitness {
        state_before: hash_data(b"state0"),
        state_after: hash_data(b"state1"),
        step_inputs: hash_data(b"data"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    acc.output_hash = hash_data(b"output");
    let proof = ivc.finalize(acc).unwrap();

    match &proof {
        VerifiedProof::HashIvc {
            blinding_commitment,
            checkpoints,
            ..
        } => {
            // Attacker recomputes blinding from the public checkpoints
            let mut recomputed = ZERO_HASH;
            for (i, cp) in checkpoints.iter().enumerate() {
                let counter = ((i + 1) as u64).to_le_bytes();
                let mut blinding_input = Vec::with_capacity(40);
                blinding_input.extend_from_slice(cp);
                blinding_input.extend_from_slice(&counter);
                let blinding = hash_blinding(&blinding_input);
                recomputed = hash_combine(&recomputed, &blinding);
            }

            assert_eq!(
                blinding_commitment.as_ref().unwrap(),
                &recomputed,
                "Attacker can recompute blinding commitment from public data"
            );
            // Impact: The blinding commitment adds zero privacy.
            // It's verifiable (good) but not hiding (bad).
        }
        _ => panic!("wrong proof type"),
    }
}

// ========================================================================
// V5-05 MEDIUM: CompositeProof.verify_composition() non-constant-time
// ========================================================================
//
// proof_composition.rs line 73:
//   expected == self.composition_hash
//
// This uses Rust's default PartialEq for [u8; 32], which short-circuits.
// All other hash comparisons in the codebase use hash_eq() for constant-time.

#[test]
fn attack_v5_05_composite_proof_timing() {
    let outer = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let composite = CompositeProof::compose(outer, vec![]);

    // Functional test: composition should verify
    assert!(composite.verify_composition());

    // Tamper test: should fail
    let mut tampered = composite.clone();
    tampered.composition_hash[0] ^= 0xFF;
    assert!(!tampered.verify_composition());

    // NOTE: The vulnerability is the use of == instead of hash_eq()
    // which leaks information about the hash prefix via timing.
    // This is a medium-severity issue as it requires precise timing
    // measurements which are often impractical remotely.
}

// ========================================================================
// V5-06 MEDIUM: VerifiedResponse.verify_value_integrity() non-constant-time
// ========================================================================
//
// proof_serialize.rs line 134:
//   hash_data(&self.value_bytes) == self.value_hash
//
// Uses default == instead of hash_eq().

#[test]
fn attack_v5_06_verified_response_timing() {
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let value_bytes = b"test value".to_vec();
    let response = VerifiedResponse::new(&proof, ZERO_HASH, value_bytes, ZERO_HASH);

    // Should verify
    assert!(response.verify_value_integrity());

    // NOTE: The vulnerability is == instead of constant-time comparison.
    // Same severity as V5-05.
}

// ========================================================================
// V5-07 MEDIUM: Checkpoints in proof leak full computation trace
// ========================================================================
//
// VerifiedProof::HashIvc includes `checkpoints: Vec<Hash>` which contains
// every step's transition hash. In Private/PrivateInputs modes, this leaks
// the computation trace even though the mode claims to hide information.
//
// Each checkpoint = hash_transition(state_before, step_inputs, state_after)
// While not directly invertible, having ALL transition hashes allows:
// - Counting exact number of computation steps
// - Comparing traces between proofs to detect identical computations
// - Potential correlation attacks if attacker knows partial input

#[test]
fn attack_v5_07_private_mode_leaks_checkpoints() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"secret_fn");

    let mut acc = ivc.init(&code_hash, PrivacyMode::Private);

    // Feed 5 distinct steps
    for i in 0..5u8 {
        let witness = StepWitness {
            state_before: hash_data(&[i]),
            state_after: hash_data(&[i + 1]),
            step_inputs: hash_data(&[i * 2]),
        };
        ivc.fold_step(&mut acc, &witness).unwrap();
    }
    acc.output_hash = hash_data(b"output");
    let proof = ivc.finalize(acc).unwrap();

    match &proof {
        VerifiedProof::HashIvc {
            checkpoints,
            privacy_mode,
            ..
        } => {
            assert_eq!(*privacy_mode, PrivacyMode::Private);
            // Private mode still exposes all 5 checkpoint hashes
            assert_eq!(checkpoints.len(), 5);
            // Each checkpoint is unique and reveals computation structure
            for i in 0..5 {
                assert_ne!(checkpoints[i], ZERO_HASH);
                for j in (i + 1)..5 {
                    assert_ne!(
                        checkpoints[i], checkpoints[j],
                        "Checkpoints should be unique (leaks computation structure)"
                    );
                }
            }
        }
        _ => panic!("wrong proof type"),
    }
    // Impact: "Private" mode is not truly private — the computation trace
    // is fully exposed. The only thing hidden is the I/O binding.
}

// ========================================================================
// V5-08 MEDIUM: CompositeProof with empty inner_proofs is ambiguous
// ========================================================================
//
// A CompositeProof with inner_proofs = [] is indistinguishable from
// a standalone proof, but the composition_hash is different. An attacker
// could wrap any standalone proof in a CompositeProof to change its
// identity hash without changing the underlying proof.

#[test]
fn attack_v5_08_composite_wrapping_attack() {
    let proof_a = VerifiedProof::Mock {
        input_hash: hash_data(b"input"),
        output_hash: hash_data(b"output"),
        privacy_mode: PrivacyMode::Transparent,
    };
    let proof_b = proof_a.clone();

    // Same proof, wrapped vs unwrapped
    let composite = CompositeProof::compose(proof_a, vec![]);
    assert_eq!(composite.proof_count(), 1);
    assert!(composite.verify_composition());

    // The composite's composition_hash is different from just
    // hash_data(serde_json::to_vec(&proof_b))
    let _direct_hash = hash_data(&serde_json::to_vec(&proof_b).unwrap());
    // With no inner proofs, composition_hash = hash_data(outer_bytes)
    // which happens to be the same. But if we nest composites:
    let nested = CompositeProof::compose(
        VerifiedProof::Mock {
            input_hash: ZERO_HASH,
            output_hash: ZERO_HASH,
            privacy_mode: PrivacyMode::Transparent,
        },
        vec![proof_b],
    );
    assert!(nested.verify_composition());

    // verify_composition only checks the hash binding — it does NOT verify
    // the individual proofs inside. An attacker can compose invalid proofs.
    let invalid_inner = VerifiedProof::HashIvc {
        chain_tip: [0xFF; 32],
        merkle_root: [0xAA; 32],
        step_count: 999,
        code_hash: [0xBB; 32],
        privacy_mode: PrivacyMode::Transparent,
        blinding_commitment: None,
        checkpoints: vec![], // mismatches step_count
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
    };
    let bad_composite = CompositeProof::compose(
        VerifiedProof::Mock {
            input_hash: ZERO_HASH,
            output_hash: ZERO_HASH,
            privacy_mode: PrivacyMode::Transparent,
        },
        vec![invalid_inner],
    );
    // verify_composition passes because it only checks the composition hash
    assert!(
        bad_composite.verify_composition(),
        "CompositeProof accepts invalid inner proofs"
    );
}

// ========================================================================
// V5-09 LOW: MerkleProof.from_bytes allows up to 64 siblings
// ========================================================================
//
// 64 siblings means a tree with 2^64 leaves, which is absurd.
// A more reasonable limit would be ~40 (2^40 = 1 trillion leaves).
// While this doesn't enable a direct exploit, it allows an attacker
// to craft proofs that waste verifier memory and CPU time.

#[test]
fn attack_v5_09_oversized_sibling_count() {
    // Craft a proof with 64 siblings (maximum allowed)
    let mut data = vec![0u8; 108 + 33 * 64];
    // Set sibling_count = 64 (at offset 40..44, big-endian)
    data[40..44].copy_from_slice(&64u32.to_be_bytes());
    // Fill in siblings with valid is_left bytes
    for i in 0..64 {
        let offset = 44 + 33 * i;
        data[offset + 32] = 0x00; // is_left = false
    }

    let result = MerkleProof::from_bytes(&data);
    assert!(result.is_ok(), "64 siblings should be accepted");

    // sibling_count = 65 should be rejected
    let mut data65 = vec![0u8; 108 + 33 * 65];
    data65[40..44].copy_from_slice(&65u32.to_be_bytes());
    for i in 0..65 {
        let offset = 44 + 33 * i;
        data65[offset + 32] = 0x00;
    }
    let result65 = MerkleProof::from_bytes(&data65);
    assert!(result65.is_err(), "65 siblings should be rejected");

    // A reasonable max for any practical system would be ~40
    // (supports trees with over 1 trillion leaves)
}

// ========================================================================
// V5-10 LOW: __macro_new Mock guard only active with "mock" feature
// ========================================================================
//
// The guard in __macro_new that rejects Mock proofs is gated behind:
//   #[cfg(all(feature = "mock", not(test)))]
//
// Without the "mock" feature enabled (which is the default for production),
// the guard is completely absent. Mock proofs are always accepted because
// the VerifiedProof enum always includes the Mock variant (it's not
// feature-gated). This means in production builds without the mock feature,
// __macro_new happily accepts Mock proofs.

#[test]
fn attack_v5_10_mock_proof_accepted_in_default_build() {
    let mock_proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };

    // This should be rejected in production but is accepted
    // (We're in a test build, but the point is that without the "mock" feature
    // AND not in test mode, the guard doesn't exist at all)
    let verified = Verified::__macro_new(42u64, mock_proof);
    assert_eq!(*verified.value(), 42);

    // The real fix: the Mock variant should be gated behind cfg(test) or
    // cfg(feature = "mock") in the VerifiedProof enum itself, not just
    // in the constructor guard.
}

// ========================================================================
// Additional: Cross-proof confusion via output_hash collision
// ========================================================================
// Two different computations with the same output_hash would have
// interchangeable proofs for disclosure purposes, since disclosure
// only binds via output_hash (tokens_hash).

#[test]
fn attack_cross_proof_same_output_different_computation() {
    let tokens = vec![100, 200, 300];
    let ivc = HashIvc;

    // Computation A: different code_hash, same output tokens
    let code_a = hash_data(b"function_a");
    let mut acc_a = ivc.init(&code_a, PrivacyMode::Transparent);
    let witness_a = StepWitness {
        state_before: hash_data(b"a_before"),
        state_after: hash_data(b"a_after"),
        step_inputs: hash_data(b"a_inputs"),
    };
    ivc.fold_step(&mut acc_a, &witness_a).unwrap();
    acc_a.output_hash = tokens_hash(&tokens);
    acc_a.input_hash = ZERO_HASH;
    let proof_a = ivc.finalize(acc_a).unwrap();

    // Computation B: different code and steps, but same output tokens
    let code_b = hash_data(b"function_b");
    let mut acc_b = ivc.init(&code_b, PrivacyMode::Transparent);
    let witness_b = StepWitness {
        state_before: hash_data(b"b_before"),
        state_after: hash_data(b"b_after"),
        step_inputs: hash_data(b"b_inputs"),
    };
    ivc.fold_step(&mut acc_b, &witness_b).unwrap();
    acc_b.output_hash = tokens_hash(&tokens);
    acc_b.input_hash = ZERO_HASH;
    let proof_b = ivc.finalize(acc_b).unwrap();

    // Create disclosure from proof_a
    let verified_a = Verified::__macro_new(tokens.clone(), proof_a.clone());
    let disclosure_a = create_disclosure(&verified_a, &[0, 1]).unwrap();
    assert!(verify_disclosure(&disclosure_a));

    // Now create disclosure using proof_b's execution proof but same tokens
    // (attacker swaps which computation allegedly produced the output)
    let mut franken_disclosure = disclosure_a.clone();
    franken_disclosure.execution_proof = proof_b;

    // This should FAIL because the chain_tip/merkle_root in proof_b
    // are from a different computation than proof_a, and the IVC verify
    // will check them. BUT the output_hash matches.
    let result = verify_disclosure(&franken_disclosure);

    // The IVC verify will pass because it only checks internal consistency
    // of proof_b (which is self-consistent). The output_binding matches
    // proof_b's output_hash. So this actually PASSES.
    // The verifier cannot distinguish which function produced the output.
    //
    // This is mitigated by code_hash binding — the verifier should check
    // disclosure.execution_proof.code_hash() against a known expected value.
    // But verify_disclosure() itself does not enforce this.
    if result {
        // The franken-disclosure passes because:
        // 1. proof_b is internally consistent (chain, merkle, blinding all match)
        // 2. proof_b.output_hash == tokens_hash(tokens) == disclosure.output_binding
        // 3. verify_disclosure doesn't check code_hash against any expected value
    }
}

// ========================================================================
// Additional: Disclosure detachment from specific computation identity
// ========================================================================
// verify_disclosure does not require the caller to specify which code_hash
// they expect. This means any valid proof with matching output_hash works.

#[test]
fn attack_disclosure_no_code_hash_enforcement() {
    let tokens = sample_tokens();
    let verified = make_verified(tokens.clone());
    let disclosure = create_disclosure(&verified, &[0, 1, 2]).unwrap();

    // The disclosure carries execution_proof which has code_hash [0x03; 32]
    // But verify_disclosure() never asks "what code_hash do you expect?"
    // It only checks internal consistency.
    assert!(verify_disclosure(&disclosure));

    // A verifier who doesn't manually check code_hash cannot know
    // which function produced these tokens.
    match &disclosure.execution_proof {
        VerifiedProof::HashIvc { code_hash, .. } => {
            // The code_hash is available but not enforced
            assert_ne!(*code_hash, ZERO_HASH);
            // Verifier MUST manually check:
            //   disclosure.execution_proof.code_hash() == expected_code_hash
            // But the API doesn't force this.
        }
        _ => {}
    }
}
