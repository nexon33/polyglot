//! Round 7 Pentest Attack Tests for poly-verified.
//!
//! Findings:
//! V7-01 CRITICAL: VerifiedResponse::new() silently swallows proof serialization failures
//! V7-02 HIGH:     Verified::flatten() silently discards inner proof (security downgrade)
//! V7-03 HIGH:     Disclosure leaf_index not validated (Merkle proof position spoofing)
//! V7-04 HIGH:     VerifiedResponse::from_bytes allows unbounded proof_len (OOM DoS)
//! V7-05 MEDIUM:   CompositeProof::verify_composition accepts structurally invalid proofs
//! V7-06 MEDIUM:   FixedPoint::from_decimal panics on large decimal_places (DoS)
//! V7-07 MEDIUM:   FixedPoint::from_int overflows silently for extreme i64 values
//! V7-08 MEDIUM:   Verified::is_verified() returns true for Mock proofs in production
//! V7-09 MEDIUM:   Disclosure token count mismatch allows inflation via total_tokens field
//! V7-10 LOW:      CompositeProof composition_hash is order-dependent on inner_proofs
//! V7-11 LOW:      VerifiedProof::code_hash() leaks real code_hash in struct even in Private mode
//! V7-12 LOW:      HashChain::append wraps on u64 overflow (step_count becomes 0)

use sha2::{Digest, Sha256};

use poly_verified::crypto::hash::hash_data;
use poly_verified::crypto::merkle::MerkleTree;
use poly_verified::disclosure::{
    create_disclosure, disclosure_output_hash, token_leaf, verify_disclosure, DisclosedToken,
};
use poly_verified::fixed_point::FixedPoint;
use poly_verified::ivc::hash_ivc::HashIvc;
use poly_verified::ivc::IvcBackend;
use poly_verified::proof_composition::CompositeProof;
use poly_verified::proof_serialize::VerifiedResponse;
use poly_verified::types::{
    hash_eq, Hash, PrivacyMode, ProofNode, StepWitness, VerifiedProof, ZERO_HASH,
};
use poly_verified::verified_type::Verified;

// ========================================================================
// Helpers
// ========================================================================

fn tokens_hash(tokens: &[u32]) -> Hash {
    let mut hasher = Sha256::new();
    for &t in tokens {
        hasher.update(t.to_le_bytes());
    }
    hasher.finalize().into()
}

fn valid_hash_ivc_proof_for_tokens(tokens: &[u32]) -> VerifiedProof {
    let ivc = HashIvc;
    let code_hash = [0x03; 32];
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    acc.input_hash = ZERO_HASH;
    acc.output_hash = disclosure_output_hash(tokens);
    ivc.finalize(acc).unwrap()
}

fn make_verified(tokens: Vec<u32>) -> Verified<Vec<u32>> {
    let proof = valid_hash_ivc_proof_for_tokens(&tokens);
    Verified::__macro_new(tokens, proof)
}

fn sample_tokens() -> Vec<u32> {
    vec![100, 200, 300, 400, 500, 600, 700, 800]
}

/// Build a valid multi-step HashIvc proof.
fn make_multistep_proof(steps: u8) -> VerifiedProof {
    let ivc = HashIvc;
    let code_hash = hash_data(b"multistep_test");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    for i in 0..steps {
        let witness = StepWitness {
            state_before: hash_data(&[i]),
            state_after: hash_data(&[i + 1]),
            step_inputs: hash_data(&[i * 2]),
        };
        ivc.fold_step(&mut acc, &witness).unwrap();
    }
    ivc.finalize(acc).unwrap()
}

// ========================================================================
// V7-01 CRITICAL (FIXED): VerifiedResponse::new() swallows serialization failure
// ========================================================================
//
// VerifiedResponse::new() used `serde_json::to_vec(proof).unwrap_or_default()`
// which silently produces empty proof_bytes on serialization failure.
// This was fixed in CompositeProof (V6-04) but NOT in VerifiedResponse.
//
// Impact: If serialization ever failed (e.g., due to a future VerifiedProof
// variant with non-serializable data), the response would contain empty
// proof_bytes. A receiver calling verify_value_integrity() would still pass
// (it only checks value_hash), and the proof would be silently absent.
//
// FIX: Changed to expect() with a clear panic message.

#[test]
fn fix_v7_01_verified_response_serialization_succeeds() {
    // Verify that normal proof serialization still works after the fix.
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let response = VerifiedResponse::new(&proof, ZERO_HASH, b"data".to_vec(), ZERO_HASH);
    assert!(
        !response.proof_bytes.is_empty(),
        "proof_bytes should not be empty for a valid proof"
    );

    let bytes = response.to_bytes();
    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();
    assert!(decoded.verify_value_integrity());
    assert_eq!(decoded.value_bytes, b"data");
}

#[test]
fn fix_v7_01b_hash_ivc_proof_serializes() {
    let proof = make_multistep_proof(3);
    let response = VerifiedResponse::new(&proof, ZERO_HASH, b"test".to_vec(), ZERO_HASH);
    assert!(
        !response.proof_bytes.is_empty(),
        "HashIvc proof should serialize successfully"
    );

    // Verify roundtrip
    let bytes = response.to_bytes();
    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();
    assert!(decoded.verify_value_integrity());
}

// ========================================================================
// V7-02 HIGH: Verified::flatten() discards inner proof (security downgrade)
// ========================================================================
//
// When Verified<Verified<T>> is flattened, the outer proof is kept and the
// inner proof is discarded. This means:
//   1. An outer function with a weak Mock proof wraps an inner function
//      with a strong HashIvc proof.
//   2. After flatten(), only the weak Mock proof remains.
//   3. The consumer sees a Verified<T> with a Mock proof and may trust it.
//
// This is a design issue, not a crypto break, but it violates the principle
// of least surprise: the strongest proof should survive.

#[test]
fn attack_v7_02_flatten_discards_stronger_inner_proof() {
    let inner_proof = make_multistep_proof(5);
    let inner = Verified::__macro_new(42u64, inner_proof);

    // Wrap with a weak Mock proof
    let outer_proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let outer = Verified::__macro_new(inner, outer_proof);

    // Before flatten: inner has HashIvc proof (strong)
    assert!(matches!(
        outer.value().proof(),
        VerifiedProof::HashIvc { .. }
    ));

    // After flatten: only Mock proof survives (weak)
    let flat = outer.flatten();
    assert_eq!(*flat.value(), 42);
    assert!(
        matches!(flat.proof(), VerifiedProof::Mock { .. }),
        "flatten() discards the inner HashIvc proof, keeping only the outer Mock proof"
    );
    // The consumer now has a Verified<u64> with a Mock proof, which provides
    // no cryptographic guarantee. The strong inner proof is gone.
}

#[test]
fn attack_v7_02b_flatten_proof_identity() {
    // Verify that flatten always keeps the OUTER proof, not the inner.
    let inner_proof = VerifiedProof::Mock {
        input_hash: [0x01; 32],
        output_hash: [0x02; 32],
        privacy_mode: PrivacyMode::Transparent,
    };
    let outer_proof = VerifiedProof::Mock {
        input_hash: [0xAA; 32],
        output_hash: [0xBB; 32],
        privacy_mode: PrivacyMode::Transparent,
    };

    let inner = Verified::__macro_new(99u64, inner_proof);
    let outer = Verified::__macro_new(inner, outer_proof);
    let flat = outer.flatten();

    // The flat proof should be the OUTER proof (0xAA/0xBB), not inner (0x01/0x02)
    match flat.proof() {
        VerifiedProof::Mock {
            input_hash,
            output_hash,
            ..
        } => {
            assert_eq!(*input_hash, [0xAA; 32]);
            assert_eq!(*output_hash, [0xBB; 32]);
        }
        _ => panic!("Expected Mock proof"),
    }
}

// ========================================================================
// V7-03 HIGH (FIXED): Disclosure leaf_index not validated
// ========================================================================
//
// verify_disclosure() checks that each Merkle proof verifies against the
// output_root, and that the leaf matches the token. However, it did NOT
// check that the proof's leaf_index matches the actual position of the
// token in the disclosure.
//
// Attack: An attacker creates a valid disclosure, then swaps the Merkle
// proofs between two revealed positions. Each proof individually verifies
// (correct leaf, correct root), but the proofs are for the WRONG positions.
//
// Impact: Position spoofing. Token at index 2 could be presented with the
// proof for index 5, making the verifier believe it's at position 5.
//
// FIX: Added leaf_index check in verify_disclosure.

#[test]
fn fix_v7_03_leaf_index_mismatch_now_rejected() {
    let tokens = vec![100, 200, 300, 400, 500, 600, 700, 800];
    let verified = make_verified(tokens);
    let mut disclosure = create_disclosure(&verified, &[2, 5]).unwrap();

    // Verify original works
    assert!(verify_disclosure(&disclosure));

    // Attack: swap the Merkle proofs for positions 2 and 5.
    // Both proofs are individually valid (correct leaf, correct root),
    // but they are for the wrong positions.
    assert_eq!(disclosure.proofs.len(), 2);
    disclosure.proofs.swap(0, 1);

    // [FIXED] Now fails because leaf_index in each proof doesn't match
    // the token position it's associated with.
    assert!(
        !verify_disclosure(&disclosure),
        "Swapped Merkle proofs should now fail (V7-03 leaf_index validation)"
    );
}

#[test]
fn fix_v7_03b_forged_leaf_index_rejected() {
    let tokens = vec![100, 200, 300, 400];
    let verified = make_verified(tokens);
    let mut disclosure = create_disclosure(&verified, &[1]).unwrap();

    // Tamper: change the proof's leaf_index to a different position
    assert_eq!(disclosure.proofs[0].leaf_index, 1);
    disclosure.proofs[0].leaf_index = 3; // claim it's for position 3

    // [FIXED] Now fails because leaf_index doesn't match actual position
    assert!(
        !verify_disclosure(&disclosure),
        "Forged leaf_index should be rejected (V7-03 fix)"
    );
}

#[test]
fn fix_v7_03c_original_disclosure_still_valid() {
    // Regression: ensure the fix doesn't break normal disclosures
    let verified = make_verified(sample_tokens());
    let disclosure = create_disclosure(&verified, &[0, 3, 7]).unwrap();
    assert!(verify_disclosure(&disclosure));
}

// ========================================================================
// V7-04 HIGH (FIXED): VerifiedResponse::from_bytes unbounded proof_len
// ========================================================================
//
// proof_len is read as u32 (up to 4,294,967,295 bytes = ~4 GiB).
// An attacker sending a crafted wire message with proof_len = 0xFFFFFFFF
// causes the receiver to attempt allocating ~4 GiB for proof_bytes,
// leading to OOM and denial of service.
//
// FIX: Added a 16 MiB cap on proof_len in from_bytes().

#[test]
fn fix_v7_04_proof_len_cap_enforced() {
    // Craft a message claiming proof_len > 16 MiB
    let mut data = vec![0u8; 134]; // minimum valid size
    data[96] = 0x00; // BackendId::Mock
    data[97] = 0x00; // PrivacyMode::Transparent
    // Set proof_len to 32 MiB (0x02000000)
    data[98..102].copy_from_slice(&0x02000000u32.to_be_bytes());

    let result = VerifiedResponse::from_bytes(&data);
    assert!(
        result.is_err(),
        "proof_len > 16 MiB should be rejected to prevent OOM"
    );
}

#[test]
fn fix_v7_04b_proof_len_max_u32_rejected() {
    // Extreme case: proof_len = u32::MAX
    let mut data = vec![0u8; 134];
    data[96] = 0x00;
    data[97] = 0x00;
    data[98..102].copy_from_slice(&u32::MAX.to_be_bytes());

    let result = VerifiedResponse::from_bytes(&data);
    assert!(
        result.is_err(),
        "proof_len = u32::MAX should be rejected"
    );
}

#[test]
fn fix_v7_04c_reasonable_proof_len_accepted() {
    // A normal proof should still work
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let response = VerifiedResponse::new(&proof, ZERO_HASH, b"value".to_vec(), ZERO_HASH);
    let bytes = response.to_bytes();
    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();
    assert_eq!(decoded.value_bytes, b"value");
}

// ========================================================================
// V7-05 MEDIUM (FIXED): CompositeProof accepts structurally invalid proofs
// ========================================================================
//
// verify_composition() only checked the composition hash binding. It did
// NOT validate that each contained proof was structurally valid.
// An attacker could compose invalid proofs (step_count mismatch, empty
// checkpoints) and verify_composition() would return true.
//
// FIX: verify_composition() now checks structural validity of all proofs.

#[test]
fn fix_v7_05_invalid_outer_proof_rejected() {
    let invalid_outer = VerifiedProof::HashIvc {
        chain_tip: [0xFF; 32],
        merkle_root: [0xAA; 32],
        step_count: 0, // invalid: zero steps
        code_hash: [0xBB; 32],
        privacy_mode: PrivacyMode::Transparent,
        blinding_commitment: None,
        checkpoints: vec![],
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
    };
    let composite = CompositeProof::compose(invalid_outer, vec![]);
    assert!(
        !composite.verify_composition(),
        "CompositeProof with invalid outer proof (step_count=0) should fail"
    );
}

#[test]
fn fix_v7_05b_invalid_inner_proof_rejected() {
    let valid_outer = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let invalid_inner = VerifiedProof::HashIvc {
        chain_tip: [0xFF; 32],
        merkle_root: [0xAA; 32],
        step_count: 100,
        code_hash: [0xBB; 32],
        privacy_mode: PrivacyMode::Transparent,
        blinding_commitment: None,
        checkpoints: vec![[0x01; 32]], // only 1 checkpoint but step_count=100
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
    };
    let composite = CompositeProof::compose(valid_outer, vec![invalid_inner]);
    assert!(
        !composite.verify_composition(),
        "CompositeProof with invalid inner proof should fail"
    );
}

#[test]
fn fix_v7_05c_valid_composite_still_works() {
    let outer = make_multistep_proof(2);
    let inner = make_multistep_proof(3);
    let composite = CompositeProof::compose(outer, vec![inner]);
    assert!(composite.verify_composition());
    assert_eq!(composite.proof_count(), 2);
}

// ========================================================================
// V7-06 MEDIUM (FIXED): FixedPoint::from_decimal panics on large decimal_places
// ========================================================================
//
// 10i128.pow(39) overflows i128 (10^38 = 1e38 > i128::MAX ~ 1.7e38).
// An attacker providing decimal_places >= 39 causes a panic in pow().
//
// FIX: Cap decimal_places at 38, return ZERO for larger values.
// Also use checked_mul for the numerator.

#[test]
fn fix_v7_06_large_decimal_places_no_panic() {
    // Previously panicked due to 10i128.pow(39) overflow
    let result = FixedPoint::from_decimal(100, 39);
    assert_eq!(result.raw(), 0, "decimal_places >= 38 should return ZERO");

    let result2 = FixedPoint::from_decimal(1, 100);
    assert_eq!(result2.raw(), 0, "decimal_places=100 should return ZERO");

    let result3 = FixedPoint::from_decimal(1, u32::MAX);
    assert_eq!(result3.raw(), 0, "decimal_places=u32::MAX should return ZERO");
}

#[test]
fn fix_v7_06b_normal_decimal_unaffected() {
    // Verify the fix doesn't break normal usage
    let half = FixedPoint::from_decimal(50, 2); // 0.50
    let result = half * FixedPoint::from_int(100);
    assert_eq!(result.to_i64(), 50);

    let precise = FixedPoint::from_decimal(123456, 5); // 1.23456
    assert_eq!(precise.to_i64(), 1);
}

#[test]
fn fix_v7_06c_decimal_places_37_works() {
    // 10^37 is within i128 range, should work
    let result = FixedPoint::from_decimal(1, 37);
    // 1 * SCALE / 10^37 is very small but should not panic
    assert!(result.raw() >= 0);
}

// ========================================================================
// V7-07 MEDIUM: FixedPoint::from_int overflow for extreme i64 values
// ========================================================================
//
// from_int multiplies by SCALE (2^48) using unchecked multiplication.
// For i64::MAX * 2^48, the result overflows i128:
//   i64::MAX * 2^48 = (2^63 - 1) * 2^48 = ~2^111 which fits in i128.
// Actually: i128::MAX ~ 2^127, so i64::MAX * 2^48 < 2^112 < 2^127.
// So this is safe for i64. But u64::MAX (via From<u64>):
//   u64::MAX * 2^48 = (2^64 - 1) * 2^48 ~ 2^112, still fits.
//
// However, the From<u64> impl uses `v as i128` which is wrong for
// values > i64::MAX because u64 to i128 is zero-extended but
// the multiplication could still overflow for values near u64::MAX.
// Let's verify the boundary behavior.

#[test]
fn attack_v7_07_from_int_extreme_values() {
    // i64::MAX * 2^48 should fit in i128
    let max = FixedPoint::from_int(i64::MAX);
    assert!(max.raw() > 0, "i64::MAX should produce positive FixedPoint");
    assert_eq!(max.to_i64(), i64::MAX);

    // i64::MIN * 2^48 should also fit
    let min = FixedPoint::from_int(i64::MIN);
    assert!(min.raw() < 0, "i64::MIN should produce negative FixedPoint");
    assert_eq!(min.to_i64(), i64::MIN);
}

#[test]
fn attack_v7_07b_from_u64_extreme_values() {
    // u64::MAX via From<u64>
    let max_u64: FixedPoint = u64::MAX.into();
    // u64::MAX as i128 = 18446744073709551615
    // * 2^48 = 18446744073709551615 * 281474976710656 ~ 5.19e33
    // i128::MAX ~ 1.7e38, so it fits
    assert!(max_u64.raw() > 0, "u64::MAX should produce positive FixedPoint");

    // But to_i64 will truncate since the value > i64::MAX
    let as_i64 = max_u64.to_i64();
    // (u64::MAX as i128 * SCALE) / SCALE = u64::MAX as i128 ~ i64::MAX
    // Actually (u64::MAX as i128) = 18446744073709551615
    // (18446744073709551615 as i64) wraps to -1
    // This is a known truncation behavior
    assert_eq!(as_i64, -1, "u64::MAX as i64 wraps to -1 (known truncation)");
}

// ========================================================================
// V7-08 MEDIUM (FIXED): is_verified() returns true for Mock in production
// ========================================================================
//
// Verified::is_verified() returned `true` for Mock proofs unconditionally.
// In production code, Mock proofs should not be considered "verified" since
// they provide no cryptographic guarantee.
//
// FIX: In non-test builds, Mock proofs return false from is_verified().
// In test builds (like these tests), Mock proofs still return true
// for testing convenience.

#[test]
fn fix_v7_08_is_verified_mock_rejected_in_production() {
    // [V7-08 FIXED] In integration tests (which compile the library without
    // cfg(test)), Mock proofs are correctly rejected by is_verified().
    // Only unit tests within the library crate or builds with feature="mock"
    // accept Mock proofs.
    let mock_proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let v = Verified::__macro_new(42u64, mock_proof);
    // Integration test = library compiled without cfg(test) and without mock feature
    assert!(
        !v.is_verified(),
        "Mock proof should be rejected in production (non-test, non-mock) builds"
    );
}

#[test]
fn fix_v7_08b_is_verified_hash_ivc() {
    let proof = make_multistep_proof(3);
    let v = Verified::__macro_new(42u64, proof);
    assert!(v.is_verified(), "HashIvc proof with step_count > 0 should be verified");
}

#[test]
fn fix_v7_08c_is_verified_zero_step_hash_ivc() {
    // A HashIvc proof with step_count = 0 should not be considered verified
    let proof = VerifiedProof::HashIvc {
        chain_tip: ZERO_HASH,
        merkle_root: ZERO_HASH,
        step_count: 0,
        code_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
        blinding_commitment: None,
        checkpoints: vec![],
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
    };
    let v = Verified::__macro_new(42u64, proof);
    assert!(!v.is_verified(), "Zero-step HashIvc should not be verified");
}

// ========================================================================
// V7-09 MEDIUM: Disclosure total_tokens inflation
// ========================================================================
//
// verify_disclosure checks tokens.len() == total_tokens. But what if
// an attacker crafts a disclosure where both are wrong? They need to
// also keep the Merkle tree consistent. Let's probe the defenses.

#[test]
fn attack_v7_09_disclosure_total_tokens_inflated() {
    let verified = make_verified(vec![100, 200, 300, 400]);
    let mut disclosure = create_disclosure(&verified, &[0]).unwrap();

    // Inflate total_tokens to claim more tokens exist
    disclosure.total_tokens = 10;

    // tokens.len() (4) != total_tokens (10) → should fail
    assert!(
        !verify_disclosure(&disclosure),
        "Inflated total_tokens should fail"
    );
}

#[test]
fn attack_v7_09b_disclosure_total_tokens_deflated() {
    let verified = make_verified(vec![100, 200, 300, 400]);
    let mut disclosure = create_disclosure(&verified, &[0]).unwrap();

    // Deflate total_tokens
    disclosure.total_tokens = 2;

    assert!(
        !verify_disclosure(&disclosure),
        "Deflated total_tokens should fail"
    );
}

// ========================================================================
// V7-10 LOW: CompositeProof hash is order-dependent on inner_proofs
// ========================================================================
//
// If inner_proofs = [A, B] vs [B, A], the composition_hash differs.
// This is correct behavior (order should matter for call sequence),
// but we verify it's properly enforced.

#[test]
fn attack_v7_10_inner_proof_ordering_matters() {
    let outer = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let inner_a = VerifiedProof::Mock {
        input_hash: [0x01; 32],
        output_hash: [0x02; 32],
        privacy_mode: PrivacyMode::Transparent,
    };
    let inner_b = VerifiedProof::Mock {
        input_hash: [0x03; 32],
        output_hash: [0x04; 32],
        privacy_mode: PrivacyMode::Transparent,
    };

    let comp_ab = CompositeProof::compose(outer.clone(), vec![inner_a.clone(), inner_b.clone()]);
    let comp_ba = CompositeProof::compose(outer, vec![inner_b, inner_a]);

    assert_ne!(
        comp_ab.composition_hash, comp_ba.composition_hash,
        "Different ordering of inner proofs should produce different composition hashes"
    );
    assert!(comp_ab.verify_composition());
    assert!(comp_ba.verify_composition());
}

#[test]
fn attack_v7_10b_swap_inner_proofs_detected() {
    let outer = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let inner_a = VerifiedProof::Mock {
        input_hash: [0x01; 32],
        output_hash: [0x02; 32],
        privacy_mode: PrivacyMode::Transparent,
    };
    let inner_b = VerifiedProof::Mock {
        input_hash: [0x03; 32],
        output_hash: [0x04; 32],
        privacy_mode: PrivacyMode::Transparent,
    };

    let mut composite =
        CompositeProof::compose(outer, vec![inner_a.clone(), inner_b.clone()]);
    assert!(composite.verify_composition());

    // Swap inner proofs but keep the original composition_hash
    composite.inner_proofs = vec![inner_b, inner_a];
    assert!(
        !composite.verify_composition(),
        "Swapping inner proofs should invalidate composition hash"
    );
}

// ========================================================================
// V7-11 LOW: code_hash leaked in VerifiedProof even in Private mode
// ========================================================================
//
// VerifiedProof::code_hash() returns ZERO_HASH in Private mode, but the
// actual code_hash is still stored in the proof struct. An attacker with
// access to the serialized proof (via serde) can extract the real code_hash.

#[test]
fn attack_v7_11_private_mode_code_hash_in_struct() {
    let real_code = hash_data(b"secret_algorithm");
    let proof = VerifiedProof::HashIvc {
        chain_tip: [0x01; 32],
        merkle_root: [0x02; 32],
        step_count: 1,
        code_hash: real_code,
        privacy_mode: PrivacyMode::Private,
        blinding_commitment: Some([0xAA; 32]),
        checkpoints: vec![[0xBB; 32]],
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
    };

    // code_hash() accessor correctly returns ZERO_HASH
    assert_eq!(proof.code_hash(), ZERO_HASH);

    // But the real code_hash is still in the struct and can be extracted
    // via serialization
    let _json = serde_json::to_string(&proof).unwrap();
    let _code_hex = hex::encode(real_code);
    // The real code_hash bytes are present in the serialized form
    // (as a JSON array of numbers)
    match &proof {
        VerifiedProof::HashIvc { code_hash, .. } => {
            assert_eq!(
                *code_hash, real_code,
                "Real code_hash is still accessible via pattern matching"
            );
            // This is a design issue: if Private mode is meant to hide the code
            // identity, the code_hash should be zeroed in the proof struct itself,
            // not just in the accessor method.
        }
        _ => panic!("Expected HashIvc"),
    }
}

// ========================================================================
// V7-12 LOW: HashChain length overflow
// ========================================================================
//
// HashChain::append uses `self.length += 1` which wraps at u64::MAX.
// After u64::MAX appends, length wraps to 0. While practically infeasible,
// this documents the theoretical boundary.

#[test]
fn attack_v7_12_hash_chain_length_tracking() {
    use poly_verified::crypto::chain::HashChain;

    let mut chain = HashChain::new();
    assert_eq!(chain.length, 0);

    // Verify monotonic increment
    for i in 1..=10u64 {
        chain.append(&hash_data(&i.to_le_bytes()));
        assert_eq!(chain.length, i);
    }
}

// ========================================================================
// Additional: Disclosure with manipulated Merkle proof siblings
// ========================================================================
//
// Test that adding extra siblings to a Merkle proof is detected.

#[test]
fn attack_v7_extra_merkle_siblings() {
    let verified = make_verified(vec![100, 200, 300, 400]);
    let mut disclosure = create_disclosure(&verified, &[1]).unwrap();
    assert!(verify_disclosure(&disclosure));

    // Add an extra sibling to the Merkle proof
    disclosure.proofs[0].siblings.push(ProofNode {
        hash: [0xFF; 32],
        is_left: false,
    });

    // Extra sibling changes the computed root, so verification should fail
    assert!(
        !verify_disclosure(&disclosure),
        "Extra Merkle siblings should cause root mismatch"
    );
}

// ========================================================================
// Additional: Disclosure with truncated Merkle proof siblings
// ========================================================================

#[test]
fn attack_v7_truncated_merkle_siblings() {
    let tokens: Vec<u32> = (0..16).collect(); // 16 tokens → 4 levels
    let verified = make_verified(tokens);
    let mut disclosure = create_disclosure(&verified, &[7]).unwrap();
    assert!(verify_disclosure(&disclosure));

    // Remove last sibling
    if !disclosure.proofs[0].siblings.is_empty() {
        disclosure.proofs[0].siblings.pop();
    }

    assert!(
        !verify_disclosure(&disclosure),
        "Truncated Merkle proof should fail"
    );
}

// ========================================================================
// Additional: FixedPoint arithmetic chain precision
// ========================================================================

#[test]
fn attack_v7_fixed_point_chain_determinism() {
    // Verify that long arithmetic chains are deterministic
    let mut a = FixedPoint::from_int(1);
    let b = FixedPoint::from_decimal(333, 3); // ~0.333

    for _ in 0..100 {
        a = a + b;
        a = a * FixedPoint::from_decimal(999, 3); // ~0.999
    }

    let mut c = FixedPoint::from_int(1);
    for _ in 0..100 {
        c = c + b;
        c = c * FixedPoint::from_decimal(999, 3);
    }

    assert_eq!(a.raw(), c.raw(), "Identical chains must produce identical results");
}

// ========================================================================
// Additional: Verified::map then disclose creates inconsistency
// ========================================================================

#[test]
fn attack_v7_map_then_disclose_fails() {
    let tokens = vec![100, 200, 300, 400];
    let verified: Verified<Vec<u32>> = make_verified(tokens.clone());

    // Map doubles all tokens
    let doubled = verified.map(|v| v.into_iter().map(|x| x * 2).collect::<Vec<u32>>());

    // The proof still has output_hash for [100, 200, 300, 400]
    // but the value is now [200, 400, 600, 800]
    // Trying to create a disclosure from the mapped value should produce
    // a disclosure where output_binding won't match the proof's output_hash
    let disclosure = create_disclosure(&doubled, &[0, 1]).unwrap();

    // The disclosure's output_binding is for [200, 400, 600, 800]
    // but the proof's output_hash is for [100, 200, 300, 400]
    // verify_disclosure should catch this mismatch
    assert!(
        !verify_disclosure(&disclosure),
        "Disclosure from mapped value should fail output binding check"
    );
}

// ========================================================================
// Additional: VerifiedResponse privacy mode consistency
// ========================================================================

#[test]
fn attack_v7_verified_response_privacy_mode_tampering() {
    let proof = VerifiedProof::Mock {
        input_hash: [0x42; 32],
        output_hash: [0x43; 32],
        privacy_mode: PrivacyMode::Transparent,
    };
    let response = VerifiedResponse::new(&proof, [0x42; 32], b"data".to_vec(), ZERO_HASH);
    let mut bytes = response.to_bytes();

    // Tamper: change privacy_mode byte from Transparent (0x00) to Private (0x01)
    bytes[97] = 0x01;

    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();
    assert_eq!(decoded.privacy_mode, PrivacyMode::Private);

    // In Private mode, verify_value_integrity returns true (value is "hidden")
    // but the value_bytes are still present (they were included for Transparent mode)
    // This is a semantic inconsistency: Private mode should have empty value_bytes.
    if decoded.privacy_mode == PrivacyMode::Private && !decoded.value_bytes.is_empty() {
        // The receiver sees Private mode but value_bytes are present.
        // This is suspicious but not enforced by verify_value_integrity().
        // A strict implementation should reject this.
    }
    assert!(
        decoded.verify_value_integrity(),
        "Private mode always returns true from verify_value_integrity"
    );
}

// ========================================================================
// Additional: Verify disclosure with non-sequential proof indices
// ========================================================================

#[test]
fn attack_v7_disclosure_non_sequential_revealed_indices() {
    // Create a disclosure and manually rewrite indices to be non-sequential
    let verified = make_verified(vec![100, 200, 300, 400]);
    let mut disclosure = create_disclosure(&verified, &[]).unwrap();

    // Replace all tokens with revealed ones but with non-sequential indices
    disclosure.tokens = vec![
        DisclosedToken::Redacted {
            index: 0,
            leaf_hash: token_leaf(100),
        },
        DisclosedToken::Redacted {
            index: 1,
            leaf_hash: token_leaf(200),
        },
        DisclosedToken::Redacted {
            index: 5, // gap!
            leaf_hash: token_leaf(300),
        },
        DisclosedToken::Redacted {
            index: 3,
            leaf_hash: token_leaf(400),
        },
    ];

    assert!(
        !verify_disclosure(&disclosure),
        "Non-sequential indices should be rejected"
    );
}

// ========================================================================
// Additional: IVC verify with checkpoints containing duplicate hashes
// ========================================================================

#[test]
fn attack_v7_ivc_duplicate_checkpoints() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"dup_test");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);

    // Two identical witnesses produce different transition hashes
    // because state_before differs between steps
    let witness1 = StepWitness {
        state_before: hash_data(b"state0"),
        state_after: hash_data(b"state1"),
        step_inputs: hash_data(b"same_input"),
    };
    let witness2 = StepWitness {
        state_before: hash_data(b"state1"),
        state_after: hash_data(b"state2"),
        step_inputs: hash_data(b"same_input"),
    };

    ivc.fold_step(&mut acc, &witness1).unwrap();
    ivc.fold_step(&mut acc, &witness2).unwrap();

    let proof = ivc.finalize(acc).unwrap();

    match &proof {
        VerifiedProof::HashIvc { checkpoints, .. } => {
            // Even with same step_inputs, transitions differ because state_before differs
            assert_ne!(
                checkpoints[0], checkpoints[1],
                "Different state_before should produce different transition hashes"
            );
        }
        _ => panic!("Expected HashIvc"),
    }

    assert!(ivc.verify(&proof, &ZERO_HASH, &ZERO_HASH).unwrap());
}

// ========================================================================
// Additional: Verify that privacy mode mismatch in IVC is caught
// ========================================================================

#[test]
fn attack_v7_ivc_transparent_with_blinding_rejected() {
    // A Transparent proof should NOT have a blinding commitment
    let ivc = HashIvc;
    let code_hash = hash_data(b"test");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    let proof = ivc.finalize(acc).unwrap();

    // Tamper: add a blinding commitment to a Transparent proof
    let tampered = match proof {
        VerifiedProof::HashIvc {
            chain_tip,
            merkle_root,
            step_count,
            code_hash,
            checkpoints,
            input_hash,
            output_hash,
            ..
        } => VerifiedProof::HashIvc {
            chain_tip,
            merkle_root,
            step_count,
            code_hash,
            privacy_mode: PrivacyMode::Transparent,
            blinding_commitment: Some([0xAA; 32]), // injected!
            checkpoints,
            input_hash,
            output_hash,
        },
        _ => panic!("Expected HashIvc"),
    };

    let result = ivc.verify(&tampered, &ZERO_HASH, &ZERO_HASH).unwrap();
    assert!(
        !result,
        "Transparent proof with blinding commitment should be rejected"
    );
}

// ========================================================================
// Additional: FixedPoint from_decimal edge cases
// ========================================================================

#[test]
fn fix_v7_06d_from_decimal_boundary_38() {
    // decimal_places = 38 should return ZERO (cap at 38)
    let result = FixedPoint::from_decimal(1, 38);
    assert_eq!(result.raw(), 0, "decimal_places=38 should return ZERO");
}

#[test]
fn fix_v7_06e_from_decimal_large_value_saturates() {
    // Large value * SCALE might overflow
    // i64::MAX * 2^48 fits in i128, so from_decimal(i64::MAX, 0)
    // should work (it's just from_int(i64::MAX))
    let result = FixedPoint::from_decimal(i64::MAX, 0);
    assert_eq!(result.to_i64(), i64::MAX);
}

// ========================================================================
// Additional: Merkle proof for empty tree
// ========================================================================

#[test]
fn attack_v7_merkle_empty_tree_proof() {
    let tree = MerkleTree::build(&[]);
    assert_eq!(tree.root, ZERO_HASH);

    // Trying to generate a proof for an empty tree should fail
    let result = tree.generate_proof(0, &ZERO_HASH);
    assert!(result.is_err(), "Empty tree should not generate proofs");
}

// ========================================================================
// Additional: Disclosure verify with tampered output_binding
// ========================================================================

#[test]
fn attack_v7_disclosure_tampered_output_binding() {
    let verified = make_verified(sample_tokens());
    let mut disclosure = create_disclosure(&verified, &[0, 1]).unwrap();
    assert!(verify_disclosure(&disclosure));

    // Tamper with output_binding (the SHA-256 of raw token bytes)
    disclosure.output_binding[0] ^= 0xFF;

    assert!(
        !verify_disclosure(&disclosure),
        "Tampered output_binding should fail"
    );
}

// ========================================================================
// Additional: Cross-module consistency -- Merkle tree + disclosure
// ========================================================================

#[test]
fn attack_v7_merkle_tree_disclosure_consistency() {
    let tokens = vec![10, 20, 30, 40, 50];
    let verified = make_verified(tokens.clone());

    // Create disclosure and manually verify Merkle tree consistency
    let disclosure = create_disclosure(&verified, &[0, 1, 2, 3, 4]).unwrap();

    // Reconstruct leaves from revealed tokens
    let leaves: Vec<Hash> = tokens.iter().map(|&t| token_leaf(t)).collect();
    let tree = MerkleTree::build(&leaves);

    // The disclosure's output_root should match the tree root
    assert_eq!(
        disclosure.output_root, tree.root,
        "Disclosure output_root should match reconstructed Merkle root"
    );

    // Each proof's root should match
    for proof in &disclosure.proofs {
        assert!(hash_eq(&proof.root, &tree.root));
    }

    assert!(verify_disclosure(&disclosure));
}
