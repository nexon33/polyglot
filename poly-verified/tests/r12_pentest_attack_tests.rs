//! Round 12 Pentest Attack Tests for poly-verified.
//!
//! Findings:
//! V12-01 HIGH:    Verified::map() breaks I/O binding — mapped value diverges from proof's output_hash
//! V12-02 HIGH:    Verified::flatten() discards inner proof — inner computation unverifiable
//! V12-03 HIGH:    FixedPoint comparison after saturation — distinct computations compare equal
//! V12-04 HIGH:    FixedPoint::to_i64() wraps silently on overflow — wrong decision in verified context
//! V12-05 HIGH:    Disclosure Merkle sibling hashes leak redacted token positions cross-audience
//! V12-06 HIGH:    CompositeProof inner proof substitution — swap inner with different computation
//! V12-07 HIGH:    CodeAttestation node_id not cryptographically bound to signing key
//! V12-08 HIGH:    HashIvc Private mode skips both I/O checks — any output_hash accepted
//!
//! Additional MEDIUM/LOW findings tested:
//! V12-09 MEDIUM:  FixedPoint::exp_approx diverges for large inputs — silent precision loss
//! V12-10 MEDIUM:  FixedPoint from_decimal precision cliff at boundary (37 decimal places)
//! V12-11 MEDIUM:  Disclosure with all-same tokens: Merkle siblings reveal token value
//! V12-12 MEDIUM:  CompositeProof privacy mode can be set independently of contained proofs
//! V12-13 MEDIUM:  VerifiedResponse Private mode hides value — receiver cannot verify content
//! V12-14 MEDIUM:  HashIvc accumulator I/O hashes are pub — can be mutated between fold and finalize
//! V12-15 LOW:     Verified<T> Clone creates two independently-usable verified values from one proof
//! V12-16 LOW:     FixedPoint Ord is raw comparison — saturated values collapse ordering
//! V12-17 LOW:     MerkleTree single-leaf proof has empty siblings — trivially forgeable root
//! V12-18 LOW:     Commitment PartialEq constant-time but Hash derive absent — HashMap timing leak
//! V12-19 LOW:     CompositeProof with zero inner proofs and Mock outer is always valid

use sha2::{Digest, Sha256};

use poly_verified::crypto::hash::{hash_combine, hash_data};
use poly_verified::crypto::merkle::{verify_proof, MerkleTree};
use poly_verified::crypto::signing::{sign_attestation, verify_attestation};
use poly_verified::disclosure::{
    create_disclosure, token_leaf, verify_disclosure, DisclosedToken,
};
use poly_verified::fixed_point::FixedPoint;
use poly_verified::ivc::hash_ivc::HashIvc;
use poly_verified::ivc::IvcBackend;
use poly_verified::proof_composition::CompositeProof;
use poly_verified::proof_serialize::VerifiedResponse;
use poly_verified::types::{
    BackendId, Commitment, Hash, MerkleProof, PrivacyMode, StepWitness, VerifiedProof, ZERO_HASH,
};
use poly_verified::verified_type::Verified;

use ed25519_dalek::SigningKey;

// ========================================================================
// Helpers
// ========================================================================

fn tokens_hash(tokens: &[u32]) -> Hash {
    let mut hasher = Sha256::new();
    for &t in tokens {
        hasher.update(t.to_le_bytes());
    }
    hasher.finalize().into()
}

fn valid_hash_ivc_proof_for_tokens(tokens: &[u32]) -> VerifiedProof {
    let ivc = HashIvc;
    let code_hash = [0x03; 32];
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    acc.input_hash = ZERO_HASH;
    acc.output_hash = tokens_hash(tokens);
    ivc.finalize(acc).unwrap()
}

fn make_verified(tokens: Vec<u32>) -> Verified<Vec<u32>> {
    let proof = valid_hash_ivc_proof_for_tokens(&tokens);
    Verified::__macro_new(tokens, proof)
}

fn sample_tokens() -> Vec<u32> {
    vec![100, 200, 300, 400, 500, 600, 700, 800]
}

// ========================================================================
// V12-01: Verified::map() breaks I/O binding
// ========================================================================

/// ATTACK: Verified::map() transforms the wrapped value while keeping the
/// original proof. The proof's output_hash was computed from the ORIGINAL
/// value. After map(), the value no longer matches output_hash. If someone
/// creates a disclosure from the mapped Verified<T>, the output_binding
/// will be computed from the new (mapped) tokens, which won't match the
/// proof's output_hash.
#[test]
fn v12_01_map_breaks_io_binding() {
    let tokens = sample_tokens();
    let verified = make_verified(tokens.clone());

    // Map transforms the value — doubling all tokens
    let mapped = verified.map(|t| t.into_iter().map(|x| x * 2).collect::<Vec<u32>>());

    // The mapped value is different from original
    assert_ne!(mapped.value(), &tokens);

    // The proof's output_hash still corresponds to the ORIGINAL tokens
    // So if we try to create a disclosure, verify_disclosure should catch
    // the mismatch between output_binding (from doubled tokens) and
    // the proof's output_hash (from original tokens).
    let disclosure = create_disclosure(&mapped, &(0..8).collect::<Vec<_>>()).unwrap();

    // SECURITY CHECK: disclosure verification must fail because the mapped
    // tokens don't match the proof's output_hash binding.
    assert!(
        !verify_disclosure(&disclosure),
        "V12-01: Disclosure from mapped Verified should fail verification \
         because output_binding (from mapped value) != proof's output_hash (from original)"
    );
}

/// Verify that an unmapped disclosure still works (control test)
#[test]
fn v12_01_control_unmapped_disclosure_works() {
    let verified = make_verified(sample_tokens());
    let disclosure = create_disclosure(&verified, &[0, 1, 2]).unwrap();
    assert!(verify_disclosure(&disclosure));
}

// ========================================================================
// V12-02: Verified::flatten() discards inner proof
// ========================================================================

/// ATTACK: flatten() on Verified<Verified<T>> keeps the outer proof and
/// discards the inner proof. The inner computation's proof is lost, meaning
/// the inner computation is no longer independently verifiable.
#[test]
fn v12_02_flatten_discards_inner_proof() {
    let tokens = vec![42u32, 43, 44];
    let inner_proof = valid_hash_ivc_proof_for_tokens(&tokens);
    let inner = Verified::__macro_new(tokens.clone(), inner_proof.clone());

    // Outer wraps inner with a DIFFERENT proof (Mock)
    let outer_proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let outer = Verified::__macro_new(inner, outer_proof);

    // Before flatten: inner proof is a HashIvc proof
    assert!(matches!(
        outer.value().proof().backend_id(),
        BackendId::HashIvc
    ));

    // After flatten: inner proof is GONE, only outer (Mock) remains
    let flat = outer.flatten();
    assert_eq!(*flat.value(), tokens);
    assert!(matches!(flat.proof().backend_id(), BackendId::Mock));

    // The HashIvc proof that actually proved the computation is lost.
    // The flattened value now carries only a trivial Mock proof.
    // This is a semantic security issue: the stronger proof was discarded.
    assert_ne!(
        flat.proof().backend_id() as u8,
        BackendId::HashIvc as u8,
        "V12-02: flatten() silently replaced HashIvc proof with Mock proof"
    );
}

// ========================================================================
// V12-03: FixedPoint comparison after saturation
// ========================================================================

/// ATTACK: Two mathematically different overflow computations both saturate
/// to i128::MAX, making them compare as equal. In verified arithmetic,
/// this means distinct results become indistinguishable.
#[test]
fn v12_03_saturation_comparison_collapse() {
    let big = FixedPoint::from_raw(i128::MAX);
    let also_big = FixedPoint::from_raw(i128::MAX - 1);

    // Both saturate to MAX when we add ONE
    let one = FixedPoint::from_int(1);
    let result_a = big.saturating_add(one);
    let result_b = also_big.saturating_add(one);

    // SECURITY CHECK: these two represent different mathematical values
    // (MAX+1 vs MAX) but compare as equal after saturation
    assert_eq!(
        result_a, result_b,
        "V12-03: Different computations collapse to same value via saturation"
    );

    // This means: a verified comparison `result_a == result_b` would be
    // TRUE even though the original values were different.
    // In financial or medical verified computations, this is catastrophic.
}

/// Multiplication saturation also collapses distinct values
#[test]
fn v12_03_mul_saturation_collapse() {
    let a = FixedPoint::from_int(i64::MAX);
    let b = FixedPoint::from_int(i64::MAX);
    let c = FixedPoint::from_int(i64::MAX - 1);

    // Both overflow and saturate to same value
    let ab = a * b;
    let ac = a * c;

    // Both should saturate to i128::MAX
    assert_eq!(
        ab.raw(),
        ac.raw(),
        "V12-03: Distinct multiplications saturate to same raw value"
    );
}

// ========================================================================
// V12-04: FixedPoint::to_i64() wraps on overflow
// ========================================================================

/// ATTACK: to_i64() silently wraps on overflow instead of saturating.
/// A verified computation using to_i64() could produce a completely wrong
/// value (e.g., negative from a mathematically positive number).
#[test]
fn v12_04_to_i64_wrapping_overflow() {
    // Create a FixedPoint value whose integer part exceeds i64::MAX
    let huge = FixedPoint::from_raw((i64::MAX as i128 + 100) * FixedPoint::SCALE);

    // to_i64() wraps: should be > i64::MAX but wraps to a different value
    let wrapped = huge.to_i64();

    // to_i64_saturating() correctly clamps
    let saturated = huge.to_i64_saturating();
    assert_eq!(saturated, i64::MAX);

    // The wrapped value is WRONG — it's not i64::MAX
    // (it wraps because (i64::MAX + 100) as i64 wraps around)
    assert_ne!(
        wrapped, saturated,
        "V12-04: to_i64() wraps while to_i64_saturating() correctly clamps"
    );

    // Even worse: for very negative values, to_i64 might give positive
    let huge_neg = FixedPoint::from_raw((i64::MIN as i128 - 100) * FixedPoint::SCALE);
    let wrapped_neg = huge_neg.to_i64();
    let saturated_neg = huge_neg.to_i64_saturating();
    assert_eq!(saturated_neg, i64::MIN);
    assert_ne!(
        wrapped_neg, saturated_neg,
        "V12-04: Negative overflow wraps incorrectly"
    );
}

// ========================================================================
// V12-05: Disclosure Merkle sibling leak cross-audience
// ========================================================================

/// ATTACK: When creating disclosures for different audiences, the Merkle
/// proofs contain sibling hashes. An audience receiving a proof for
/// position X also gets the sibling hash at the leaf level, which is the
/// leaf hash for position X+1 (or X-1). Since leaf hashes are
/// hash_leaf(token.to_le_bytes()), an attacker can brute-force the u32
/// token value from a leaked sibling leaf hash.
#[test]
fn v12_05_merkle_siblings_leak_adjacent_tokens() {
    let tokens = vec![100, 200, 300, 400]; // 4 tokens
    let verified = make_verified(tokens.clone());

    // Audience A sees only token 0
    let disclosure_a = create_disclosure(&verified, &[0]).unwrap();

    // The Merkle proof for token 0 has siblings. The first sibling
    // is the leaf hash of the adjacent token (token 1 = 200).
    let proof_0 = &disclosure_a.proofs[0];
    assert!(!proof_0.siblings.is_empty());

    // The first sibling is hash_leaf(token[1].to_le_bytes())
    let leaked_sibling = proof_0.siblings[0].hash;
    let expected_leaf_1 = token_leaf(200); // token 1's leaf

    // SECURITY FINDING: the sibling hash reveals token 1's leaf hash,
    // allowing brute-force recovery of the token value (u32 space is small).
    assert_eq!(
        leaked_sibling, expected_leaf_1,
        "V12-05: Merkle proof sibling leaks adjacent token's leaf hash"
    );

    // Demonstrate brute-force recovery: try all u32 values near 200
    let mut recovered = None;
    for candidate in 0..=1000u32 {
        if token_leaf(candidate) == leaked_sibling {
            recovered = Some(candidate);
            break;
        }
    }
    assert_eq!(
        recovered,
        Some(200),
        "V12-05: Adjacent token recovered via brute-force of leaked sibling"
    );
}

/// Even with deeper trees, internal sibling hashes constrain possibilities
#[test]
fn v12_05_merkle_siblings_constrain_tree_structure() {
    let tokens = vec![10, 20, 30, 40, 50, 60, 70, 80]; // 8 tokens
    let verified = make_verified(tokens.clone());

    // Audience sees only token 2
    let disclosure = create_disclosure(&verified, &[2]).unwrap();
    let proof = &disclosure.proofs[0];

    // First sibling is the leaf hash of token 3 (adjacent in leaf layer)
    let expected_leaf_3 = token_leaf(40);
    assert_eq!(
        proof.siblings[0].hash, expected_leaf_3,
        "V12-05: First sibling leaks token 3's leaf hash"
    );
}

// ========================================================================
// V12-06: CompositeProof inner proof substitution
// ========================================================================

/// ATTACK: Create a composite with inner proof A, then substitute inner
/// proof B (from a different computation). The composition_hash will no
/// longer match, but verify that the check catches this.
#[test]
fn v12_06_composite_inner_proof_substitution_detected() {
    let proof_a = VerifiedProof::Mock {
        input_hash: hash_data(b"input_a"),
        output_hash: hash_data(b"output_a"),
        privacy_mode: PrivacyMode::Transparent,
    };
    let inner_a = VerifiedProof::Mock {
        input_hash: hash_data(b"inner_input_a"),
        output_hash: hash_data(b"inner_output_a"),
        privacy_mode: PrivacyMode::Transparent,
    };
    let inner_b = VerifiedProof::Mock {
        input_hash: hash_data(b"inner_input_b"),
        output_hash: hash_data(b"inner_output_b"),
        privacy_mode: PrivacyMode::Transparent,
    };

    let mut composite = CompositeProof::compose(proof_a, vec![inner_a]);
    assert!(composite.verify_composition());

    // Substitute inner proof
    composite.inner_proofs[0] = inner_b;
    assert!(
        !composite.verify_composition(),
        "V12-06: Substituted inner proof should fail composition verification"
    );
}

/// ATTACK: Reorder inner proofs — should fail because hash_combine is
/// order-dependent.
#[test]
fn v12_06_composite_inner_proof_reorder_detected() {
    let outer = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let inner_1 = VerifiedProof::Mock {
        input_hash: hash_data(b"inner_1"),
        output_hash: hash_data(b"out_1"),
        privacy_mode: PrivacyMode::Transparent,
    };
    let inner_2 = VerifiedProof::Mock {
        input_hash: hash_data(b"inner_2"),
        output_hash: hash_data(b"out_2"),
        privacy_mode: PrivacyMode::Transparent,
    };

    let mut composite = CompositeProof::compose(outer, vec![inner_1.clone(), inner_2.clone()]);
    assert!(composite.verify_composition());

    // Swap order
    composite.inner_proofs = vec![inner_2, inner_1];
    assert!(
        !composite.verify_composition(),
        "V12-06: Reordered inner proofs should fail composition verification"
    );
}

// ========================================================================
// V12-07: CodeAttestation node_id not bound to signing key
// ========================================================================

/// ATTACK: Sign an attestation with key A but set node_id to key B's
/// identity. The attestation verifies with key A's verifying key, but
/// claims to be from node B. There's no enforcement that node_id ==
/// hash(public_key) or similar binding.
#[test]
fn v12_07_attestation_node_id_spoofing() {
    let key_a = SigningKey::from_bytes(&[0x42; 32]);
    let key_b = SigningKey::from_bytes(&[0x43; 32]);

    // Compute what node B's ID "should" be (e.g., hash of pubkey)
    let node_b_id = hash_data(&key_b.verifying_key().to_bytes());

    let code_hash = hash_data(b"some_code");

    // Sign with key A, but claim to be node B
    let spoofed = sign_attestation(
        &node_b_id, // node_id from B
        &code_hash,
        42,
        &key_a, // signed by A
    );

    // Verify with A's key — passes!
    let result = verify_attestation(&spoofed, &key_a.verifying_key());
    assert!(
        result.is_ok(),
        "V12-07: Attestation with spoofed node_id passes verification. \
         node_id is not cryptographically bound to the signing key."
    );

    // The attestation claims node_b_id but was signed by key_a.
    // A proper implementation should bind node_id to the public key.
    assert_ne!(
        hash_data(&key_a.verifying_key().to_bytes()),
        spoofed.node_id,
        "V12-07: Signing key doesn't match claimed node_id"
    );
}

/// ATTACK: Same key can attest to different code_hashes for the same
/// circuit_id (no revocation or uniqueness constraint).
#[test]
fn v12_07_attestation_key_reuse_across_code_versions() {
    let key = SigningKey::from_bytes(&[0x42; 32]);
    let node_id = [0xAA; 32];

    let code_v1 = hash_data(b"code_v1");
    let code_v2 = hash_data(b"code_v2");

    // Same key, same circuit_id, different code_hash
    let att_v1 = sign_attestation(&node_id, &code_v1, 100, &key);
    let att_v2 = sign_attestation(&node_id, &code_v2, 100, &key);

    // Both verify successfully
    let vk = key.verifying_key();
    assert!(verify_attestation(&att_v1, &vk).is_ok());
    assert!(verify_attestation(&att_v2, &vk).is_ok());

    // Both claim circuit_id 100 but for different code — no conflict detection
    assert_ne!(
        att_v1.code_hash, att_v2.code_hash,
        "V12-07: Two valid attestations exist for same circuit with different code"
    );
}

// ========================================================================
// V12-08: HashIvc Private mode skips I/O checks
// ========================================================================

/// ATTACK: In Private mode, the verifier skips both input_hash and
/// output_hash checks. An attacker can create a valid proof with one
/// output and claim it proves a different output.
#[test]
fn v12_08_private_mode_accepts_any_io_hashes() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"private_func");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Private);

    let witness = StepWitness {
        state_before: hash_data(b"real_input"),
        state_after: hash_data(b"real_output"),
        step_inputs: hash_data(b"step"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    acc.input_hash = hash_data(b"committed_input");
    acc.output_hash = hash_data(b"committed_output");

    let proof = ivc.finalize(acc).unwrap();

    // Verify with DIFFERENT expected I/O — should this pass?
    // In Private mode, I/O checks are skipped, so ANY expected hashes work.
    let result = ivc
        .verify(
            &proof,
            &hash_data(b"completely_different_input"),
            &hash_data(b"completely_different_output"),
        )
        .unwrap();

    assert!(
        result,
        "V12-08: Private mode skips I/O verification — attacker can claim \
         the proof corresponds to any input/output pair"
    );
}

// ========================================================================
// V12-09: FixedPoint::exp_approx divergence for large inputs
// ========================================================================

/// ATTACK: exp_approx for large x produces wildly inaccurate results
/// because the Taylor series breaks early on overflow. The result is
/// neither the correct value nor a clean saturation — it's an arbitrary
/// intermediate sum that silently pretends to be valid.
#[test]
fn v12_09_exp_approx_large_input_diverges() {
    // e^100 is astronomically large — should overflow FixedPoint
    let x = FixedPoint::from_int(100);
    let result = x.exp_approx(30);

    // The result is NOT i128::MAX (no clean saturation). Instead, the
    // Taylor series silently breaks early when a term overflows, returning
    // whatever partial sum accumulated so far. This is worse than saturation
    // because the caller has no indication the result is wrong.
    assert_ne!(
        result.raw(),
        i128::MAX,
        "V12-09: exp_approx does NOT saturate cleanly — returns partial sum"
    );

    // The partial sum is much less than the true value of e^100
    // This means verified computations using exp_approx on large inputs
    // get silently wrong results with no error indication.
    assert!(
        result.raw() > 0,
        "V12-09: Result is positive but wildly inaccurate"
    );

    // Two different large inputs may produce different wrong values
    let y = FixedPoint::from_int(50);
    let result_y = y.exp_approx(30);
    // Both are wrong, but they're different wrong values
    assert_ne!(
        result.to_i64(),
        result_y.to_i64(),
        "V12-09: Different large exp inputs produce different (both wrong) results"
    );
}

/// exp_approx with negative x: the Taylor series diverges badly for large
/// negative inputs. e^(-20) ~ 2.06e-9, but the Taylor series with 30 terms
/// produces a wildly incorrect result because alternating terms grow before
/// shrinking, causing catastrophic cancellation in fixed-point arithmetic.
#[test]
fn v12_09_exp_approx_negative_precision() {
    // e^(-20) ~ 2.06e-9 — should be nearly zero
    let x = FixedPoint::from_int(-20);
    let result = x.exp_approx(30);

    // The result is enormously wrong — the Taylor series diverges for
    // large negative x because intermediate terms overflow before the
    // alternating sum converges.
    // True value: ~0, but we get a huge number:
    assert!(
        result.to_i64() > 1000,
        "V12-09: exp(-20) should be ~0 but Taylor series gives {} — catastrophic divergence",
        result.to_i64()
    );

    // This is a critical bug: a verified computation doing exp(-20) gets
    // a completely wrong answer with no error indication.
    // For small negative x, it works fine:
    let small_neg = FixedPoint::from_int(-1);
    let small_result = small_neg.exp_approx(20);
    // e^(-1) ~ 0.368 — integer part should be 0
    assert_eq!(
        small_result.to_i64(),
        0,
        "exp(-1) should truncate to 0"
    );
}

// ========================================================================
// V12-10: FixedPoint::from_decimal precision cliff
// ========================================================================

/// ATTACK: from_decimal at boundary (37 decimal places) vs 38+ which
/// clamps to ZERO. The precision cliff at decimal_places=37 is extreme.
#[test]
fn v12_10_from_decimal_precision_cliff() {
    // 37 decimal places: still computes (but with extreme divisor)
    let val_37 = FixedPoint::from_decimal(1, 37);

    // 38 decimal places: immediately returns ZERO
    let val_38 = FixedPoint::from_decimal(1, 38);

    assert_eq!(
        val_38,
        FixedPoint::ZERO,
        "V12-10: 38 decimal places clamps to zero"
    );

    // At 37 places: 1 * SCALE / 10^37 — this is an extremely small
    // number that may also be zero due to integer division
    // The cliff between 37 and 38 is not communicated to the user.
    // This could cause surprising behavior in verified financial computations.
    assert_eq!(
        val_37.raw(),
        0,
        "V12-10: 37 decimal places also rounds to zero due to integer division"
    );

    // But smaller decimal places work fine
    let val_10 = FixedPoint::from_decimal(1, 10);
    assert_ne!(val_10.raw(), 0);
}

/// from_decimal: large values with 0 decimal places.
/// from_decimal(i64::MAX, 0) computes i64::MAX * SCALE. Since i64::MAX
/// is 2^63-1 and SCALE is 2^48, the product fits in i128 (2^111).
/// Only truly huge values or those where checked_mul fails will saturate.
#[test]
fn v12_10_from_decimal_overflow_saturates() {
    // i64::MAX with 0 decimal places: value * SCALE = (2^63-1) * 2^48
    // This fits in i128 (max ~ 2^127), so it does NOT overflow
    let result = FixedPoint::from_decimal(i64::MAX, 0);
    let expected = (i64::MAX as i128) * FixedPoint::SCALE;
    assert_eq!(
        result.raw(),
        expected,
        "V12-10: i64::MAX * SCALE fits in i128 without overflow"
    );

    // i64::MIN similarly fits
    let result_neg = FixedPoint::from_decimal(i64::MIN, 0);
    // checked_mul(i64::MIN as i128, SCALE) — i64::MIN * 2^48 fits in i128
    let expected_neg = (i64::MIN as i128) * FixedPoint::SCALE;
    assert_eq!(
        result_neg.raw(),
        expected_neg,
        "V12-10: i64::MIN * SCALE fits in i128"
    );

    // But from_int(i64::MAX) == from_decimal(i64::MAX, 0) — they should agree
    assert_eq!(
        FixedPoint::from_int(i64::MAX).raw(),
        result.raw(),
        "V12-10: from_int and from_decimal(_, 0) must agree"
    );
}

// ========================================================================
// V12-11: Disclosure with all-same tokens leaks via siblings
// ========================================================================

/// When all tokens have the same value, every leaf hash is identical.
/// An attacker seeing ANY Merkle sibling immediately knows the token
/// value at every position — the "redaction" provides no privacy.
#[test]
fn v12_11_all_same_tokens_disclosure_no_privacy() {
    let secret_token = 12345u32;
    let tokens = vec![secret_token; 8]; // all same
    let verified = make_verified(tokens);

    // Reveal only token 0
    let disclosure = create_disclosure(&verified, &[0]).unwrap();

    // Every leaf hash is the same
    let known_leaf = token_leaf(secret_token);

    // All redacted positions have the same leaf hash as the revealed one
    for token in &disclosure.tokens {
        match token {
            DisclosedToken::Redacted { leaf_hash, .. } => {
                assert_eq!(
                    *leaf_hash, known_leaf,
                    "V12-11: Redacted leaf hash identical to revealed — value leaked"
                );
            }
            _ => {}
        }
    }

    // Still verifies (this is structurally valid)
    assert!(verify_disclosure(&disclosure));
}

// ========================================================================
// V12-12: CompositeProof privacy mode independent of proofs
// ========================================================================

/// ATTACK: Construct a CompositeProof via serde where the privacy_mode
/// field is set to Transparent, but the inner proofs are Private.
/// The compose() function computes the correct restrictive mode, but
/// a deserialized CompositeProof could have an inconsistent privacy_mode.
#[test]
fn v12_12_composite_privacy_desync() {
    let outer = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Private, // Private!
    };
    let inner = VerifiedProof::Mock {
        input_hash: hash_data(b"secret"),
        output_hash: hash_data(b"secret_out"),
        privacy_mode: PrivacyMode::Private, // Private!
    };

    let mut composite = CompositeProof::compose(outer, vec![inner]);

    // compose() correctly sets privacy to Private
    assert_eq!(composite.privacy_mode, PrivacyMode::Private);

    // But we can manually override it (simulating deserialization attack)
    composite.privacy_mode = PrivacyMode::Transparent;

    // verify_composition only checks the composition_hash, not privacy_mode
    // The privacy_mode field is NOT part of the composition_hash!
    assert!(
        composite.verify_composition(),
        "V12-12: Composite with tampered privacy_mode still passes verification \
         because privacy_mode is not bound into the composition_hash"
    );
}

// ========================================================================
// V12-13: VerifiedResponse Private mode hides value
// ========================================================================

/// ATTACK: In Private mode, the receiver gets empty value_bytes and
/// ZERO_HASH value_hash. verify_value_integrity() returns true always.
/// The receiver has no way to verify WHAT was computed.
#[test]
fn v12_13_private_response_no_value_verification() {
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Private,
    };

    // Send different data — in Private mode it's all hidden anyway
    let response = VerifiedResponse::new(&proof, [0x42; 32], b"sensitive data".to_vec(), ZERO_HASH);

    // Value bytes are empty
    assert!(response.value_bytes.is_empty());
    assert_eq!(response.value_hash, ZERO_HASH);

    // verify_value_integrity always passes in Private mode
    assert!(response.verify_value_integrity());

    // Roundtrip still passes
    let bytes = response.to_bytes();
    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();
    assert!(decoded.verify_value_integrity());
    assert!(decoded.value_bytes.is_empty());
}

// ========================================================================
// V12-14: HashIvc accumulator I/O hashes are pub — mutable
// ========================================================================

/// ATTACK: The accumulator's input_hash and output_hash are `pub` fields,
/// allowing mutation between fold_step and finalize. An attacker controlling
/// the accumulator can set arbitrary I/O hashes.
#[test]
fn v12_14_accumulator_io_hash_mutation() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"test_func");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);

    let witness = StepWitness {
        state_before: hash_data(b"real_before"),
        state_after: hash_data(b"real_after"),
        step_inputs: hash_data(b"real_inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();

    // Attacker mutates I/O hashes to claim different computation
    let fake_input = hash_data(b"fake_input");
    let fake_output = hash_data(b"fake_output");
    acc.input_hash = fake_input;
    acc.output_hash = fake_output;

    let proof = ivc.finalize(acc).unwrap();

    // The proof verifies with the FAKE I/O hashes
    assert!(ivc.verify(&proof, &fake_input, &fake_output).unwrap());

    // It does NOT verify with the real computation's I/O
    assert!(!ivc
        .verify(
            &proof,
            &hash_data(b"real_before"),
            &hash_data(b"real_after")
        )
        .unwrap());

    // This means: whoever controls the accumulator can bind arbitrary I/O.
    // The chain proves the STEPS were correct, but the I/O binding is
    // entirely up to the caller. This is by design but is a trust boundary issue.
}

// ========================================================================
// V12-15: Verified<T> Clone creates duplicates
// ========================================================================

/// Clone creates two Verified values that are independently usable.
/// The proof was generated for ONE computation, but now two copies exist.
/// Both can create disclosures, both claim to be independently verified.
#[test]
fn v12_15_verified_clone_independent_use() {
    let verified = make_verified(sample_tokens());

    let clone1 = verified.clone();
    let clone2 = verified.clone();

    // Both clones produce valid disclosures
    let d1 = create_disclosure(&clone1, &[0, 1]).unwrap();
    let d2 = create_disclosure(&clone2, &[2, 3]).unwrap();

    assert!(verify_disclosure(&d1));
    assert!(verify_disclosure(&d2));

    // Both are "verified" — from one proof, unlimited verified copies
    assert!(clone1.is_verified());
    assert!(clone2.is_verified());
}

// ========================================================================
// V12-16: FixedPoint Ord collapses saturated ordering
// ========================================================================

/// After saturation, ordering information is lost.
/// a < b mathematically, but after saturation a == b.
#[test]
fn v12_16_fixedpoint_ord_saturation() {
    let a = FixedPoint::from_raw(i128::MAX);
    let one = FixedPoint::from_int(1);
    let two = FixedPoint::from_int(2);

    // a + 1 and a + 2 should be different, but both saturate to MAX
    let r1 = a.saturating_add(one);
    let r2 = a.saturating_add(two);

    assert_eq!(r1.cmp(&r2), std::cmp::Ordering::Equal);
    assert_eq!(
        r1, r2,
        "V12-16: Ord collapses after saturation — a+1 == a+2"
    );
}

// ========================================================================
// V12-17: MerkleTree single-leaf trivially forgeable
// ========================================================================

/// With a single leaf, the Merkle proof has no siblings.
/// The "root" is just the leaf itself. An attacker who knows the
/// token value can forge the entire proof.
#[test]
fn v12_17_single_leaf_merkle_trivial_forgery() {
    let token_val = 42u32;
    let leaf = token_leaf(token_val);

    // Forge a proof: root == leaf, no siblings needed
    let forged_proof = MerkleProof {
        leaf,
        leaf_index: 0,
        siblings: vec![],
        root: leaf, // root IS the leaf
        code_hash: ZERO_HASH,
    };

    // The forged proof verifies!
    assert!(
        verify_proof(&forged_proof),
        "V12-17: Single-leaf Merkle proof is trivially forgeable"
    );

    // An attacker just needs to know the token value to forge the tree
    let attacker_leaf = token_leaf(42);
    let attacker_proof = MerkleProof {
        leaf: attacker_leaf,
        leaf_index: 0,
        siblings: vec![],
        root: attacker_leaf,
        code_hash: [0xFF; 32], // any code hash
    };
    assert!(verify_proof(&attacker_proof));
}

// ========================================================================
// V12-18: Commitment lacks Hash derive — timing leak in HashMap
// ========================================================================

/// Commitment implements constant-time PartialEq but does not implement
/// Hash. If used as a HashMap key (via custom Hash impl or derived one),
/// the hash computation would use standard (non-constant-time) methods,
/// creating a timing side-channel.
#[test]
fn v12_18_commitment_partial_eq_constant_time() {
    let a = Commitment {
        root: [0x01; 32],
        total_checkpoints: 10,
        chain_tip: [0x02; 32],
        code_hash: [0x03; 32],
    };

    // Identical commitment
    let b = a.clone();
    assert_eq!(a, b);

    // Differs only in last byte of code_hash
    let mut c = a.clone();
    c.code_hash[31] ^= 0x01;
    assert_ne!(a, c);

    // Constant-time PartialEq is correctly implemented.
    // But absence of std::hash::Hash means Commitment can't be safely
    // used in HashSet/HashMap without a timing-safe hasher.
    // This is a design-level concern, not a runtime bug.
}

// ========================================================================
// V12-19: CompositeProof with Mock outer always valid
// ========================================================================

/// An attacker can create a CompositeProof with a Mock outer proof
/// and no inner proofs. This always passes verify_composition because
/// Mock proofs are considered structurally valid.
#[test]
fn v12_19_composite_mock_outer_always_valid() {
    let mock = VerifiedProof::Mock {
        input_hash: [0xFF; 32],
        output_hash: [0xAA; 32],
        privacy_mode: PrivacyMode::Transparent,
    };

    let composite = CompositeProof::compose(mock, vec![]);
    assert!(
        composite.verify_composition(),
        "V12-19: Mock outer composite always passes — no cryptographic proof needed"
    );
}

// ========================================================================
// Additional integration tests for robustness
// ========================================================================

/// Verify that disclosure verification catches mismatched execution proof
/// output_hash even for partial disclosures (where tokens_hash recompute
/// is not possible).
#[test]
fn v12_integration_partial_disclosure_output_hash_mismatch() {
    let tokens = sample_tokens();
    let verified = make_verified(tokens.clone());

    let mut disclosure = create_disclosure(&verified, &[2, 5]).unwrap();

    // Tamper with output_binding
    disclosure.output_binding = hash_data(b"tampered");

    assert!(
        !verify_disclosure(&disclosure),
        "Partial disclosure with tampered output_binding should fail"
    );
}

/// Verify that verify_disclosure rejects a disclosure where output_root
/// is correct but execution_proof output_hash was swapped.
#[test]
fn v12_integration_disclosure_proof_swap() {
    let tokens_a = vec![100, 200, 300, 400];
    let tokens_b = vec![500, 600, 700, 800];

    let verified_a = make_verified(tokens_a.clone());
    let verified_b = make_verified(tokens_b.clone());

    let mut disclosure_a = create_disclosure(&verified_a, &[0, 1, 2, 3]).unwrap();

    // Swap in proof B's execution_proof (different output_hash)
    disclosure_a.execution_proof = verified_b.proof().clone();

    // Should fail: output_binding (from tokens_a) != proof's output_hash (from tokens_b)
    assert!(
        !verify_disclosure(&disclosure_a),
        "Disclosure with swapped execution proof should fail"
    );
}

/// Verify Merkle tree determinism: same leaves always produce same root.
#[test]
fn v12_integration_merkle_determinism() {
    let leaves: Vec<Hash> = (0..16u32).map(|i| token_leaf(i)).collect();

    let tree1 = MerkleTree::build(&leaves);
    let tree2 = MerkleTree::build(&leaves);

    assert_eq!(tree1.root, tree2.root);
}

/// Verify that hash_combine is not commutative (order matters).
#[test]
fn v12_integration_hash_combine_non_commutative() {
    let a = hash_data(b"first");
    let b = hash_data(b"second");

    let ab = hash_combine(&a, &b);
    let ba = hash_combine(&b, &a);

    assert_ne!(ab, ba, "hash_combine must not be commutative");
}

/// Verify that HashIvc proofs from different code_hashes are not
/// interchangeable.
#[test]
fn v12_integration_code_hash_binding() {
    let ivc = HashIvc;
    let code_a = hash_data(b"code_a");
    let code_b = hash_data(b"code_b");

    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };

    let mut acc_a = ivc.init(&code_a, PrivacyMode::Transparent);
    ivc.fold_step(&mut acc_a, &witness).unwrap();
    let proof_a = ivc.finalize(acc_a).unwrap();

    let mut acc_b = ivc.init(&code_b, PrivacyMode::Transparent);
    ivc.fold_step(&mut acc_b, &witness).unwrap();
    let proof_b = ivc.finalize(acc_b).unwrap();

    // Proofs from different code should have different chain_tips
    match (&proof_a, &proof_b) {
        (
            VerifiedProof::HashIvc {
                chain_tip: tip_a, ..
            },
            VerifiedProof::HashIvc {
                chain_tip: tip_b, ..
            },
        ) => {
            assert_ne!(
                tip_a, tip_b,
                "Different code_hashes must produce different chain_tips"
            );
        }
        _ => panic!("Expected HashIvc proofs"),
    }
}

/// FixedPoint: division by very small number. checked_div computes
/// (self.raw * SCALE) / rhs.raw. When self is large and rhs.raw is 1,
/// self.raw * SCALE can overflow, returning None.
#[test]
fn v12_integration_fixedpoint_division_amplification() {
    // Use a large enough value that self.raw * SCALE overflows i128
    // self.raw = big_val * SCALE, so self.raw * SCALE = big_val * SCALE^2
    // Need big_val * SCALE^2 > i128::MAX
    // SCALE = 2^48, SCALE^2 = 2^96, i128::MAX ~ 2^127
    // So big_val > 2^31 should overflow: use 2^32
    let big = FixedPoint::from_int(1i64 << 40);
    let tiny = FixedPoint::from_raw(1); // smallest possible non-zero

    // checked_div: (big.raw * SCALE) / 1 = big.raw * SCALE
    // big.raw = (1<<40) * (1<<48) = 1<<88. big.raw * SCALE = 1<<136 > i128::MAX
    let result = big.checked_div(tiny);

    assert!(
        result.is_none(),
        "V12-integration: Division by extremely small value overflows in checked_div"
    );

    // But the non-checked Div trait saturates instead of returning None
    let div_result = big / FixedPoint::from_raw(1);
    // Should saturate to MAX since both are positive
    assert_eq!(
        div_result.raw(),
        i128::MAX,
        "Div trait saturates on overflow"
    );
}

/// FixedPoint: chained operations accumulate precision loss
#[test]
fn v12_integration_fixedpoint_precision_chain() {
    let third = FixedPoint::from_decimal(1, 0).checked_div(FixedPoint::from_int(3));
    assert!(third.is_some());
    let third = third.unwrap();

    // 1/3 * 3 should be 1, but fixed-point truncation makes it 0
    let reconstructed = third.checked_mul(FixedPoint::from_int(3));
    assert!(reconstructed.is_some());
    let reconstructed = reconstructed.unwrap();

    // Due to truncation: 1/3 = 0.333... truncated, * 3 = 0.999...
    // which truncates to 0 in to_i64
    let diff = (FixedPoint::ONE - reconstructed).abs();
    assert!(
        diff.raw() > 0,
        "Precision loss: 1/3 * 3 != 1 in fixed-point arithmetic"
    );
}

/// Verified: is_verified returns false for HashIvc with step_count == 0
#[test]
fn v12_integration_zero_step_not_verified() {
    let proof = VerifiedProof::HashIvc {
        chain_tip: ZERO_HASH,
        merkle_root: ZERO_HASH,
        step_count: 0,
        code_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
        blinding_commitment: None,
        checkpoints: vec![],
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
    };
    let v = Verified::__macro_new(42u64, proof);
    assert!(!v.is_verified());
}

/// SignedCommitment: tampering with any commitment field invalidates signature
#[test]
fn v12_integration_signed_commitment_tamper_detection() {
    use poly_verified::crypto::commitment::{
        create_commitment, sign_commitment, verify_signed_commitment,
    };

    let checkpoints: Vec<Hash> = (0..4u8).map(|i| hash_data(&[i])).collect();
    let code_hash = hash_data(b"test_code");
    let (commitment, _) = create_commitment(&checkpoints, &code_hash);

    let key = SigningKey::from_bytes(&[0x42; 32]);
    let signed = sign_commitment(&commitment, &key);

    // Original verifies
    assert!(verify_signed_commitment(&signed).is_ok());

    // Tamper with total_checkpoints
    let mut tampered = signed.clone();
    tampered.commitment.total_checkpoints += 1;
    assert!(verify_signed_commitment(&tampered).is_err());

    // Tamper with root
    let mut tampered2 = signed.clone();
    tampered2.commitment.root[0] ^= 0xFF;
    assert!(verify_signed_commitment(&tampered2).is_err());
}

/// VerifiedResponse: validate_header_consistency catches privacy_mode tamper
#[test]
fn v12_integration_response_header_privacy_tamper() {
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let response = VerifiedResponse::new(&proof, ZERO_HASH, b"data".to_vec(), ZERO_HASH);

    // Original is consistent
    assert!(response.validate_header_consistency());

    // Serialize, tamper with privacy_mode byte, deserialize
    let mut bytes = response.to_bytes();
    // privacy_mode is at offset 97
    bytes[97] = PrivacyMode::Private as u8;
    let tampered = VerifiedResponse::from_bytes(&bytes).unwrap();

    // Header says Private, proof says Transparent — inconsistent
    assert!(
        !tampered.validate_header_consistency(),
        "Tampered privacy_mode should be detected"
    );
}

/// VerifiedResponse: validate_header_consistency catches proof_scheme tamper
#[test]
fn v12_integration_response_header_scheme_tamper() {
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let response = VerifiedResponse::new(&proof, ZERO_HASH, b"data".to_vec(), ZERO_HASH);

    let mut bytes = response.to_bytes();
    // proof_scheme is at offset 96
    bytes[96] = BackendId::HashIvc as u8;
    let tampered = VerifiedResponse::from_bytes(&bytes).unwrap();

    assert!(
        !tampered.validate_header_consistency(),
        "Tampered proof_scheme should be detected"
    );
}

/// Hash chain: replaying the same step produces a different chain than
/// two distinct steps.
#[test]
fn v12_integration_hash_chain_replay_detection() {
    use poly_verified::crypto::chain::HashChain;

    let step_a = hash_data(b"step_a");
    let step_b = hash_data(b"step_b");

    // Chain with A, B
    let mut chain_ab = HashChain::new();
    chain_ab.append(&step_a);
    chain_ab.append(&step_b);

    // Chain with A, A (replay)
    let mut chain_aa = HashChain::new();
    chain_aa.append(&step_a);
    chain_aa.append(&step_a);

    assert_ne!(
        chain_ab.tip, chain_aa.tip,
        "Replaying the same step must produce different chain tip"
    );
}
