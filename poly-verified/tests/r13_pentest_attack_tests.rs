//! Round 13 Pentest Attack Tests for poly-verified.
//!
//! Findings:
//! V13-01 HIGH:    Proof replay across different Verified<T> type contexts — same proof, different T
//! V13-02 HIGH:    Disclosure cross-splice with partial redaction — Merkle root matches but tokens differ
//! V13-03 HIGH:    CompositeProof inner I/O chain not enforced — inner output != next inner input
//! V13-04 HIGH:    VerifiedResponse value_bytes unbounded — no size limit on deserialization (DoS)
//! V13-05 HIGH:    Disclosure verify_disclosure accepts extra proofs appended after revealed count
//! V13-06 HIGH:    HashIvc proof checkpoint mutation after finalize — checkpoints are public Vec
//! V13-07 HIGH:    VerifiedResponse from_bytes parser differential — serde vs wire format divergence
//! V13-08 HIGH:    Disclosure with forged redacted leaf hashes that reconstruct to same Merkle root
//! V13-09 MEDIUM:  Hash chain fork detection gap — two chains share prefix but diverge undetected
//! V13-10 MEDIUM:  Merkle tree with power-of-two vs non-power-of-two leaf count — odd duplication leak
//! V13-11 MEDIUM:  CompositeProof serialization roundtrip — composition_hash not re-verified on deser
//! V13-12 MEDIUM:  VerifiedProof serde allows constructing HashIvc with mismatched step_count/checkpoints
//! V13-13 MEDIUM:  Disclosure for tokens at index 0 — leaf_index wrapping with u64 max
//! V13-14 MEDIUM:  CodeAttestation circuit_id has no maximum — u64::MAX as sentinel abuse
//! V13-15 MEDIUM:  FixedPoint from_raw allows any i128 — no canonical range enforcement
//! V13-16 MEDIUM:  Commitment from_bytes + to_bytes not using canonical endianness for all fields
//! V13-17 MEDIUM:  VerifiedResponse code_hash not cross-checked against proof_bytes content
//! V13-18 MEDIUM:  Disclosure empty token set edge case — total_tokens=0 handling
//! V13-19 MEDIUM:  Privacy mode transition — proof created as Transparent, used in Private context
//! V13-20 LOW:     MerkleProof code_hash field not verified in verify_proof
//! V13-21 LOW:     HashIvc blinding_commitment derivation is deterministic from checkpoints (not random)
//! V13-22 LOW:     Verified<T> Serialize exposes proof internals including private mode checkpoints
//! V13-23 LOW:     FixedPoint Display truncation hides sub-millionth precision
//! V13-24 LOW:     CompositeProof proof_count off-by-one potential with MAX_INNER_PROOFS
//! V13-25 LOW:     Disclosure output_binding computed from raw token bytes — no domain separation
//!
//! Additional robustness/integration tests:
//! V13-26 through V13-42: edge case and integration coverage

use sha2::{Digest, Sha256};

use poly_verified::crypto::hash::{
    hash_blinding, hash_chain_step, hash_combine, hash_data, hash_leaf, hash_transition,
};
use poly_verified::crypto::merkle::{verify_proof, MerkleTree};
use poly_verified::crypto::signing::{sign_attestation, verify_attestation};
use poly_verified::disclosure::{
    create_disclosure, token_leaf, verify_disclosure, Disclosure,
    DisclosedToken,
};
use poly_verified::fixed_point::FixedPoint;
use poly_verified::ivc::hash_ivc::HashIvc;
use poly_verified::ivc::IvcBackend;
use poly_verified::proof_composition::CompositeProof;
use poly_verified::proof_serialize::VerifiedResponse;
use poly_verified::types::{
    BackendId, CodeAttestation, Commitment, Hash, MerkleProof, PrivacyMode,
    StepWitness, VerifiedProof, ZERO_HASH,
};
use poly_verified::verified_type::Verified;

use ed25519_dalek::SigningKey;

// ========================================================================
// Helpers
// ========================================================================

fn tokens_hash(tokens: &[u32]) -> Hash {
    let mut hasher = Sha256::new();
    for &t in tokens {
        hasher.update(t.to_le_bytes());
    }
    hasher.finalize().into()
}

fn valid_hash_ivc_proof_for_tokens(tokens: &[u32]) -> VerifiedProof {
    let ivc = HashIvc;
    let code_hash = [0x03; 32];
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    let witness = StepWitness {
        state_before: hash_data(b"before"),
        state_after: hash_data(b"after"),
        step_inputs: hash_data(b"inputs"),
    };
    ivc.fold_step(&mut acc, &witness).unwrap();
    acc.input_hash = ZERO_HASH;
    acc.output_hash = tokens_hash(tokens);
    ivc.finalize(acc).unwrap()
}

fn make_verified(tokens: Vec<u32>) -> Verified<Vec<u32>> {
    let proof = valid_hash_ivc_proof_for_tokens(&tokens);
    Verified::__macro_new(tokens, proof)
}

fn sample_tokens() -> Vec<u32> {
    vec![100, 200, 300, 400, 500, 600, 700, 800]
}

// ========================================================================
// V13-01: Proof replay across different Verified<T> type contexts
// ========================================================================

/// ATTACK: The proof inside Verified<T> has no binding to the type T.
/// An attacker can take a proof from Verified<Vec<u32>> and attach it to
/// Verified<u64> (via __macro_new). The proof proves the Vec<u32> computation,
/// but the receiver sees a u64 value claiming to be verified by the same proof.
/// The type parameter T is not part of the proof's binding.
#[test]
fn v13_01_proof_replay_across_type_contexts() {
    let tokens = sample_tokens();
    let verified_vec: Verified<Vec<u32>> = make_verified(tokens.clone());

    // Extract the proof
    let proof = verified_vec.proof().clone();

    // Attach the same proof to a completely different type
    let verified_u64: Verified<u64> = Verified::__macro_new(99999u64, proof.clone());

    // Both claim to be verified with the same proof
    assert!(
        verified_u64.is_verified(),
        "V13-01: Proof from Vec<u32> accepted for u64 — type T not bound to proof"
    );

    // The proof's output_hash was computed from the Vec<u32> tokens.
    // The u64 value 99999 is completely unrelated, but is_verified() passes
    // because it only checks step_count > 0, not value-proof binding.
    assert_eq!(
        verified_vec.proof().backend_id() as u8,
        verified_u64.proof().backend_id() as u8,
        "V13-01: Same proof backend in both type contexts"
    );
}

/// Control: Verified wrapping a String with the same proof also passes.
#[test]
fn v13_01_proof_replay_string_context() {
    let tokens = sample_tokens();
    let verified_vec = make_verified(tokens);
    let proof = verified_vec.proof().clone();

    let verified_str: Verified<String> =
        Verified::__macro_new("totally_unrelated".to_string(), proof);
    assert!(
        verified_str.is_verified(),
        "V13-01: Proof from Vec<u32> accepted for String"
    );
}

// ========================================================================
// V13-02: Disclosure cross-splice with partial redaction
// ========================================================================

/// ATTACK: Create two Verified<Vec<u32>> with different tokens but the same
/// length. Create a disclosure from A (partial reveal), then splice in
/// redacted leaf hashes from B. If the Merkle root check catches this,
/// verify that it does. If not, this is a vulnerability.
#[test]
fn v13_02_disclosure_cross_splice_redacted_hashes() {
    let tokens_a = vec![100, 200, 300, 400];
    let tokens_b = vec![500, 600, 700, 800];

    let verified_a = make_verified(tokens_a.clone());
    let verified_b = make_verified(tokens_b.clone());

    // Create disclosure A revealing only token 0
    let mut disclosure_a = create_disclosure(&verified_a, &[0]).unwrap();

    // Create disclosure B revealing nothing (all redacted)
    let disclosure_b = create_disclosure(&verified_b, &[]).unwrap();

    // Splice: replace A's redacted leaf hashes with B's redacted hashes
    // at positions 1, 2, 3
    for i in 1..4 {
        if let DisclosedToken::Redacted { leaf_hash, .. } = &disclosure_b.tokens[i] {
            disclosure_a.tokens[i] = DisclosedToken::Redacted {
                index: i,
                leaf_hash: *leaf_hash,
            };
        }
    }

    // The Merkle root reconstruction should fail because the spliced
    // leaf hashes are from a different tree.
    assert!(
        !verify_disclosure(&disclosure_a),
        "V13-02: Cross-spliced redacted leaf hashes must be detected by Merkle root check"
    );
}

// ========================================================================
// V13-03: CompositeProof inner I/O chain not enforced
// ========================================================================

/// ATTACK: In a computation graph outer -> inner_1 -> inner_2, the output
/// of inner_1 should equal the input of inner_2. But CompositeProof does
/// not verify this I/O chaining. An attacker can compose proofs from
/// completely unrelated computations.
#[test]
fn v13_03_composite_io_chain_not_enforced() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"func");

    // Create two independent proofs with non-matching I/O
    let mut acc1 = ivc.init(&code_hash, PrivacyMode::Transparent);
    let w1 = StepWitness {
        state_before: hash_data(b"start_1"),
        state_after: hash_data(b"end_1"),
        step_inputs: hash_data(b"in_1"),
    };
    ivc.fold_step(&mut acc1, &w1).unwrap();
    acc1.input_hash = hash_data(b"input_1");
    acc1.output_hash = hash_data(b"output_1");
    let proof_1 = ivc.finalize(acc1).unwrap();

    let mut acc2 = ivc.init(&code_hash, PrivacyMode::Transparent);
    let w2 = StepWitness {
        state_before: hash_data(b"start_2"),
        state_after: hash_data(b"end_2"),
        step_inputs: hash_data(b"in_2"),
    };
    ivc.fold_step(&mut acc2, &w2).unwrap();
    acc2.input_hash = hash_data(b"input_2_UNRELATED"); // != output_1
    acc2.output_hash = hash_data(b"output_2");
    let proof_2 = ivc.finalize(acc2).unwrap();

    // Compose: proof_1 is outer, proof_2 is inner
    // output_1 != input_2_UNRELATED, so the I/O chain is broken
    let composite = CompositeProof::compose(proof_1, vec![proof_2]);

    // verify_composition only checks the composition_hash binding,
    // not I/O chaining between proofs.
    assert!(
        composite.verify_composition(),
        "V13-03: CompositeProof does NOT enforce I/O chaining between inner proofs — \
         unrelated computations can be composed"
    );
}

/// Two inner proofs with contradictory I/O still compose.
#[test]
fn v13_03_composite_contradictory_io() {
    // Inner proof says output = X, next inner says input = Y where X != Y
    let outer = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: hash_data(b"outer_out"),
        privacy_mode: PrivacyMode::Transparent,
    };
    let inner_1 = VerifiedProof::Mock {
        input_hash: hash_data(b"in_1"),
        output_hash: hash_data(b"out_1"),
        privacy_mode: PrivacyMode::Transparent,
    };
    let inner_2 = VerifiedProof::Mock {
        input_hash: hash_data(b"in_2_DIFFERENT"), // != out_1
        output_hash: hash_data(b"out_2"),
        privacy_mode: PrivacyMode::Transparent,
    };

    let composite = CompositeProof::compose(outer, vec![inner_1, inner_2]);
    assert!(
        composite.verify_composition(),
        "V13-03: Contradictory I/O chain still passes composition verification"
    );
}

// ========================================================================
// V13-04: VerifiedResponse value_bytes unbounded on deserialization
// ========================================================================

/// ATTACK: The wire format allows value_bytes to consume all remaining bytes
/// after the proof section. There is no size limit on value_bytes, so a
/// crafted message with a tiny proof but GB of value data could cause OOM.
/// The proof_len has a 16 MiB cap, but value_bytes has no cap.
#[test]
fn v13_04_value_bytes_unbounded() {
    let proof = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    let small_value = b"small".to_vec();
    let response = VerifiedResponse::new(&proof, ZERO_HASH, small_value, ZERO_HASH);

    let mut bytes = response.to_bytes();

    // Append a moderate amount of extra data as "value_bytes"
    // (In real attack this would be much larger)
    let extra = vec![0xAA; 100_000];
    bytes.extend_from_slice(&extra);

    // from_bytes accepts ALL trailing data as value_bytes
    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();

    // The decoded value_bytes is much larger than the original
    assert!(
        decoded.value_bytes.len() > 100_000,
        "V13-04: value_bytes has no size cap — accepts {} bytes (original was 5)",
        decoded.value_bytes.len()
    );

    // value_hash won't match, but the parsing succeeds — DoS vector
    assert!(
        !decoded.verify_value_integrity(),
        "V13-04: Inflated value_bytes fails integrity check (good)"
    );
}

// ========================================================================
// V13-05: Disclosure verify_disclosure accepts mismatched proof count
// ========================================================================

/// ATTACK: Create a valid disclosure, then append extra (duplicate) Merkle
/// proofs. verify_disclosure checks that all proofs are consumed (proof_idx
/// == proofs.len()), so this should be caught.
#[test]
fn v13_05_extra_proofs_rejected() {
    let tokens = sample_tokens();
    let verified = make_verified(tokens);
    let mut disclosure = create_disclosure(&verified, &[0]).unwrap();

    // Clone the existing proof and append it as a duplicate
    let extra_proof = disclosure.proofs[0].clone();
    disclosure.proofs.push(extra_proof);

    // verify_disclosure should catch: we have 1 revealed token but 2 proofs
    assert!(
        !verify_disclosure(&disclosure),
        "V13-05: Extra proofs appended to disclosure must be rejected"
    );
}

/// Remove a proof from a multi-reveal disclosure — should fail.
#[test]
fn v13_05_missing_proof_rejected() {
    let tokens = sample_tokens();
    let verified = make_verified(tokens);
    let mut disclosure = create_disclosure(&verified, &[0, 1, 2]).unwrap();

    // Remove the last proof
    disclosure.proofs.pop();

    // Should fail: 3 revealed tokens but only 2 proofs
    assert!(
        !verify_disclosure(&disclosure),
        "V13-05: Missing proof for revealed token must be rejected"
    );
}

// ========================================================================
// V13-06: HashIvc proof checkpoint mutation after finalize
// ========================================================================

/// ATTACK: After finalize produces a VerifiedProof, the checkpoints Vec
/// inside VerifiedProof::HashIvc is accessible. Mutating it should cause
/// verification failure because chain_tip and merkle_root won't match.
#[test]
fn v13_06_checkpoint_mutation_after_finalize() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"func");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);

    for i in 0..3u8 {
        let witness = StepWitness {
            state_before: hash_data(&[i]),
            state_after: hash_data(&[i + 1]),
            step_inputs: hash_data(&[i * 2]),
        };
        ivc.fold_step(&mut acc, &witness).unwrap();
    }
    let input_hash = hash_data(b"input");
    let output_hash = hash_data(b"output");
    acc.input_hash = input_hash;
    acc.output_hash = output_hash;

    let proof = ivc.finalize(acc).unwrap();

    // Verify original
    assert!(ivc.verify(&proof, &input_hash, &output_hash).unwrap());

    // Mutate a checkpoint via serde roundtrip
    let mut json = serde_json::to_value(&proof).unwrap();
    if let Some(checkpoints) = json.get_mut("HashIvc").and_then(|v| v.get_mut("checkpoints")) {
        if let Some(arr) = checkpoints.as_array_mut() {
            if let Some(first) = arr.first_mut() {
                if let Some(bytes) = first.as_array_mut() {
                    if let Some(b) = bytes.first_mut() {
                        *b = serde_json::json!(255);
                    }
                }
            }
        }
    }
    let mutated_proof: VerifiedProof = serde_json::from_value(json).unwrap();

    // Mutated proof should fail verification
    assert!(
        !ivc.verify(&mutated_proof, &input_hash, &output_hash)
            .unwrap(),
        "V13-06: Mutated checkpoints must be detected by chain_tip verification"
    );
}

// ========================================================================
// V13-07: VerifiedResponse parser differential: serde vs wire format
// ========================================================================

/// ATTACK: The VerifiedResponse has both `to_bytes`/`from_bytes` (wire format)
/// and serde_json serialization (via proof_bytes). If the two disagree,
/// one parser may accept what the other rejects. Specifically, proof_bytes
/// is JSON inside a binary envelope. If proof_bytes contains valid JSON that
/// parses to a different proof variant, the wire header and proof content diverge.
#[test]
fn v13_07_parser_differential_proof_bytes() {
    let proof_mock = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };

    let response = VerifiedResponse::new(&proof_mock, ZERO_HASH, b"data".to_vec(), ZERO_HASH);
    let bytes = response.to_bytes();

    // The wire header says proof_scheme = Mock (0x00).
    // Now craft different proof_bytes (a HashIvc proof JSON) and inject it.
    let ivc = HashIvc;
    let code_hash = hash_data(b"test");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    let w = StepWitness {
        state_before: hash_data(b"b"),
        state_after: hash_data(b"a"),
        step_inputs: hash_data(b"i"),
    };
    ivc.fold_step(&mut acc, &w).unwrap();
    let hash_ivc_proof = ivc.finalize(acc).unwrap();
    let hash_ivc_json = serde_json::to_vec(&hash_ivc_proof).unwrap();

    // Reconstruct: keep header (says Mock) but replace proof_bytes with HashIvc JSON
    let proof_len_offset = 98;
    let original_proof_len =
        u32::from_be_bytes(bytes[proof_len_offset..proof_len_offset + 4].try_into().unwrap())
            as usize;
    let original_proof_end = proof_len_offset + 4 + original_proof_len;

    let mut crafted = Vec::new();
    crafted.extend_from_slice(&bytes[..proof_len_offset]); // header up to proof_len
    crafted.extend_from_slice(&(hash_ivc_json.len() as u32).to_be_bytes());
    crafted.extend_from_slice(&hash_ivc_json);
    crafted.extend_from_slice(&bytes[original_proof_end..]); // verifier_key + value_bytes

    let decoded = VerifiedResponse::from_bytes(&crafted).unwrap();

    // Header says Mock, but proof_bytes contains HashIvc
    assert_eq!(decoded.proof_scheme as u8, BackendId::Mock as u8);

    // validate_header_consistency should catch the mismatch
    assert!(
        !decoded.validate_header_consistency(),
        "V13-07: Parser differential detected — header says Mock, proof_bytes says HashIvc"
    );
}

// ========================================================================
// V13-08: Disclosure with forged redacted hashes (second preimage)
// ========================================================================

/// If an attacker could find a different set of leaf hashes that produce the
/// same Merkle root, they could substitute redacted positions. This test
/// verifies that naive substitution is caught, demonstrating the Merkle root
/// reconstruction check works.
#[test]
fn v13_08_forged_redacted_hashes_detected() {
    let tokens = vec![100, 200, 300, 400];
    let verified = make_verified(tokens.clone());

    // All redacted disclosure
    let mut disclosure = create_disclosure(&verified, &[]).unwrap();

    // Try to replace a redacted leaf hash with a different hash
    // The Merkle root reconstruction should fail.
    if let DisclosedToken::Redacted { index, .. } = &disclosure.tokens[1] {
        disclosure.tokens[1] = DisclosedToken::Redacted {
            index: *index,
            leaf_hash: hash_data(b"forged_leaf"),
        };
    }

    assert!(
        !verify_disclosure(&disclosure),
        "V13-08: Forged redacted leaf hash must be detected by Merkle root reconstruction"
    );
}

/// Test that ALL positions must have correct hashes for root to reconstruct.
#[test]
fn v13_08_forged_last_position() {
    let tokens = vec![10, 20, 30, 40, 50, 60, 70, 80];
    let verified = make_verified(tokens);
    let mut disclosure = create_disclosure(&verified, &[]).unwrap();

    // Forge the very last position
    let last = disclosure.tokens.len() - 1;
    disclosure.tokens[last] = DisclosedToken::Redacted {
        index: last,
        leaf_hash: [0xFF; 32],
    };

    assert!(
        !verify_disclosure(&disclosure),
        "V13-08: Forged last-position leaf hash detected"
    );
}

// ========================================================================
// V13-09: Hash chain fork detection gap
// ========================================================================

/// Two computations that share the same first N steps but diverge at step
/// N+1 produce different chain_tips. This test verifies that the hash chain
/// properly separates forked computations.
#[test]
fn v13_09_hash_chain_fork_divergence() {
    use poly_verified::crypto::chain::HashChain;

    let shared_step = hash_data(b"shared_step");

    // Chain A: shared + fork_a
    let mut chain_a = HashChain::new();
    chain_a.append(&shared_step);
    chain_a.append(&hash_data(b"fork_a"));

    // Chain B: shared + fork_b
    let mut chain_b = HashChain::new();
    chain_b.append(&shared_step);
    chain_b.append(&hash_data(b"fork_b"));

    // After shared prefix, the chains diverge
    assert_ne!(
        chain_a.tip, chain_b.tip,
        "V13-09: Forked chains must have different tips"
    );

    // Verify: just the shared prefix has identical tips
    let mut prefix_a = HashChain::new();
    prefix_a.append(&shared_step);
    let mut prefix_b = HashChain::new();
    prefix_b.append(&shared_step);
    assert_eq!(
        prefix_a.tip, prefix_b.tip,
        "V13-09: Shared prefix produces identical tips (control)"
    );
}

/// Deep fork: 100 shared steps then divergence
#[test]
fn v13_09_deep_fork_detection() {
    use poly_verified::crypto::chain::HashChain;

    let mut chain_a = HashChain::new();
    let mut chain_b = HashChain::new();

    // 100 shared steps
    for i in 0..100u64 {
        let step = hash_data(&i.to_le_bytes());
        chain_a.append(&step);
        chain_b.append(&step);
    }
    assert_eq!(chain_a.tip, chain_b.tip, "100 shared steps match");

    // Diverge
    chain_a.append(&hash_data(b"A"));
    chain_b.append(&hash_data(b"B"));

    assert_ne!(
        chain_a.tip, chain_b.tip,
        "V13-09: Deep fork detected after 100 shared steps"
    );
}

// ========================================================================
// V13-10: Merkle tree odd leaf duplication information leak
// ========================================================================

/// When a Merkle tree has an odd number of leaves, the last leaf is
/// duplicated: hash_combine(leaf, leaf). An observer seeing a proof for
/// the second-to-last leaf gets the last leaf's hash as a sibling,
/// AND the proof path structure reveals the tree has an odd count.
#[test]
fn v13_10_odd_leaf_count_structure_leak() {
    // 3 leaves: positions 0, 1, 2
    let leaves = vec![hash_data(b"a"), hash_data(b"b"), hash_data(b"c")];
    let tree = MerkleTree::build(&leaves);

    // Get proof for leaf 2 (the odd one)
    let proof = tree.generate_proof(2, &ZERO_HASH).unwrap();

    // The first sibling is hash_combine(leaf[2], leaf[2]) — self-duplicate
    // Actually for leaf 2, sibling at leaf level is the duplicate of itself
    // because it's the odd leaf. sibling_index = 3 which doesn't exist,
    // so it duplicates current (layer[current_index]).
    assert_eq!(
        proof.siblings[0].hash, leaves[2],
        "V13-10: Odd leaf's sibling is itself — reveals tree has odd count"
    );

    // The proof reveals that position 2 is the last leaf (because its
    // sibling is itself). This leaks the tree size to the verifier.
    assert!(verify_proof(&proof));
}

/// Even leaf count: no self-duplication at leaf level
#[test]
fn v13_10_even_leaf_no_self_duplicate() {
    let leaves = vec![
        hash_data(b"a"),
        hash_data(b"b"),
        hash_data(b"c"),
        hash_data(b"d"),
    ];
    let tree = MerkleTree::build(&leaves);

    // Leaf 2's sibling is leaf 3 — different
    let proof = tree.generate_proof(2, &ZERO_HASH).unwrap();
    assert_ne!(
        proof.siblings[0].hash, leaves[2],
        "V13-10: Even tree, leaf 2's sibling is leaf 3 (different)"
    );
    assert_eq!(proof.siblings[0].hash, leaves[3]);
}

// ========================================================================
// V13-11: CompositeProof serde roundtrip — no re-verification
// ========================================================================

/// ATTACK: Deserialize a CompositeProof from JSON, tamper with the
/// privacy_mode field. Before V13-11 FIX, the privacy_mode was NOT bound
/// into the composition_hash, so tampering went undetected.
///
/// V13-11 FIX: privacy_mode is now bound into the composition_hash AND
/// verify_composition recomputes the most-restrictive mode and checks it
/// matches the stored field. Tampering is now detected.
#[test]
fn v13_11_composite_serde_privacy_tamper() {
    let outer = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Private,
    };
    let composite = CompositeProof::compose(outer, vec![]);
    assert_eq!(composite.privacy_mode, PrivacyMode::Private);

    // Original verifies
    assert!(composite.verify_composition());

    // Tamper: directly change the privacy_mode field (simulating deserialization attack)
    let mut tampered = composite.clone();
    tampered.privacy_mode = PrivacyMode::Transparent;

    // The privacy mode was changed
    assert_eq!(tampered.privacy_mode, PrivacyMode::Transparent);

    // [V13-11 FIX] verify_composition now REJECTS the tampered privacy_mode
    // because it recomputes most_restrictive_privacy from the contained proofs
    // and finds that the stored field doesn't match (should be Private).
    // Additionally, the composition_hash was computed with the privacy mode bound in,
    // so it won't match even if the privacy_mode check is bypassed.
    assert!(
        !tampered.verify_composition(),
        "V13-11 FIX: Tampered privacy_mode now detected by verify_composition"
    );
}

// ========================================================================
// V13-12: VerifiedProof serde allows inconsistent HashIvc
// ========================================================================

/// ATTACK: Craft a HashIvc proof via serde where step_count != checkpoints.len().
/// The verify method should catch this, but construction via serde bypasses
/// the normal accumulator path.
#[test]
fn v13_12_serde_crafted_inconsistent_hashivc() {
    // Create a valid proof
    let ivc = HashIvc;
    let code_hash = hash_data(b"func");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    let w = StepWitness {
        state_before: hash_data(b"b"),
        state_after: hash_data(b"a"),
        step_inputs: hash_data(b"i"),
    };
    ivc.fold_step(&mut acc, &w).unwrap();
    let proof = ivc.finalize(acc).unwrap();

    // Serialize, tamper step_count, deserialize
    let mut json = serde_json::to_value(&proof).unwrap();
    if let Some(hashivc) = json.get_mut("HashIvc") {
        hashivc["step_count"] = serde_json::json!(999);
    }
    let crafted: VerifiedProof = serde_json::from_value(json).unwrap();

    // The crafted proof has step_count=999 but only 1 checkpoint
    match &crafted {
        VerifiedProof::HashIvc {
            step_count,
            checkpoints,
            ..
        } => {
            assert_eq!(*step_count, 999);
            assert_eq!(checkpoints.len(), 1);
        }
        _ => panic!("wrong variant"),
    }

    // verify should catch the mismatch
    assert!(
        !ivc.verify(&crafted, &ZERO_HASH, &ZERO_HASH).unwrap(),
        "V13-12: step_count != checkpoints.len() must be rejected by verify"
    );
}

// ========================================================================
// V13-13: MerkleProof leaf_index boundary — u64::MAX
// ========================================================================

/// ATTACK: Craft a MerkleProof with leaf_index = u64::MAX. This should be
/// rejected in disclosure verification because no tree has 2^64 leaves.
#[test]
fn v13_13_leaf_index_u64_max() {
    let leaf = token_leaf(42);
    let forged_proof = MerkleProof {
        leaf,
        leaf_index: u64::MAX,
        siblings: vec![],
        root: leaf,
        code_hash: ZERO_HASH,
    };

    // verify_proof only checks hash chain up to root — passes for no siblings
    assert!(
        verify_proof(&forged_proof),
        "V13-13: verify_proof doesn't validate leaf_index bounds"
    );

    // But in a disclosure context, the position check should catch it
    // because the position in the token list can't be u64::MAX
    let tokens = vec![42u32];
    let verified = make_verified(tokens);
    let mut disclosure = create_disclosure(&verified, &[0]).unwrap();

    // Replace the proof with our crafted one (u64::MAX leaf_index)
    disclosure.proofs[0] = forged_proof;

    assert!(
        !verify_disclosure(&disclosure),
        "V13-13: leaf_index = u64::MAX rejected in disclosure verification"
    );
}

// ========================================================================
// V13-14: CodeAttestation circuit_id sentinel abuse
// ========================================================================

/// ATTACK: Use circuit_id = u64::MAX or 0 as sentinel values. The system
/// does not restrict circuit_id range, allowing "special" values that
/// could confuse downstream logic.
#[test]
fn v13_14_attestation_sentinel_circuit_ids() {
    let key = SigningKey::from_bytes(&[0x42; 32]);
    let node_id = [0xAA; 32];
    let code_hash = hash_data(b"code");

    // Sign with circuit_id = 0
    let att_zero = sign_attestation(&node_id, &code_hash, 0, &key);
    assert!(verify_attestation(&att_zero, &key.verifying_key()).is_ok());

    // Sign with circuit_id = u64::MAX
    let att_max = sign_attestation(&node_id, &code_hash, u64::MAX, &key);
    assert!(verify_attestation(&att_max, &key.verifying_key()).is_ok());

    // Both are valid — no range restriction on circuit_id
    // An attacker could use 0 or MAX as "wildcard" sentinels if downstream
    // code treats them specially.
    assert_eq!(att_zero.circuit_id, 0);
    assert_eq!(att_max.circuit_id, u64::MAX);
}

// ========================================================================
// V13-15: FixedPoint from_raw allows any i128
// ========================================================================

/// ATTACK: from_raw accepts any i128 value, including those that don't
/// represent a valid fixed-point number. For example, a raw value that
/// would require more precision than the 48 fractional bits can represent.
/// There is no canonical range enforcement.
#[test]
fn v13_15_fixedpoint_from_raw_no_validation() {
    // Raw value 1 means 1/2^48 — a tiny fraction, but valid
    let tiny = FixedPoint::from_raw(1);
    assert_eq!(tiny.to_i64(), 0);

    // Raw value i128::MAX
    let max = FixedPoint::from_raw(i128::MAX);
    // to_i64() on this wraps (V12-04 finding) but the construction itself succeeds
    let sat = max.to_i64_saturating();
    assert_eq!(sat, i64::MAX);

    // i128::MIN
    let min = FixedPoint::from_raw(i128::MIN);
    let sat_min = min.to_i64_saturating();
    assert_eq!(sat_min, i64::MIN);

    // Any i128 is accepted — no canonical form check
    let weird = FixedPoint::from_raw(42);
    assert_eq!(weird.raw(), 42);

    // Arithmetic on non-canonical values can produce unexpected results
    let a = FixedPoint::from_raw(i128::MAX);
    let b = FixedPoint::from_raw(i128::MAX);
    let sum = a + b; // saturating_add
    assert_eq!(
        sum.raw(),
        i128::MAX,
        "V13-15: Addition of two MAX values saturates (expected)"
    );
}

// ========================================================================
// V13-16: Commitment byte encoding — field order and endianness
// ========================================================================

/// Verify that Commitment to_bytes/from_bytes uses consistent endianness
/// and that swapping fields in the byte representation is detected.
#[test]
fn v13_16_commitment_field_swap_detection() {
    let commitment = Commitment {
        root: [0x11; 32],
        total_checkpoints: 42,
        chain_tip: [0x22; 32],
        code_hash: [0x33; 32],
    };

    let bytes = commitment.to_bytes();

    // Swap root and chain_tip in the byte representation
    let mut swapped = bytes;
    swapped[0..32].copy_from_slice(&[0x22; 32]); // chain_tip in root position
    swapped[40..72].copy_from_slice(&[0x11; 32]); // root in chain_tip position

    let decoded = Commitment::from_bytes(&swapped).unwrap();

    // The fields are swapped
    assert_ne!(
        decoded, commitment,
        "V13-16: Swapped fields produce different commitment (correct)"
    );
    assert_eq!(decoded.root, [0x22; 32]);
    assert_eq!(decoded.chain_tip, [0x11; 32]);
}

/// Verify total_checkpoints uses little-endian encoding consistently.
#[test]
fn v13_16_commitment_endianness() {
    let commitment = Commitment {
        root: ZERO_HASH,
        total_checkpoints: 0x0102030405060708,
        chain_tip: ZERO_HASH,
        code_hash: ZERO_HASH,
    };

    let bytes = commitment.to_bytes();
    // total_checkpoints at bytes[32..40], should be LE
    assert_eq!(
        &bytes[32..40],
        &[0x08, 0x07, 0x06, 0x05, 0x04, 0x03, 0x02, 0x01],
        "V13-16: total_checkpoints must be little-endian"
    );

    let decoded = Commitment::from_bytes(&bytes).unwrap();
    assert_eq!(decoded.total_checkpoints, 0x0102030405060708);
}

// ========================================================================
// V13-17: VerifiedResponse code_hash not cross-checked
// ========================================================================

/// ATTACK: The wire header's code_hash field is set by the sender and not
/// cross-checked against the code_hash inside proof_bytes. An attacker can
/// set a different code_hash in the header than what's in the proof.
#[test]
fn v13_17_response_code_hash_header_mismatch() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"real_code");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    let w = StepWitness {
        state_before: hash_data(b"b"),
        state_after: hash_data(b"a"),
        step_inputs: hash_data(b"i"),
    };
    ivc.fold_step(&mut acc, &w).unwrap();
    let proof = ivc.finalize(acc).unwrap();

    let response =
        VerifiedResponse::new(&proof, ZERO_HASH, b"data".to_vec(), ZERO_HASH);

    let mut bytes = response.to_bytes();

    // Tamper: overwrite the code_hash field in header (bytes 64..96)
    let fake_code_hash = hash_data(b"FAKE_code");
    bytes[64..96].copy_from_slice(&fake_code_hash);

    let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();

    // Header code_hash is now different from proof's code_hash
    assert_eq!(&decoded.code_hash, &fake_code_hash);

    // validate_header_consistency checks proof_scheme and privacy_mode
    // but does NOT check code_hash against proof content
    // This means the tampered code_hash goes undetected by current validation
    let proof_from_bytes: VerifiedProof =
        serde_json::from_slice(&decoded.proof_bytes).unwrap();
    let proof_code_hash = proof_from_bytes.code_hash();
    assert_ne!(
        decoded.code_hash, proof_code_hash,
        "V13-17: Header code_hash differs from proof's code_hash — not cross-checked"
    );
}

// ========================================================================
// V13-18: Disclosure empty token set handling
// ========================================================================

/// Verify that verify_disclosure correctly rejects a zero-length token disclosure.
#[test]
fn v13_18_empty_disclosure_rejected() {
    let disclosure = Disclosure {
        tokens: vec![],
        proofs: vec![],
        output_root: ZERO_HASH,
        total_tokens: 0,
        execution_proof: VerifiedProof::Mock {
            input_hash: ZERO_HASH,
            output_hash: ZERO_HASH,
            privacy_mode: PrivacyMode::Transparent,
        },
        output_binding: ZERO_HASH,
    };

    assert!(
        !verify_disclosure(&disclosure),
        "V13-18: Empty disclosure (0 tokens) must be rejected"
    );
}

/// Disclosure where total_tokens doesn't match tokens.len()
#[test]
fn v13_18_total_tokens_mismatch() {
    let tokens = sample_tokens();
    let verified = make_verified(tokens);
    let mut disclosure = create_disclosure(&verified, &[0]).unwrap();

    // Set wrong total_tokens
    disclosure.total_tokens = 100;

    assert!(
        !verify_disclosure(&disclosure),
        "V13-18: total_tokens != tokens.len() must be rejected"
    );
}

// ========================================================================
// V13-19: Privacy mode transition attack
// ========================================================================

/// ATTACK: Create a proof as Transparent, then use serde to change
/// the privacy_mode to Private. The chain_tip binding includes privacy_mode,
/// so this should cause verification failure.
#[test]
fn v13_19_privacy_mode_downgrade_detected() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"func");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    let w = StepWitness {
        state_before: hash_data(b"b"),
        state_after: hash_data(b"a"),
        step_inputs: hash_data(b"i"),
    };
    ivc.fold_step(&mut acc, &w).unwrap();
    acc.input_hash = hash_data(b"in");
    acc.output_hash = hash_data(b"out");
    let proof = ivc.finalize(acc).unwrap();

    // Tamper: change privacy_mode from Transparent to Private via serde
    let mut json = serde_json::to_value(&proof).unwrap();
    if let Some(hashivc) = json.get_mut("HashIvc") {
        hashivc["privacy_mode"] = serde_json::json!("Private");
        // Also need blinding_commitment for Private mode
        hashivc["blinding_commitment"] = serde_json::json!(vec![0u8; 32]);
    }
    let tampered: VerifiedProof = serde_json::from_value(json).unwrap();

    // The chain_tip was computed with Transparent mode binding.
    // Changing to Private means mode_binding = hash_data(&[0x01]) instead of &[0x00],
    // so chain_tip won't match.
    assert!(
        !ivc.verify(&tampered, &hash_data(b"in"), &hash_data(b"out"))
            .unwrap(),
        "V13-19: Privacy mode downgrade detected — chain_tip binding includes mode"
    );
}

/// Upgrade from Private to Transparent should also fail.
#[test]
fn v13_19_privacy_mode_upgrade_detected() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"func");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Private);
    let w = StepWitness {
        state_before: hash_data(b"b"),
        state_after: hash_data(b"a"),
        step_inputs: hash_data(b"i"),
    };
    ivc.fold_step(&mut acc, &w).unwrap();
    let proof = ivc.finalize(acc).unwrap();

    // Tamper: change to Transparent and remove blinding
    let mut json = serde_json::to_value(&proof).unwrap();
    if let Some(hashivc) = json.get_mut("HashIvc") {
        hashivc["privacy_mode"] = serde_json::json!("Transparent");
        hashivc["blinding_commitment"] = serde_json::Value::Null;
    }
    let tampered: VerifiedProof = serde_json::from_value(json).unwrap();

    assert!(
        !ivc.verify(&tampered, &ZERO_HASH, &ZERO_HASH).unwrap(),
        "V13-19: Privacy mode upgrade detected — chain_tip binding includes mode"
    );
}

// ========================================================================
// V13-20: MerkleProof code_hash not verified in verify_proof
// ========================================================================

/// ATTACK: verify_proof does not check code_hash at all. An attacker can
/// set any code_hash in the MerkleProof and it still verifies.
#[test]
fn v13_20_merkle_proof_code_hash_ignored() {
    let leaves = vec![hash_data(b"a"), hash_data(b"b"), hash_data(b"c"), hash_data(b"d")];
    let tree = MerkleTree::build(&leaves);

    let mut proof = tree.generate_proof(0, &hash_data(b"real_code")).unwrap();

    // Change code_hash to something completely different
    proof.code_hash = [0xFF; 32];

    // verify_proof still passes — code_hash is not checked
    assert!(
        verify_proof(&proof),
        "V13-20: verify_proof ignores code_hash field — any code_hash accepted"
    );
}

// ========================================================================
// V13-21: HashIvc blinding is deterministic, not random
// ========================================================================

/// The blinding_commitment in Private mode is computed deterministically
/// from the checkpoints and step counters. This means the "blinding" is
/// reproducible by anyone who knows the checkpoints.
#[test]
fn v13_21_blinding_deterministic_not_random() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"func");

    // Run the same computation twice
    let mut results = Vec::new();
    for _ in 0..2 {
        let mut acc = ivc.init(&code_hash, PrivacyMode::Private);
        let w = StepWitness {
            state_before: hash_data(b"b"),
            state_after: hash_data(b"a"),
            step_inputs: hash_data(b"i"),
        };
        ivc.fold_step(&mut acc, &w).unwrap();
        results.push(ivc.finalize(acc).unwrap());
    }

    // Both produce the same blinding_commitment
    match (&results[0], &results[1]) {
        (
            VerifiedProof::HashIvc {
                blinding_commitment: Some(bc1),
                ..
            },
            VerifiedProof::HashIvc {
                blinding_commitment: Some(bc2),
                ..
            },
        ) => {
            assert_eq!(
                bc1, bc2,
                "V13-21: Blinding commitment is deterministic — same computation \
                 always produces same blinding. Not truly random."
            );
        }
        _ => panic!("Expected HashIvc with blinding"),
    }
}

// ========================================================================
// V13-22: Verified<T> Serialize exposes proof internals
// ========================================================================

/// Verified<T> derives Serialize, which means proof internals (including
/// checkpoints, chain_tip, etc.) are serialized even in Private mode.
/// This could leak computation details if the serialized form is exposed.
#[test]
fn v13_22_verified_serialize_exposes_private_proof() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"secret_func");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Private);
    let w = StepWitness {
        state_before: hash_data(b"secret_state"),
        state_after: hash_data(b"secret_result"),
        step_inputs: hash_data(b"secret_input"),
    };
    ivc.fold_step(&mut acc, &w).unwrap();
    let proof = ivc.finalize(acc).unwrap();

    let verified = Verified::__macro_new(42u64, proof);

    // Serialize the Verified value
    let json = serde_json::to_string(&verified).unwrap();

    // The JSON contains the full proof internals
    assert!(
        json.contains("chain_tip"),
        "V13-22: Serialized Verified exposes chain_tip even in Private mode"
    );
    assert!(
        json.contains("checkpoints"),
        "V13-22: Serialized Verified exposes checkpoints even in Private mode"
    );
    assert!(
        json.contains("blinding_commitment"),
        "V13-22: Serialized Verified exposes blinding_commitment"
    );
}

// ========================================================================
// V13-23: FixedPoint Display truncation hides precision
// ========================================================================

/// The Display impl shows 6 decimal places. Values with precision beyond
/// 6 places are truncated (not rounded) in the display, potentially
/// misleading in verified computation audit logs.
#[test]
fn v13_23_fixedpoint_display_truncation() {
    // 1/3 = 0.333333333... but Display shows 0.333333 (6 places)
    let third = FixedPoint::from_int(1)
        .checked_div(FixedPoint::from_int(3))
        .unwrap();
    let display = format!("{}", third);
    assert_eq!(
        display, "0.333333",
        "V13-23: Display truncates to 6 decimal places"
    );

    // The actual raw value has much more precision
    let expected_raw = FixedPoint::SCALE / 3;
    assert_eq!(third.raw(), expected_raw);

    // Two values that look the same in Display can be different
    let a = FixedPoint::from_raw(expected_raw);
    let b = FixedPoint::from_raw(expected_raw + 1);
    assert_eq!(
        format!("{}", a),
        format!("{}", b),
        "V13-23: Two different values display identically"
    );
    assert_ne!(a, b, "V13-23: But they are NOT equal");
}

// ========================================================================
// V13-24: CompositeProof proof_count boundary
// ========================================================================

/// Verify that MAX_INNER_PROOFS is enforced on verification, not just
/// construction.
#[test]
fn v13_24_composite_max_inner_proofs_on_verify() {
    // Create a composite via serde with > MAX_INNER_PROOFS inner proofs
    let outer = VerifiedProof::Mock {
        input_hash: ZERO_HASH,
        output_hash: ZERO_HASH,
        privacy_mode: PrivacyMode::Transparent,
    };
    // We can't construct via compose() (it asserts), so test the limit
    let composite = CompositeProof::compose(outer.clone(), vec![]);
    let mut json = serde_json::to_value(&composite).unwrap();

    // Create 1025 inner proofs via JSON (exceeds MAX_INNER_PROOFS=1024)
    let inner_json = serde_json::to_value(&outer).unwrap();
    let many_inners: Vec<_> = (0..1025).map(|_| inner_json.clone()).collect();
    json["inner_proofs"] = serde_json::json!(many_inners);

    let oversized: CompositeProof = serde_json::from_value(json).unwrap();
    assert_eq!(oversized.inner_proofs.len(), 1025);

    // verify_composition should reject
    assert!(
        !oversized.verify_composition(),
        "V13-24: Deserialized composite with >1024 inner proofs must be rejected"
    );
}

// ========================================================================
// V13-25: Disclosure output_binding no domain separation
// ========================================================================

/// The output_binding is SHA-256 of raw token bytes concatenated.
/// tokens_hash([100, 200]) = SHA256(100_le || 200_le).
/// A different token sequence that produces the same byte pattern would
/// collide. This test verifies domain separation by checking that different
/// orderings produce different hashes (which they do, since each token is
/// 4 bytes LE).
#[test]
fn v13_25_output_binding_order_dependent() {
    let hash_a = tokens_hash(&[100, 200]);
    let hash_b = tokens_hash(&[200, 100]);

    assert_ne!(
        hash_a, hash_b,
        "V13-25: Token order must affect output_binding"
    );
}

/// However, tokens_hash doesn't use a domain separator or length prefix.
/// A single token [0x00C80000] could collide with two tokens [200, 0] if
/// the byte representations happen to align. Test that 4-byte LE encoding
/// prevents this for typical values.
#[test]
fn v13_25_output_binding_length_ambiguity() {
    // tokens_hash([200, 0]) = SHA256(C8_00_00_00 || 00_00_00_00)
    // tokens_hash([0xC8]) = SHA256(C8_00_00_00)
    // These are different lengths, so they differ
    let hash_two = tokens_hash(&[200, 0]);
    let hash_one = tokens_hash(&[200]);
    assert_ne!(
        hash_two, hash_one,
        "V13-25: Different token counts with shared prefix produce different hashes"
    );

    // But same count, shifted bytes: [0, 200] vs [200, 0]
    let hash_shifted = tokens_hash(&[0, 200]);
    assert_ne!(hash_two, hash_shifted);
}

// ========================================================================
// V13-26: Disclosure with single revealed token at various positions
// ========================================================================

/// Verify disclosure works correctly for each position in an 8-token output.
#[test]
fn v13_26_disclosure_each_position() {
    let tokens = sample_tokens();
    let verified = make_verified(tokens);

    for i in 0..8 {
        let disclosure = create_disclosure(&verified, &[i]).unwrap();
        assert!(
            verify_disclosure(&disclosure),
            "V13-26: Disclosure for single position {} must verify",
            i
        );
    }
}

// ========================================================================
// V13-27: HashIvc multi-step proof with I/O binding
// ========================================================================

/// Verify that a multi-step proof correctly binds I/O hashes.
#[test]
fn v13_27_multistep_io_binding() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"multistep");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);

    for i in 0..10u8 {
        let w = StepWitness {
            state_before: hash_data(&[i]),
            state_after: hash_data(&[i + 1]),
            step_inputs: hash_data(&[i * 3]),
        };
        ivc.fold_step(&mut acc, &w).unwrap();
    }

    let input_hash = hash_data(b"real_input");
    let output_hash = hash_data(b"real_output");
    acc.input_hash = input_hash;
    acc.output_hash = output_hash;
    let proof = ivc.finalize(acc).unwrap();

    // Correct I/O: passes
    assert!(ivc.verify(&proof, &input_hash, &output_hash).unwrap());

    // Wrong input: fails
    assert!(!ivc
        .verify(&proof, &hash_data(b"wrong_input"), &output_hash)
        .unwrap());

    // Wrong output: fails
    assert!(!ivc
        .verify(&proof, &input_hash, &hash_data(b"wrong_output"))
        .unwrap());
}

// ========================================================================
// V13-28: Verified<Result<T, VerifiedError>> type confusion
// ========================================================================

/// An attacker creates a Verified<Result<T, VerifiedError>> wrapping an
/// Err variant with a proof that was generated for an Ok result.
/// The proof doesn't distinguish between Ok and Err paths.
#[test]
fn v13_28_verified_result_path_confusion() {
    use poly_verified::error::VerifiedError;

    let tokens = sample_tokens();
    let proof = valid_hash_ivc_proof_for_tokens(&tokens);

    // Create Verified<Ok(tokens)> — this is the "real" result
    let verified_ok: Verified<Result<Vec<u32>, VerifiedError>> =
        Verified::__macro_new(Ok(tokens.clone()), proof.clone());

    assert!(verified_ok.is_ok());
    assert!(verified_ok.is_verified());

    // Now attach the same proof to an Err result
    let verified_err: Verified<Result<Vec<u32>, VerifiedError>> =
        Verified::__macro_new(Err(VerifiedError::DivisionByZero), proof);

    assert!(verified_err.is_err());
    // The proof still "verifies" because the proof doesn't encode the Result variant
    assert!(
        verified_err.is_verified(),
        "V13-28: Proof from Ok path accepted on Err variant — \
         Result success/failure not bound in proof"
    );
}

// ========================================================================
// V13-29: SignedCommitment signature malleability check
// ========================================================================

/// Ed25519 signatures are not malleable in ed25519-dalek (which uses strict
/// verification). Verify that a modified signature correctly fails.
#[test]
fn v13_29_signed_commitment_signature_tamper() {
    use poly_verified::crypto::commitment::{
        create_commitment, sign_commitment, verify_signed_commitment,
    };

    let checkpoints: Vec<Hash> = (0..4u8).map(|i| hash_data(&[i])).collect();
    let code_hash = hash_data(b"code");
    let (commitment, _) = create_commitment(&checkpoints, &code_hash);

    let key = SigningKey::from_bytes(&[0x42; 32]);
    let mut signed = sign_commitment(&commitment, &key);

    // Flip a bit in the signature
    signed.signature[0] ^= 0x01;

    assert!(
        verify_signed_commitment(&signed).is_err(),
        "V13-29: Tampered signature must fail verification"
    );
}

// ========================================================================
// V13-30: MerkleTree large tree consistency
// ========================================================================

/// Build a large Merkle tree (1024 leaves) and verify all proofs.
#[test]
fn v13_30_large_merkle_tree() {
    let leaves: Vec<Hash> = (0..1024u32).map(|i| hash_data(&i.to_le_bytes())).collect();
    let tree = MerkleTree::build(&leaves);

    // Verify proofs at boundary positions
    for &idx in &[0u64, 1, 511, 512, 1023] {
        let proof = tree.generate_proof(idx, &ZERO_HASH).unwrap();
        assert!(
            verify_proof(&proof),
            "V13-30: Proof for index {} in 1024-leaf tree must verify",
            idx
        );
    }
}

// ========================================================================
// V13-31: Disclosure with adjacent revealed tokens
// ========================================================================

/// When two adjacent tokens are both revealed, their Merkle proofs share
/// some siblings. Verify this doesn't cause issues.
#[test]
fn v13_31_adjacent_revealed_tokens() {
    let tokens = sample_tokens();
    let verified = make_verified(tokens);

    // Reveal adjacent: 3, 4, 5
    let disclosure = create_disclosure(&verified, &[3, 4, 5]).unwrap();

    assert_eq!(disclosure.proofs.len(), 3);
    assert!(verify_disclosure(&disclosure));

    // All three proofs should have the same root
    for p in &disclosure.proofs {
        assert_eq!(p.root, disclosure.output_root);
    }
}

// ========================================================================
// V13-32: VerifiedResponse roundtrip for every privacy mode
// ========================================================================

#[test]
fn v13_32_response_roundtrip_all_privacy_modes() {
    for mode in [
        PrivacyMode::Transparent,
        PrivacyMode::PrivateInputs,
        PrivacyMode::Private,
    ] {
        let proof = VerifiedProof::Mock {
            input_hash: hash_data(b"input"),
            output_hash: hash_data(b"output"),
            privacy_mode: mode,
        };

        let response = VerifiedResponse::new(
            &proof,
            hash_data(b"input"),
            b"test_value".to_vec(),
            hash_data(b"verifier_key"),
        );

        let bytes = response.to_bytes();
        let decoded = VerifiedResponse::from_bytes(&bytes).unwrap();

        assert_eq!(decoded.privacy_mode, mode);
        assert!(decoded.validate_header_consistency());
        assert!(decoded.verify_value_integrity());

        match mode {
            PrivacyMode::Private => {
                assert!(decoded.value_bytes.is_empty());
                assert_eq!(decoded.value_hash, ZERO_HASH);
                assert_eq!(decoded.input_hash, ZERO_HASH);
            }
            PrivacyMode::PrivateInputs => {
                assert_eq!(decoded.value_bytes, b"test_value");
                assert_eq!(decoded.input_hash, ZERO_HASH);
            }
            PrivacyMode::Transparent => {
                assert_eq!(decoded.value_bytes, b"test_value");
                assert_eq!(decoded.input_hash, hash_data(b"input"));
            }
        }
    }
}

// ========================================================================
// V13-33: HashIvc PrivateInputs mode I/O verification
// ========================================================================

/// PrivateInputs: inputs are hidden but output must match.
#[test]
fn v13_33_private_inputs_output_checked() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"func");
    let mut acc = ivc.init(&code_hash, PrivacyMode::PrivateInputs);
    let w = StepWitness {
        state_before: hash_data(b"b"),
        state_after: hash_data(b"a"),
        step_inputs: hash_data(b"i"),
    };
    ivc.fold_step(&mut acc, &w).unwrap();
    let real_output = hash_data(b"real_out");
    acc.output_hash = real_output;
    let proof = ivc.finalize(acc).unwrap();

    // Correct output: passes (any input accepted in PrivateInputs mode)
    assert!(ivc.verify(&proof, &hash_data(b"any_input"), &real_output).unwrap());

    // Wrong output: fails
    assert!(
        !ivc.verify(&proof, &ZERO_HASH, &hash_data(b"wrong_output"))
            .unwrap(),
        "V13-33: PrivateInputs mode must still verify output hash"
    );
}

// ========================================================================
// V13-34: Disclosure all-revealed full verification
// ========================================================================

/// Full reveal should recompute tokens_hash and verify against output_binding.
#[test]
fn v13_34_full_reveal_tokens_hash_verification() {
    let tokens = vec![10, 20, 30, 40];
    let verified = make_verified(tokens.clone());

    let disclosure = create_disclosure(&verified, &[0, 1, 2, 3]).unwrap();

    // All revealed: tokens_hash recomputation applies
    assert!(verify_disclosure(&disclosure));

    // Tamper: change output_binding (mismatch with tokens_hash)
    let mut tampered = disclosure.clone();
    tampered.output_binding = hash_data(b"wrong");

    assert!(
        !verify_disclosure(&tampered),
        "V13-34: Tampered output_binding caught by tokens_hash recomputation"
    );
}

// ========================================================================
// V13-35: Disclosure token index spoofing
// ========================================================================

/// ATTACK: Set a disclosed token's index to a wrong value.
#[test]
fn v13_35_token_index_spoofing() {
    let tokens = sample_tokens();
    let verified = make_verified(tokens);
    let mut disclosure = create_disclosure(&verified, &[]).unwrap();

    // Set token 3's index to 4 (wrong)
    disclosure.tokens[3] = DisclosedToken::Redacted {
        index: 4, // wrong! should be 3
        leaf_hash: hash_data(b"whatever"),
    };

    assert!(
        !verify_disclosure(&disclosure),
        "V13-35: Token index spoofing detected by sequential index check"
    );
}

// ========================================================================
// V13-36: Hash domain separation between all hash functions
// ========================================================================

/// Verify that all five domain-separated hash functions produce different
/// outputs for the same input.
#[test]
fn v13_36_full_domain_separation() {
    let input = [0xAB; 32];

    let h_data = hash_data(&input);
    let h_leaf = hash_leaf(&input);
    let h_transition = hash_transition(&input, &input, &input);
    let h_chain = hash_chain_step(&input, &input);
    let h_blinding = hash_blinding(&input);
    let h_combine = hash_combine(&input, &input);

    // All must be different
    let all = [h_data, h_leaf, h_transition, h_chain, h_blinding, h_combine];
    for i in 0..all.len() {
        for j in (i + 1)..all.len() {
            assert_ne!(
                all[i], all[j],
                "V13-36: Hash functions {} and {} must produce different outputs",
                i, j
            );
        }
    }
}

// ========================================================================
// V13-37: VerifiedProof serde roundtrip preserves all fields
// ========================================================================

#[test]
fn v13_37_proof_serde_roundtrip() {
    let ivc = HashIvc;
    let code_hash = hash_data(b"roundtrip");
    let mut acc = ivc.init(&code_hash, PrivacyMode::Transparent);
    for i in 0..5u8 {
        let w = StepWitness {
            state_before: hash_data(&[i]),
            state_after: hash_data(&[i + 1]),
            step_inputs: hash_data(&[i * 2]),
        };
        ivc.fold_step(&mut acc, &w).unwrap();
    }
    acc.input_hash = hash_data(b"in");
    acc.output_hash = hash_data(b"out");
    let proof = ivc.finalize(acc).unwrap();

    // Roundtrip through JSON
    let json = serde_json::to_string(&proof).unwrap();
    let deserialized: VerifiedProof = serde_json::from_str(&json).unwrap();

    // Must still verify
    assert!(
        ivc.verify(&deserialized, &hash_data(b"in"), &hash_data(b"out"))
            .unwrap(),
        "V13-37: Serde roundtrip must preserve proof validity"
    );
}

// ========================================================================
// V13-38: CodeAttestation serialization roundtrip integrity
// ========================================================================

#[test]
fn v13_38_attestation_roundtrip() {
    let key = SigningKey::from_bytes(&[0x42; 32]);
    let node_id = [0xAA; 32];
    let code_hash = hash_data(b"code");

    let att = sign_attestation(&node_id, &code_hash, 12345, &key);

    // Binary roundtrip
    let bytes = att.to_bytes();
    let decoded = CodeAttestation::from_bytes(&bytes).unwrap();

    assert_eq!(decoded.node_id, node_id);
    assert_eq!(decoded.code_hash, code_hash);
    assert_eq!(decoded.circuit_id, 12345);
    assert_eq!(decoded.signature, att.signature);

    // Decoded attestation still verifies
    assert!(verify_attestation(&decoded, &key.verifying_key()).is_ok());
}

// ========================================================================
// V13-39: Disclosure with PrivateInputs mode proof
// ========================================================================

/// Create a disclosure with a PrivateInputs mode proof and verify it works.
#[test]
fn v13_39_disclosure_private_inputs_mode() {
    let tokens = vec![10, 20, 30, 40];
    let ivc = HashIvc;
    let code_hash = [0x03; 32];
    let mut acc = ivc.init(&code_hash, PrivacyMode::PrivateInputs);
    let w = StepWitness {
        state_before: hash_data(b"b"),
        state_after: hash_data(b"a"),
        step_inputs: hash_data(b"i"),
    };
    ivc.fold_step(&mut acc, &w).unwrap();
    acc.input_hash = ZERO_HASH;
    acc.output_hash = tokens_hash(&tokens);
    let proof = ivc.finalize(acc).unwrap();

    let verified = Verified::__macro_new(tokens, proof);
    let disclosure = create_disclosure(&verified, &[1, 2]).unwrap();

    assert!(
        verify_disclosure(&disclosure),
        "V13-39: Disclosure with PrivateInputs mode proof should verify"
    );
}

// ========================================================================
// V13-40: FixedPoint arithmetic identity laws
// ========================================================================

/// Verify that FixedPoint arithmetic respects basic identity laws
/// (additive identity, multiplicative identity).
#[test]
fn v13_40_fixedpoint_identity_laws() {
    let values = [
        FixedPoint::from_int(0),
        FixedPoint::from_int(1),
        FixedPoint::from_int(-1),
        FixedPoint::from_int(42),
        FixedPoint::from_int(-999),
        FixedPoint::from_decimal(314159, 5), // pi approximation
    ];

    for &v in &values {
        // Additive identity: v + 0 == v
        assert_eq!(v + FixedPoint::ZERO, v, "Additive identity failed for {:?}", v);

        // Multiplicative identity: v * 1 == v
        assert_eq!(v * FixedPoint::ONE, v, "Multiplicative identity failed for {:?}", v);

        // Additive inverse: v + (-v) == 0
        let sum = v + (-v);
        assert_eq!(sum, FixedPoint::ZERO, "Additive inverse failed for {:?}", v);
    }
}

// ========================================================================
// V13-41: Commitment PartialEq symmetry
// ========================================================================

#[test]
fn v13_41_commitment_eq_symmetry() {
    let a = Commitment {
        root: [0x11; 32],
        total_checkpoints: 5,
        chain_tip: [0x22; 32],
        code_hash: [0x33; 32],
    };
    let b = a.clone();

    // Symmetry: a == b implies b == a
    assert_eq!(a, b);
    assert_eq!(b, a);

    // Reflexivity: a == a
    assert_eq!(a, a);
}

// ========================================================================
// V13-42: BackendId and PrivacyMode from_u8 exhaustive rejection
// ========================================================================

#[test]
fn v13_42_backend_id_exhaustive() {
    // Valid values
    assert!(BackendId::from_u8(0x00).is_ok());
    assert!(BackendId::from_u8(0x01).is_ok());
    assert!(BackendId::from_u8(0x02).is_ok());
    assert!(BackendId::from_u8(0x03).is_ok());

    // All others must be rejected
    for v in 0x04..=0xFF {
        assert!(
            BackendId::from_u8(v).is_err(),
            "V13-42: BackendId 0x{:02x} should be rejected",
            v
        );
    }
}

#[test]
fn v13_42_privacy_mode_exhaustive() {
    // Valid values
    assert!(PrivacyMode::from_u8(0x00).is_ok());
    assert!(PrivacyMode::from_u8(0x01).is_ok());
    assert!(PrivacyMode::from_u8(0x02).is_ok());

    // All others must be rejected
    for v in 0x03..=0xFF {
        assert!(
            PrivacyMode::from_u8(v).is_err(),
            "V13-42: PrivacyMode 0x{:02x} should be rejected",
            v
        );
    }
}

/// BackendId quantum resistance property
#[test]
fn v13_42_backend_quantum_resistance() {
    assert!(!BackendId::Mock.is_quantum_resistant());
    assert!(BackendId::HashIvc.is_quantum_resistant());
    // Nova and HyperNova are not hash-based
    assert!(!BackendId::Nova.is_quantum_resistant());
    assert!(!BackendId::HyperNova.is_quantum_resistant());
}
